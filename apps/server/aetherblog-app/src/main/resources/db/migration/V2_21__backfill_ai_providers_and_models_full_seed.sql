-- ============================================================
-- Backfill AI providers/models full builtin seed
-- 目标：生产环境补齐缺失的默认供应商与模型配置
-- 说明：复用 V2_11 的 providers + models 全量种子；仅补缺，不覆盖现有数据
-- 幂等：ON CONFLICT DO NOTHING
-- ============================================================

-- Compatibility guard:
-- Some legacy environments carry an older/incompatible api_type check constraint
-- (e.g. does not allow 'azure'). Normalize legacy alias and recreate constraint
-- before bulk provider seed to avoid Flyway startup failure.
DO $$
BEGIN
    IF EXISTS (
        SELECT 1
        FROM information_schema.tables
        WHERE table_schema = current_schema()
          AND table_name = 'ai_providers'
    ) THEN
        UPDATE ai_providers
        SET api_type = 'openai_compat'
        WHERE api_type IS NULL
           OR btrim(api_type) = ''
           OR lower(api_type) = 'openai';

        IF EXISTS (
            SELECT 1
            FROM pg_constraint
            WHERE conname = 'chk_ai_provider_api_type'
              AND conrelid = 'ai_providers'::regclass
        ) THEN
            ALTER TABLE ai_providers
                DROP CONSTRAINT chk_ai_provider_api_type;
        END IF;

        ALTER TABLE ai_providers
            ADD CONSTRAINT chk_ai_provider_api_type CHECK (
                api_type IN ('openai_compat', 'anthropic', 'google', 'azure', 'custom')
            ) NOT VALID;
    END IF;
END $$;

-- Part 1: Providers (full seed from V2_11)
INSERT INTO ai_providers (code, name, display_name, api_type, base_url, doc_url, capabilities, priority) VALUES
    ('openai', 'OpenAI', 'OpenAI', 'openai_compat', 'https://api.openai.com/v1', 'https://platform.openai.com/docs/models', '{"source": "builtin", "description": "OpenAI 是全球领先的人工智能研究机构，其开发的模型如GPT系列推动了自然语言处理的前沿。OpenAI 致力于通过创新和高效的AI解决方案改变多个行业。他们的产品具有显著的性能和经济性，广泛用于研究、商业和创新应用。", "apiKeyUrl": "https://platform.openai.com/api-keys?utm_source=lobehub", "modelsUrl": "https://platform.openai.com/docs/models", "url": "https://openai.com", "settings": {"responseAnimation": "smooth", "showModelFetcher": true, "supportResponsesApi": true}, "checkModel": "gpt-5-nano"}', 1000),
    ('azure', 'Azure OpenAI', 'Azure OpenAI', 'azure', NULL, 'https://learn.microsoft.com/azure/ai-services/openai/concepts/models', '{"source": "builtin", "description": "Azure 提供多种先进的AI模型，包括GPT-3.5和最新的GPT-4系列，支持多种数据类型和复杂任务，致力于安全、可靠和可持续的AI解决方案。", "modelsUrl": "https://learn.microsoft.com/azure/ai-services/openai/concepts/models", "url": "https://azure.microsoft.com", "settings": {"defaultShowBrowserRequest": true, "sdkType": "azure", "showDeployName": true}}', 999),
    ('azureai', 'Azure AI', 'Azure AI', 'azure', NULL, 'https://ai.azure.com/explore/models', '{"source": "builtin", "description": "Azure 提供多种先进的AI模型，包括GPT-3.5和最新的GPT-4系列，支持多种数据类型和复杂任务，致力于安全、可靠和可持续的AI解决方案。", "modelsUrl": "https://ai.azure.com/explore/models", "url": "https://ai.azure.com", "settings": {"defaultShowBrowserRequest": true, "sdkType": "azureai", "showDeployName": true}}', 998),
    ('ollama', 'Ollama', 'Ollama', 'openai_compat', 'http://localhost:11434/v1', 'https://ollama.com/library', '{"source": "builtin", "description": "Ollama 提供的模型广泛涵盖代码生成、数学运算、多语种处理和对话互动等领域，支持企业级和本地化部署的多样化需求。", "modelsUrl": "https://ollama.com/library", "url": "https://ollama.com", "settings": {"defaultShowBrowserRequest": true, "sdkType": "ollama", "showApiKey": false, "showModelFetcher": true}, "checkModel": "deepseek-r1"}', 997),
    ('ollamacloud', 'Ollama Cloud', 'Ollama Cloud', 'openai_compat', NULL, 'https://ollama.com/library', '{"source": "builtin", "description": "Ollama Cloud 提供官方托管的推理服务，开箱即用地访问 Ollama 模型库，并支持 OpenAI 兼容接口。", "modelsUrl": "https://ollama.com/library", "url": "https://ollama.com/cloud", "settings": {"disableBrowserRequest": true, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "gpt-oss:20b"}', 996),
    ('vllm', 'vLLM', 'vLLM', 'openai_compat', 'http://localhost:8000/v1', 'https://docs.vllm.ai/en/latest/models/supported_models.html#supported-models', '{"source": "builtin", "description": "vLLM 是一个快速且易于使用的库，用于 LLM 推理和服务。", "modelsUrl": "https://docs.vllm.ai/en/latest/models/supported_models.html#supported-models", "url": "https://docs.vllm.ai", "settings": {"proxyUrl": {"placeholder": "http://localhost:8000/v1"}, "sdkType": "openai", "showModelFetcher": true}}', 995),
    ('comfyui', 'ComfyUI', 'ComfyUI', 'custom', NULL, 'https://www.comfy.org/', '{"source": "builtin", "description": "强大的开源图像、视频、音频生成工作流引擎，支持 SD FLUX Qwen Hunyuan WAN 等先进模型，提供节点化工作流编辑和私有化部署能力", "url": "https://www.comfy.org/", "settings": {"disableBrowserRequest": true, "sdkType": "comfyui", "showAddNewModel": false, "showApiKey": true, "showChecker": false, "showModelFetcher": false}}', 994),
    ('xinference', 'Xinference', 'Xinference', 'openai_compat', 'http://localhost:9997/v1', 'https://inference.readthedocs.io/zh-cn/latest/models/builtin/index.html', '{"source": "builtin", "description": "Xorbits Inference (Xinference) 是一个开源平台，用于简化各种 AI 模型的运行和集成。借助 Xinference，您可以使用任何开源 LLM、嵌入模型和多模态模型在云端或本地环境中运行推理，并创建强大的 AI 应用。", "modelsUrl": "https://inference.readthedocs.io/zh-cn/latest/models/builtin/index.html", "url": "https://inference.readthedocs.io/zh-cn/v0.12.3/index.html", "settings": {"proxyUrl": {"placeholder": "http://localhost:9997/v1"}, "sdkType": "openai"}}', 993),
    ('anthropic', 'Anthropic', 'Anthropic', 'anthropic', 'https://api.anthropic.com', 'https://docs.anthropic.com/en/docs/about-claude/models#model-names', '{"source": "builtin", "description": "Anthropic 是一家专注于人工智能研究和开发的公司，提供了一系列先进的语言模型，如 Claude 3.5 Sonnet、Claude 3 Sonnet、Claude 3 Opus 和 Claude 3 Haiku。这些模型在智能、速度和成本之间取得了理想的平衡，适用于从企业级工作负载到快速响应的各种应用场景。Claude 3.5 Sonnet 作为其最新模型，在多项评估中表现优异，同时保持了较高的性价比。", "modelsUrl": "https://docs.anthropic.com/en/docs/about-claude/models#model-names", "url": "https://anthropic.com", "settings": {"proxyUrl": {"placeholder": "https://api.anthropic.com"}, "responseAnimation": "smooth", "sdkType": "anthropic", "showModelFetcher": true}, "checkModel": "claude-3-haiku-20240307"}', 992),
    ('bedrock', 'Bedrock', 'Bedrock', 'custom', NULL, 'https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html', '{"source": "builtin", "description": "Bedrock 是亚马逊 AWS 提供的一项服务，专注于为企业提供先进的 AI 语言模型和视觉模型。其模型家族包括 Anthropic 的 Claude 系列、Meta 的 Llama 3.1 系列等，涵盖从轻量级到高性能的多种选择，支持文本生成、对话、图像处理等多种任务，适用于不同规模和需求的企业应用。", "modelsUrl": "https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html", "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html", "settings": {"sdkType": "bedrock"}, "checkModel": "anthropic.claude-instant-v1"}', 991),
    ('google', 'Google', 'Google', 'google', 'https://generativelanguage.googleapis.com', 'https://ai.google.dev/gemini-api/docs/models/gemini', '{"source": "builtin", "description": "Google 的 Gemini 系列是其最先进、通用的 AI模型，由 Google DeepMind 打造，专为多模态设计，支持文本、代码、图像、音频和视频的无缝理解与处理。适用于从数据中心到移动设备的多种环境，极大提升了AI模型的效率与应用广泛性。", "modelsUrl": "https://ai.google.dev/gemini-api/docs/models/gemini", "url": "https://ai.google.dev", "settings": {"proxyUrl": {"placeholder": "https://generativelanguage.googleapis.com"}, "responseAnimation": {"speed": 50, "text": "smooth"}, "sdkType": "google", "showModelFetcher": true}, "checkModel": "gemini-2.0-flash"}', 990),
    ('vertexai', 'Vertex AI', 'Vertex AI', 'google', NULL, 'https://console.cloud.google.com/vertex-ai/model-garden', '{"source": "builtin", "description": "Google 的 Gemini 系列是其最先进、通用的 AI模型，由 Google DeepMind 打造，专为多模态设计，支持文本、代码、图像、音频和视频的无缝理解与处理。适用于从数据中心到移动设备的多种环境，极大提升了AI模型的效率与应用广泛性。", "modelsUrl": "https://console.cloud.google.com/vertex-ai/model-garden", "url": "https://cloud.google.com/vertex-ai", "settings": {"disableBrowserRequest": true, "responseAnimation": "smooth", "showModelFetcher": false}, "checkModel": "gemini-1.5-flash-001"}', 989),
    ('deepseek', 'DeepSeek', 'DeepSeek', 'openai_compat', 'https://api.deepseek.com', 'https://platform.deepseek.com/api-docs/zh-cn/quick_start/pricing', '{"source": "builtin", "description": "DeepSeek 是一家专注于人工智能技术研究和应用的公司，其最新模型 DeepSeek-V3 多项评测成绩超越 Qwen2.5-72B 和 Llama-3.1-405B 等开源模型，性能对齐领军闭源模型 GPT-4o 与 Claude-3.5-Sonnet。", "modelsUrl": "https://platform.deepseek.com/api-docs/zh-cn/quick_start/pricing", "url": "https://deepseek.com", "settings": {"proxyUrl": {"placeholder": "https://api.deepseek.com"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "deepseek-chat"}', 988),
    ('moonshot', 'Moonshot', 'Moonshot', 'openai_compat', 'https://api.moonshot.cn/v1', 'https://platform.moonshot.cn/docs/intro', '{"source": "builtin", "description": "Moonshot 是由北京月之暗面科技有限公司推出的开源平台，提供多种自然语言处理模型，应用领域广泛，包括但不限于内容创作、学术研究、智能推荐、医疗诊断等，支持长文本处理和复杂生成任务。", "modelsUrl": "https://platform.moonshot.cn/docs/intro", "url": "https://www.moonshot.cn", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://api.moonshot.cn/v1"}, "responseAnimation": {"speed": 2, "text": "smooth"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "kimi-latest"}', 987),
    ('aihubmix', 'AiHubMix', 'AiHubMix', 'openai_compat', NULL, 'https://docs.aihubmix.com/cn/api/Model-List', '{"source": "builtin", "description": "AiHubMix 通过统一的 API 接口提供对多种 AI 模型的访问。", "apiKeyUrl": "https://lobe.li/9mZhb4T", "modelsUrl": "https://docs.aihubmix.com/cn/api/Model-List", "url": "https://aihubmix.com?utm_source=lobehub", "settings": {"sdkType": "router", "showModelFetcher": true}, "checkModel": "gpt-4.1-nano"}', 986),
    ('openrouter', 'OpenRouter', 'OpenRouter', 'openai_compat', 'https://openrouter.ai/api/v1', 'https://openrouter.ai/models', '{"source": "builtin", "description": "OpenRouter 是一个提供多种前沿大模型接口的服务平台，支持 OpenAI、Anthropic、LLaMA 及更多，适合多样化的开发和应用需求。用户可根据自身需求灵活选择最优的模型和价格，助力AI体验的提升。", "modelsUrl": "https://openrouter.ai/models", "url": "https://openrouter.ai", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://openrouter.ai/api/v1"}, "sdkType": "openai", "searchMode": "params", "showModelFetcher": true}, "checkModel": "google/gemma-2-9b-it:free"}', 985),
    ('fal', 'Fal', 'Fal', 'openai_compat', NULL, 'https://fal.ai', '{"source": "builtin", "description": "面向开发者的生成式媒体平台", "url": "https://fal.ai", "settings": {"disableBrowserRequest": true, "showAddNewModel": false, "showChecker": false, "showModelFetcher": false}}', 984),
    ('huggingface', 'HuggingFace', 'HuggingFace', 'custom', NULL, 'https://huggingface.co/docs/api-inference/en/supported-models', '{"source": "builtin", "description": "HuggingFace Inference API 提供了一种快速且免费的方式，让您可以探索成千上万种模型，适用于各种任务。无论您是在为新应用程序进行原型设计，还是在尝试机器学习的功能，这个 API 都能让您即时访问多个领域的高性能模型。", "apiKeyUrl": "https://huggingface.co/settings/tokens", "modelsUrl": "https://huggingface.co/docs/api-inference/en/supported-models", "url": "https://huggingface.co", "settings": {"disableBrowserRequest": true, "sdkType": "huggingface", "showModelFetcher": true}, "checkModel": "mistralai/Mistral-7B-Instruct-v0.2"}', 983),
    ('cloudflare', 'Cloudflare Workers AI', 'Cloudflare Workers AI', 'custom', NULL, 'https://developers.cloudflare.com/workers-ai/models', '{"source": "builtin", "description": "在 Cloudflare 的全球网络上运行由无服务器 GPU 驱动的机器学习模型。", "url": "https://developers.cloudflare.com/workers-ai/models", "settings": {"disableBrowserRequest": true, "sdkType": "cloudflare", "showModelFetcher": true}, "checkModel": "@hf/meta-llama/meta-llama-3-8b-instruct"}', 982),
    ('github', 'GitHub', 'GitHub', 'azure', NULL, 'https://github.com/marketplace/models', '{"source": "builtin", "description": "通过GitHub模型，开发人员可以成为AI工程师，并使用行业领先的AI模型进行构建。", "url": "https://github.com/marketplace/models", "settings": {"sdkType": "azure", "showModelFetcher": true}, "checkModel": "microsoft/Phi-3-mini-4k-instruct"}', 981),
    ('newapi', 'New API', 'New API', 'openai_compat', 'https://your.new-api-provider.com', 'https://github.com/Calcium-Ion/new-api', '{"source": "builtin", "description": "开源的多个 AI 服务聚合统一转发平台", "url": "https://github.com/Calcium-Ion/new-api", "settings": {"proxyUrl": {"placeholder": "https://your.new-api-provider.com"}, "sdkType": "router", "showModelFetcher": true}, "checkModel": "gpt-4o-mini"}', 980),
    ('bfl', 'Black Forest Labs', 'Black Forest Labs', 'openai_compat', NULL, 'https://bfl.ai/', '{"source": "builtin", "description": "领先的前沿人工智能研究实验室，构建明日的视觉基础设施。", "url": "https://bfl.ai/", "settings": {"disableBrowserRequest": true, "showAddNewModel": false, "showChecker": false, "showModelFetcher": false}}', 979),
    ('novita', 'Novita', 'Novita', 'openai_compat', 'https://api.novita.ai/v3/openai', 'https://novita.ai/model-api/product/llm-api', '{"source": "builtin", "description": "Novita AI 是一个提供多种大语言模型与 AI 图像生成的 API 服务的平台，灵活、可靠且具有成本效益。它支持 Llama3、Mistral 等最新的开源模型，并为生成式 AI 应用开发提供了全面、用户友好且自动扩展的 API 解决方案，适合 AI 初创公司的快速发展。", "modelsUrl": "https://novita.ai/model-api/product/llm-api", "url": "https://novita.ai", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://api.novita.ai/v3/openai"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "meta-llama/llama-3.1-8b-instruct"}', 978),
    ('ppio', 'PPIO', 'PPIO', 'openai_compat', NULL, 'https://ppinfra.com/llm-api?utm_source=github_lobe-chat&utm_medium=github_readme&utm_campaign=link', '{"source": "builtin", "description": "PPIO 派欧云提供稳定、高性价比的开源模型 API 服务，支持 DeepSeek 全系列、Llama、Qwen 等行业领先大模型。", "modelsUrl": "https://ppinfra.com/llm-api?utm_source=github_lobe-chat&utm_medium=github_readme&utm_campaign=link", "url": "https://ppinfra.com/user/register?invited_by=RQIMOC&utm_source=github_lobechat", "settings": {"disableBrowserRequest": true, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "deepseek/deepseek-r1-distill-qwen-32b"}', 977),
    ('ai302', '302.AI', '302.AI', 'openai_compat', 'https://api.302.ai/v1', 'https://302.ai/pricing/', '{"source": "builtin", "description": "302.AI 是一个按需付费的 AI 应用平台，提供市面上最全的 AI API 和 AI 在线应用", "apiKeyUrl": "https://lobe.li/Oizw5sN", "modelsUrl": "https://302.ai/pricing/", "url": "https://302.ai", "settings": {"proxyUrl": {"placeholder": "https://api.302.ai/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "gpt-4o"}', 976),
    ('nvidia', 'Nvidia', 'Nvidia', 'openai_compat', 'https://integrate.api.nvidia.com/v1', 'https://build.nvidia.com/models', '{"source": "builtin", "description": "NVIDIA NIM™ 提供容器，可用于自托管 GPU 加速推理微服务，支持在云端、数据中心、RTX™ AI 个人电脑和工作站上部署预训练和自定义 AI 模型。", "modelsUrl": "https://build.nvidia.com/models", "url": "https://build.nvidia.com", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://integrate.api.nvidia.com/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "meta/llama-3.2-1b-instruct"}', 975),
    ('togetherai', 'Together AI', 'Together AI', 'openai_compat', 'https://api.together.xyz/v1', 'https://docs.together.ai/docs/chat-models', '{"source": "builtin", "description": "Together AI 致力于通过创新的 AI 模型实现领先的性能，提供广泛的自定义能力，包括快速扩展支持和直观的部署流程，满足企业的各种需求。", "modelsUrl": "https://docs.together.ai/docs/chat-models", "url": "https://www.together.ai", "settings": {"proxyUrl": {"placeholder": "https://api.together.xyz/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "meta-llama/Llama-Vision-Free"}', 974),
    ('fireworksai', 'Fireworks AI', 'Fireworks AI', 'openai_compat', 'https://api.fireworks.ai/inference/v1', 'https://fireworks.ai/models?show=Serverless', '{"source": "builtin", "description": "Fireworks AI 是一家领先的高级语言模型服务商，专注于功能调用和多模态处理。其最新模型 Firefunction V2 基于 Llama-3，优化用于函数调用、对话及指令跟随。视觉语言模型 FireLLaVA-13B 支持图像和文本混合输入。其他 notable 模型包括 Llama 系列和 Mixtral 系列，提供高效的多语言指令跟随与生成支持。", "modelsUrl": "https://fireworks.ai/models?show=Serverless", "url": "https://fireworks.ai", "settings": {"proxyUrl": {"placeholder": "https://api.fireworks.ai/inference/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "accounts/fireworks/models/llama-v3p2-3b-instruct"}', 973),
    ('groq', 'Groq', 'Groq', 'openai_compat', 'https://api.groq.com/openai/v1', 'https://console.groq.com/docs/models', '{"source": "builtin", "description": "Groq 的 LPU 推理引擎在最新的独立大语言模型（LLM）基准测试中表现卓越，以其惊人的速度和效率重新定义了 AI 解决方案的标准。Groq 是一种即时推理速度的代表，在基于云的部署中展现了良好的性能。", "modelsUrl": "https://console.groq.com/docs/models", "url": "https://groq.com", "settings": {"proxyUrl": {"placeholder": "https://api.groq.com/openai/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "llama-3.1-8b-instant"}', 972),
    ('perplexity', 'Perplexity', 'Perplexity', 'openai_compat', 'https://api.perplexity.ai', 'https://docs.perplexity.ai/guides/model-cards', '{"source": "builtin", "description": "Perplexity 是一家领先的对话生成模型提供商，提供多种先进的Llama 3.1模型，支持在线和离线应用，特别适用于复杂的自然语言处理任务。", "modelsUrl": "https://docs.perplexity.ai/guides/model-cards", "url": "https://www.perplexity.ai", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://api.perplexity.ai"}, "responseAnimation": {"speed": 2, "text": "smooth"}, "sdkType": "openai"}, "checkModel": "sonar"}', 971),
    ('mistral', 'Mistral', 'Mistral', 'openai_compat', 'https://api.mistral.ai', 'https://docs.mistral.ai/getting-started/models', '{"source": "builtin", "description": "Mistral 提供先进的通用、专业和研究型模型，广泛应用于复杂推理、多语言任务、代码生成等领域，通过功能调用接口，用户可以集成自定义功能，实现特定应用。", "modelsUrl": "https://docs.mistral.ai/getting-started/models", "url": "https://mistral.ai", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://api.mistral.ai"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "ministral-3b-latest"}', 970),
    ('modelscope', 'ModelScope', 'ModelScope', 'openai_compat', 'https://api-inference.modelscope.cn/v1', 'https://modelscope.cn', '{"source": "builtin", "description": "ModelScope是阿里云推出的模型即服务平台，提供丰富的AI模型和推理服务。", "url": "https://modelscope.cn", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://api-inference.modelscope.cn/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "Qwen/Qwen3-4B"}', 969),
    ('ai21', 'Ai21Labs', 'Ai21Labs', 'openai_compat', NULL, 'https://docs.ai21.com/reference', '{"source": "builtin", "description": "AI21 Labs 为企业构建基础模型和人工智能系统，加速生成性人工智能在生产中的应用。", "modelsUrl": "https://docs.ai21.com/reference", "url": "https://studio.ai21.com", "settings": {"sdkType": "openai"}, "checkModel": "jamba-mini"}', 968),
    ('upstage', 'Upstage', 'Upstage', 'openai_compat', 'https://api.upstage.ai/v1/solar', 'https://developers.upstage.ai/docs/getting-started/models', '{"source": "builtin", "description": "Upstage 专注于为各种商业需求开发AI模型，包括 Solar LLM 和文档 AI，旨在实现工作的人造通用智能（AGI）。通过 Chat API 创建简单的对话代理，并支持功能调用、翻译、嵌入以及特定领域应用。", "modelsUrl": "https://developers.upstage.ai/docs/getting-started/models", "url": "https://upstage.ai", "settings": {"proxyUrl": {"placeholder": "https://api.upstage.ai/v1/solar"}, "sdkType": "openai"}, "checkModel": "solar-1-mini-chat"}', 967),
    ('xai', 'xAI (Grok)', 'xAI (Grok)', 'openai_compat', 'https://api.x.ai/v1', 'https://docs.x.ai/docs#models', '{"source": "builtin", "description": "xAI 是一家致力于构建人工智能以加速人类科学发现的公司。我们的使命是推动我们对宇宙的共同理解。", "modelsUrl": "https://docs.x.ai/docs#models", "url": "https://x.ai/api", "settings": {"proxyUrl": {"placeholder": "https://api.x.ai/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "grok-2-1212"}', 966),
    ('jina', 'Jina AI', 'Jina AI', 'openai_compat', 'https://deepsearch.jina.ai/v1', 'https://jina.ai/models', '{"source": "builtin", "description": "Jina AI 成立于 2020 年，是一家领先的搜索 AI 公司。我们的搜索底座平台包含了向量模型、重排器和小语言模型，可帮助企业构建可靠且高质量的生成式AI和多模态的搜索应用。", "modelsUrl": "https://jina.ai/models", "url": "https://jina.ai", "settings": {"proxyUrl": {"placeholder": "https://deepsearch.jina.ai/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "jina-deepsearch-v1"}', 965),
    ('sambanova', 'SambaNova', 'SambaNova', 'openai_compat', 'https://api.sambanova.ai/v1', 'https://cloud.sambanova.ai/plans/pricing', '{"source": "builtin", "description": "SambaNova Cloud 可让开发者轻松使用最佳的开源模型，并享受最快的推理速度。", "modelsUrl": "https://cloud.sambanova.ai/plans/pricing", "url": "https://cloud.sambanova.ai", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://api.sambanova.ai/v1"}, "sdkType": "openai"}, "checkModel": "Meta-Llama-3.2-1B-Instruct"}', 964),
    ('cohere', 'Cohere', 'Cohere', 'openai_compat', 'https://api.cohere.ai/compatibility/v1', 'https://docs.cohere.com/v2/docs/models', '{"source": "builtin", "description": "Cohere 为您带来最前沿的多语言模型、先进的检索功能以及为现代企业量身定制的 AI 工作空间 — 一切都集成在一个安全的平台中。", "modelsUrl": "https://docs.cohere.com/v2/docs/models", "url": "https://cohere.com", "settings": {"proxyUrl": {"placeholder": "https://api.cohere.ai/compatibility/v1"}, "sdkType": "openai"}, "checkModel": "command-r7b-12-2024"}', 963),
    ('v0', 'Vercel (v0)', 'Vercel (v0)', 'openai_compat', NULL, 'https://vercel.com/docs/v0/api#models', '{"source": "builtin", "description": "v0 是一个配对编程助手，你只需用自然语言描述想法，它就能为你的项目生成代码和用户界面（UI）", "modelsUrl": "https://vercel.com/docs/v0/api#models", "url": "https://v0.dev", "settings": {"disableBrowserRequest": true, "sdkType": "openai"}, "checkModel": "v0-1.5-md"}', 962),
    ('qwen', 'Aliyun Bailian', 'Aliyun Bailian', 'openai_compat', 'https://dashscope.aliyuncs.com/compatible-mode/v1', 'https://help.aliyun.com/zh/dashscope/developer-reference/api-details', '{"source": "builtin", "description": "通义千问是阿里云自主研发的超大规模语言模型，具有强大的自然语言理解和生成能力。它可以回答各种问题、创作文字内容、表达观点看法、撰写代码等，在多个领域发挥作用。", "modelsUrl": "https://help.aliyun.com/zh/dashscope/developer-reference/api-details", "url": "https://www.aliyun.com/product/bailian", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://dashscope.aliyuncs.com/compatible-mode/v1"}, "responseAnimation": {"speed": 2, "text": "smooth"}, "sdkType": "openai", "showDeployName": true, "showModelFetcher": true}, "checkModel": "qwen-flash"}', 961),
    ('wenxin', 'Wenxin', 'Wenxin', 'openai_compat', 'https://qianfan.baidubce.com/v2', 'https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Nlks5zkzu#%E5%AF%B9%E8%AF%9Dchat', '{"source": "builtin", "description": "企业级一站式大模型与AI原生应用开发及服务平台，提供最全面易用的生成式人工智能模型开发、应用开发全流程工具链", "modelsUrl": "https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Nlks5zkzu#%E5%AF%B9%E8%AF%9Dchat", "url": "https://cloud.baidu.com/wenxin.html", "settings": {"proxyUrl": {"placeholder": "https://qianfan.baidubce.com/v2"}, "responseAnimation": {"speed": 2, "text": "smooth"}, "sdkType": "openai"}, "checkModel": "ernie-speed-128k"}', 960),
    ('tencentcloud', 'TencentCloud', 'TencentCloud', 'openai_compat', 'https://api.lkeap.cloud.tencent.com/v1', 'https://cloud.tencent.com/document/api/1772/115963', '{"source": "builtin", "description": "知识引擎原子能力（LLM Knowledge Engine Atomic Power）基于知识引擎研发的知识问答全链路能力，面向企业及开发者，提供灵活组建及开发模型应用的能力。您可通过多款原子能力组建您专属的模型服务，调用文档解析、拆分、embedding、多轮改写等服务进行组装，定制企业专属 AI 业务。", "modelsUrl": "https://cloud.tencent.com/document/api/1772/115963", "url": "https://cloud.tencent.com/document/api/1772/115365", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://api.lkeap.cloud.tencent.com/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "deepseek-v3"}', 959),
    ('hunyuan', 'Hunyuan', 'Hunyuan', 'openai_compat', 'https://api.hunyuan.cloud.tencent.com/v1', 'https://cloud.tencent.com/document/product/1729/104753', '{"source": "builtin", "description": "由腾讯研发的大语言模型，具备强大的中文创作能力，复杂语境下的逻辑推理能力，以及可靠的任务执行能力", "modelsUrl": "https://cloud.tencent.com/document/product/1729/104753", "url": "https://hunyuan.tencent.com", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://api.hunyuan.cloud.tencent.com/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "hunyuan-lite"}', 958),
    ('zhipu', 'ZhiPu', 'ZhiPu', 'openai_compat', 'https://open.bigmodel.cn/api/paas/v4', 'https://open.bigmodel.cn/dev/howuse/model', '{"source": "builtin", "description": "智谱 AI 提供多模态与语言模型的开放平台，支持广泛的AI应用场景，包括文本处理、图像理解与编程辅助等。", "modelsUrl": "https://open.bigmodel.cn/dev/howuse/model", "url": "https://zhipuai.cn", "settings": {"proxyUrl": {"placeholder": "https://open.bigmodel.cn/api/paas/v4"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "glm-4.5-flash"}', 957),
    ('siliconcloud', 'SiliconCloud', 'SiliconCloud', 'openai_compat', 'https://api.siliconflow.cn/v1', 'https://siliconflow.cn/zh-cn/models', '{"source": "builtin", "description": "SiliconCloud，基于优秀开源基础模型的高性价比 GenAI 云服务", "modelsUrl": "https://siliconflow.cn/zh-cn/models", "url": "https://siliconflow.cn/zh-cn/siliconcloud", "settings": {"proxyUrl": {"placeholder": "https://api.siliconflow.cn/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "Pro/Qwen/Qwen2-7B-Instruct"}', 956),
    ('zeroone', '01.AI', '01.AI', 'openai_compat', 'https://api.lingyiwanwu.com/v1', 'https://platform.lingyiwanwu.com/docs#模型与计费', '{"source": "builtin", "description": "零一万物致力于推动以人为本的AI 2.0技术革命，旨在通过大语言模型创造巨大的经济和社会价值，并开创新的AI生态与商业模式。", "modelsUrl": "https://platform.lingyiwanwu.com/docs#模型与计费", "url": "https://www.lingyiwanwu.com/", "settings": {"proxyUrl": {"placeholder": "https://api.lingyiwanwu.com/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "yi-lightning"}', 955),
    ('spark', 'Spark', 'Spark', 'openai_compat', 'https://spark-api-open.xf-yun.com/v1', 'https://xinghuo.xfyun.cn/spark', '{"source": "builtin", "description": "科大讯飞星火大模型提供多领域、多语言的强大 AI 能力，利用先进的自然语言处理技术，构建适用于智能硬件、智慧医疗、智慧金融等多种垂直场景的创新应用。", "modelsUrl": "https://xinghuo.xfyun.cn/spark", "url": "https://www.xfyun.cn", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://spark-api-open.xf-yun.com/v1"}, "responseAnimation": {"speed": 2, "text": "smooth"}, "sdkType": "openai", "showModelFetcher": false}, "checkModel": "lite"}', 954),
    ('sensenova', 'SenseNova', 'SenseNova', 'openai_compat', 'https://api.sensenova.cn/compatible-mode/v1', 'https://platform.sensenova.cn/pricing', '{"source": "builtin", "description": "商汤日日新，依托商汤大装置的强大的基础支撑，提供高效易用的全栈大模型服务。", "modelsUrl": "https://platform.sensenova.cn/pricing", "url": "https://platform.sensenova.cn/home", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://api.sensenova.cn/compatible-mode/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "SenseChat-Turbo"}', 953),
    ('stepfun', 'Stepfun', 'Stepfun', 'openai_compat', 'https://api.stepfun.com/v1', 'https://platform.stepfun.com/docs/llm/text', '{"source": "builtin", "description": "阶级星辰大模型具备行业领先的多模态及复杂推理能力，支持超长文本理解和强大的自主调度搜索引擎功能。", "modelsUrl": "https://platform.stepfun.com/docs/llm/text", "url": "https://stepfun.com", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://api.stepfun.com/v1"}, "responseAnimation": {"speed": 2, "text": "smooth"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "step-2-mini"}', 952),
    ('baichuan', 'Baichuan', 'Baichuan', 'openai_compat', 'https://api.baichuan-ai.com/v1', 'https://platform.baichuan-ai.com/price', '{"source": "builtin", "description": "百川智能是一家专注于人工智能大模型研发的公司，其模型在国内知识百科、长文本处理和生成创作等中文任务上表现卓越，超越了国外主流模型。百川智能还具备行业领先的多模态能力，在多项权威评测中表现优异。其模型包括 Baichuan 4、Baichuan 3 Turbo 和 Baichuan 3 Turbo 128k 等，分别针对不同应用场景进行优化，提供高性价比的解决方案。", "modelsUrl": "https://platform.baichuan-ai.com/price", "url": "https://platform.baichuan-ai.com", "settings": {"proxyUrl": {"placeholder": "https://api.baichuan-ai.com/v1"}, "responseAnimation": {"speed": 2, "text": "smooth"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "Baichuan3-Turbo"}', 951),
    ('volcengine', 'Volcengine', 'Volcengine', 'openai_compat', 'https://ark.cn-beijing.volces.com/api/v3', 'https://www.volcengine.com/docs/82379/1330310', '{"source": "builtin", "description": "字节跳动推出的大模型服务的开发平台，提供功能丰富、安全以及具备价格竞争力的模型调用服务，同时提供模型数据、精调、推理、评测等端到端功能，全方位保障您的 AI 应用开发落地。", "modelsUrl": "https://www.volcengine.com/docs/82379/1330310", "url": "https://www.volcengine.com/product/ark", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://ark.cn-beijing.volces.com/api/v3"}, "responseAnimation": {"speed": 2, "text": "smooth"}, "sdkType": "openai", "showDeployName": true}, "checkModel": "doubao-1-5-lite-32k-250115"}', 950),
    ('minimax', 'Minimax', 'Minimax', 'openai_compat', 'https://api.minimax.chat/v1', 'https://platform.minimaxi.com/document/Models', '{"source": "builtin", "description": "MiniMax 是 2021 年成立的通用人工智能科技公司，致力于与用户共创智能。MiniMax 自主研发了不同模态的通用大模型，其中包括万亿参数的 MoE 文本大模型、语音大模型以及图像大模型。并推出了海螺 AI 等应用。", "modelsUrl": "https://platform.minimaxi.com/document/Models", "url": "https://www.minimaxi.com", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://api.minimax.chat/v1"}, "responseAnimation": {"speed": 2, "text": "smooth"}, "sdkType": "openai"}, "checkModel": "MiniMax-M2"}', 949),
    ('lmstudio', 'LM Studio', 'LM Studio', 'openai_compat', 'http://127.0.0.1:1234/v1', 'https://lmstudio.ai/models', '{"source": "builtin", "description": "LM Studio 是一个用于在您的计算机上开发和实验 LLMs 的桌面应用程序。", "modelsUrl": "https://lmstudio.ai/models", "url": "https://lmstudio.ai", "settings": {"defaultShowBrowserRequest": true, "proxyUrl": {"placeholder": "http://127.0.0.1:1234/v1"}, "responseAnimation": {"speed": 2, "text": "smooth"}, "showApiKey": false, "showModelFetcher": true}}', 948),
    ('internlm', 'InternLM', 'InternLM', 'openai_compat', 'https://internlm-chat.intern-ai.org.cn/puyu/api/v1', 'https://internlm.intern-ai.org.cn/doc/docs/Models#%E8%8E%B7%E5%8F%96%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8', '{"source": "builtin", "description": "致力于大模型研究与开发工具链的开源组织。为所有 AI 开发者提供高效、易用的开源平台，让最前沿的大模型与算法技术触手可及", "modelsUrl": "https://internlm.intern-ai.org.cn/doc/docs/Models#%E8%8E%B7%E5%8F%96%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8", "url": "https://internlm.intern-ai.org.cn", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://internlm-chat.intern-ai.org.cn/puyu/api/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "internlm2.5-latest"}', 947),
    ('higress', 'Higress', 'Higress', 'openai_compat', 'https://127.0.0.1:8080/v1', 'https://higress.cn/', '{"source": "builtin", "description": "Higress 是一款云原生 API 网关，在阿里内部为解决 Tengine reload 对长连接业务有损，以及 gRPC/Dubbo 负载均衡能力不足而诞生。", "modelsUrl": "https://higress.cn/", "url": "https://apig.console.aliyun.com/", "settings": {"proxyUrl": {"desc": "输入Higress AI Gateway的访问地址", "placeholder": "https://127.0.0.1:8080/v1", "title": "AI Gateway地址"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "qwen-max"}', 946),
    ('giteeai', 'Gitee AI', 'Gitee AI', 'openai_compat', 'https://ai.gitee.com/v1', 'https://ai.gitee.com/docs/openapi/v1#tag/serverless/POST/chat/completions', '{"source": "builtin", "description": "Gitee AI 的 Serverless API 为 AI 开发者提供开箱即用的大模型推理 API 服务。", "modelsUrl": "https://ai.gitee.com/docs/openapi/v1#tag/serverless/POST/chat/completions", "url": "https://ai.gitee.com", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://ai.gitee.com/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "Qwen2.5-72B-Instruct"}', 945),
    ('taichu', 'Taichu', 'Taichu', 'openai_compat', 'https://ai-maas.wair.ac.cn/maas/v1', 'https://ai-maas.wair.ac.cn/#/doc', '{"source": "builtin", "description": "中科院自动化研究所和武汉人工智能研究院推出新一代多模态大模型，支持多轮问答、文本创作、图像生成、3D理解、信号分析等全面问答任务，拥有更强的认知、理解、创作能力，带来全新互动体验。", "modelsUrl": "https://ai-maas.wair.ac.cn/#/doc", "url": "https://ai-maas.wair.ac.cn", "settings": {"proxyUrl": {"placeholder": "https://ai-maas.wair.ac.cn/maas/v1"}, "sdkType": "openai"}, "checkModel": "taichu_llm"}', 944),
    ('ai360', '360 AI', '360 AI', 'openai_compat', NULL, 'https://ai.360.cn/platform/docs/overview', '{"source": "builtin", "description": "360 AI 是 360 公司推出的 AI 模型和服务平台，提供多种先进的自然语言处理模型，包括 360GPT2 Pro、360GPT Pro、360GPT Turbo 和 360GPT Turbo Responsibility 8K。这些模型结合了大规模参数和多模态能力，广泛应用于文本生成、语义理解、对话系统与代码生成等领域。通过灵活的定价策略，360 AI 满足多样化用户需求，支持开发者集成，推动智能化应用的革新和发展。", "modelsUrl": "https://ai.360.cn/platform/docs/overview", "url": "https://ai.360.com", "settings": {"disableBrowserRequest": true, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "360gpt-turbo"}', 943),
    ('search1api', 'Search1API', 'Search1API', 'openai_compat', 'https://api.search1api.com/v1', 'https://www.search1api.com', '{"source": "builtin", "description": "Search1API 提供可根据需要自行联网的 DeepSeek 系列模型的访问，包括标准版和快速版本，支持多种参数规模的模型选择。", "url": "https://www.search1api.com", "settings": {"proxyUrl": {"placeholder": "https://api.search1api.com/v1"}, "responseAnimation": {"speed": 2, "text": "smooth"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "deepseek-r1-70b-fast-online"}', 942),
    ('infiniai', 'InfiniAI', 'InfiniAI', 'openai_compat', 'https://cloud.infini-ai.com/maas/v1', 'https://cloud.infini-ai.com/genstudio/model', '{"source": "builtin", "description": "为应用开发者提供高性能、易上手、安全可靠的大模型服务，覆盖从大模型开发到大模型服务化部署的全流程。", "modelsUrl": "https://cloud.infini-ai.com/genstudio/model", "url": "https://cloud.infini-ai.com/genstudio", "settings": {"disableBrowserRequest": true, "proxyUrl": {"placeholder": "https://cloud.infini-ai.com/maas/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "qwen3-8b"}', 941),
    ('akashchat', 'AkashChat', 'AkashChat', 'openai_compat', NULL, 'https://chatapi.akash.network/documentation', '{"source": "builtin", "description": "Akash 是一个无需许可的云资源市场，与传统云提供商相比，其定价具有竞争力。", "modelsUrl": "https://chatapi.akash.network/documentation", "url": "https://chatapi.akash.network/", "settings": {"sdkType": "openai", "showModelFetcher": true}, "checkModel": "Meta-Llama-3-1-8B-Instruct-FP8"}', 940),
    ('qiniu', 'Qiniu', 'Qiniu', 'openai_compat', 'https://api.qnaigc.com/v1', 'https://developer.qiniu.com/aitokenapi/12882/ai-inference-api', '{"source": "builtin", "description": "七牛作为老牌云服务厂商，提供高性价比稳定的实时、批量 AI 推理服务，简单易用。", "modelsUrl": "https://developer.qiniu.com/aitokenapi/12882/ai-inference-api", "url": "https://www.qiniu.com", "settings": {"proxyUrl": {"placeholder": "https://api.qnaigc.com/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "deepseek-r1"}', 939),
    ('nebius', 'Nebius', 'Nebius', 'openai_compat', 'https://api.studio.nebius.com/v1', 'https://studio.nebius.com/', '{"source": "builtin", "description": "Nebius 通过构建大规模GPU集群和垂直整合的云平台，为全球AI创新者提供高性能基础设施。", "modelsUrl": "https://studio.nebius.com/", "url": "https://nebius.com/", "settings": {"proxyUrl": {"placeholder": "https://api.studio.nebius.com/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "Qwen/Qwen2.5-Coder-7B"}', 938),
    ('cometapi', 'CometAPI', 'CometAPI', 'openai_compat', 'https://api.cometapi.com/v1', 'https://api.cometapi.com/v1/models', '{"source": "builtin", "description": "CometAPI 是一个提供多种前沿大模型接口的服务平台，支持 OpenAI、Anthropic、Google 及更多，适合多样化的开发和应用需求。用户可根据自身需求灵活选择最优的模型和价格，助力AI体验的提升。", "modelsUrl": "https://api.cometapi.com/v1/models", "url": "https://cometapi.com", "settings": {"proxyUrl": {"placeholder": "https://api.cometapi.com/v1"}, "sdkType": "openai", "showModelFetcher": true}, "checkModel": "gpt-5-mini"}', 937),
    ('vercelaigateway', 'Vercel AI Gateway', 'Vercel AI Gateway', 'openai_compat', NULL, 'https://vercel.com/ai-gateway/models', '{"source": "builtin", "description": "Vercel AI Gateway 提供统一的 API 来访问 100+ 模型，通过单一端点即可使用 OpenAI、Anthropic、Google 等多个提供商的模型。支持预算设置、使用监控、请求负载均衡和故障转移。", "apiKeyUrl": "https://vercel.com/dashboard/ai-gateway", "modelsUrl": "https://vercel.com/ai-gateway/models", "url": "https://vercel.com/ai-gateway", "settings": {"disableBrowserRequest": true, "responseAnimation": "smooth", "showModelFetcher": true}, "checkModel": "openai/gpt-5-nano"}', 936),
    ('cerebras', 'Cerebras', 'Cerebras', 'openai_compat', NULL, 'https://inference-docs.cerebras.ai/models/overview', '{"source": "builtin", "description": "Cerebras 是一个基于其专用 CS-3 系统的 AI 推理平台，旨在提供全球最快、实时响应、高吞吐量的 LLM 服务，专为消除延迟和加速复杂的 AI 工作流（如实时代码生成和代理任务）而设计。", "modelsUrl": "https://inference-docs.cerebras.ai/models/overview", "url": "https://cerebras.ai", "settings": {"sdkType": "openai", "showModelFetcher": true}, "checkModel": "llama3.1-8b"}', 935),
    ('lobehub', 'LobeHub', 'LobeHub', 'openai_compat', NULL, 'https://lobehub.com/zh/docs/usage/subscription/model-pricing', '{"source": "builtin", "description": "LobeHub Cloud 通过官方部署的 API 来实现 AI 模型的调用，并采用 Credits 计算积分的方式来衡量 AI 模型的用量，对应大模型使用的 Tokens。", "modelsUrl": "https://lobehub.com/zh/docs/usage/subscription/model-pricing", "url": "https://lobehub.com", "settings": {"modelEditable": false, "showAddNewModel": false, "showModelFetcher": false}}', 934),
    ('openai_compat', 'OpenAI Compatible', '兼容接口', 'openai_compat', NULL, NULL, '{"chat": true, "embedding": true}', 10)
ON CONFLICT (code) DO NOTHING;

-- Part 2: Models (full seed from V2_11)
INSERT INTO ai_models (provider_id, model_id, display_name, model_type, context_window, max_output_tokens, input_cost_per_1k, output_cost_per_1k, capabilities, is_enabled) VALUES
    -- ai21
    ((SELECT id FROM ai_providers WHERE code = 'ai21'), 'jamba-mini', 'Jamba Mini', 'chat', 256000, NULL, 0.0002, 0.0004, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-06", "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "在同级别中最高效的模型，兼顾速度与质量，具备更小的体积。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai21'), 'jamba-large', 'Jamba Large', 'chat', 256000, NULL, 0.002, 0.008, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-06", "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "我们最强大、最先进的模型，专为处理企业级复杂任务而设计，具备卓越的性能。", "function_calling": true}', TRUE),
    -- ai302
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'deepseek-chat', 'deepseek-chat', 'chat', 32000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'chatgpt-4o-latest', 'chatgpt-4o-latest', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'llama3.3-70b', 'llama3.3-70b', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'deepseek-reasoner', 'deepseek-reasoner', 'chat', 64000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'gemini-2.0-flash', 'gemini-2.0-flash', 'chat', 1000000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'claude-3-7-sonnet-20250219', 'claude-3-7-sonnet-20250219', 'chat', 200000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'claude-3-7-sonnet-latest', 'claude-3-7-sonnet-latest', 'chat', 200000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'grok-3-beta', 'grok-3-beta', 'chat', 131072, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'grok-3-mini-beta', 'grok-3-mini-beta', 'chat', 131072, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'gpt-4.1', 'gpt-4.1', 'chat', 1000000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'o3', 'o3', 'chat', 200000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'o4-mini', 'o4-mini', 'chat', 200000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'qwen3-235b-a22b', 'qwen3-235b-a22b', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'qwen3-32b', 'qwen3-32b', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'gemini-2.5-pro-preview-05-06', 'gemini-2.5-pro-preview-05-06', 'chat', 1000000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'llama-4-maverick', 'llama-4-maverick', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'gemini-2.5-flash', 'gemini-2.5-flash', 'chat', 1000000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'claude-sonnet-4-20250514', 'claude-sonnet-4-20250514', 'chat', 200000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'claude-opus-4-20250514', 'claude-opus-4-20250514', 'chat', 200000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai302'), 'gemini-2.5-pro', 'gemini-2.5-pro', 'chat', 1000000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000}', TRUE),
    -- ai360
    ((SELECT id FROM ai_providers WHERE code = 'ai360'), '360zhinao2-o1', '360Zhinao2 o1', 'chat', 8000, NULL, 0.004, 0.01, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "360zhinao2-o1 使用树搜索构建思维链，并引入了反思机制，使用强化学习训练，模型具备自我反思与纠错的能力。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai360'), '360gpt2-o1', '360GPT2 o1', 'chat', 8000, NULL, 0.004, 0.01, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "360gpt2-o1 使用树搜索构建思维链，并引入了反思机制，使用强化学习训练，模型具备自我反思与纠错的能力。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ai360'), '360gpt2-pro', '360GPT2 Pro', 'chat', 8000, NULL, 0.002, 0.005, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "360智脑系列效果最好的主力千亿级大模型，广泛适用于各领域复杂任务场景。", "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai360'), '360gpt-pro', '360GPT Pro', 'chat', 8000, NULL, 0.002, 0.005, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "360智脑系列效果最好的主力千亿级大模型，广泛适用于各领域复杂任务场景。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ai360'), '360gpt-pro-trans', '360GPT Pro Trans', 'chat', 16000, NULL, 0.002, 0.005, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "description": "翻译专用模型，深度微调优化，翻译效果领先。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ai360'), '360gpt-turbo', '360GPT Turbo', 'chat', 7000, NULL, 0.001, 0.002, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 7000, "contextWindowTokens": 7000, "description": "兼顾性能和效果的百亿级大模型，适合对性能/成本要求较高 的场景。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ai360'), '360/deepseek-r1', 'DeepSeek R1', 'chat', 64000, NULL, 0.004, 0.016, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "description": "【360部署版】DeepSeek-R1在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能比肩 OpenAI o1 正式版。", "reasoning": true}', FALSE),
    -- aihubmix
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'gpt-5-pro', 'GPT-5 pro', 'chat', 400000, 272000, 0.015, 0.12, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["textVerbosity"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 120, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-10-06", "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 272000, "maxOutput": 272000, "description": "GPT-5 pro 使用更多计算来更深入地思考，并持续提供更好的答案。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'gpt-5-codex', 'GPT-5 Codex', 'chat', 400000, 128000, 0.00125, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["gpt5ReasoningEffort", "textVerbosity"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.125, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-15", "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 128000, "maxOutput": 128000, "description": "GPT-5 Codex 是一个针对 Codex 或类似环境中的代理编码任务优化的 GPT-5 版本。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'gpt-5', 'GPT-5', 'chat', 400000, 128000, 0.00125, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "structuredOutput": true, "vision": true}, "settings": {"extendParams": ["gpt5ReasoningEffort", "textVerbosity"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.125, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-07", "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 128000, "maxOutput": 128000, "description": "跨领域编码和代理任务的最佳模型。GPT-5 在准确性、速度、推理、上下文识别、结构化思维和问题解决方面实现了飞跃。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'gpt-5-mini', 'GPT-5 mini', 'chat', 400000, 128000, 0.00025, 0.002, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "structuredOutput": true, "vision": true}, "settings": {"extendParams": ["gpt5ReasoningEffort", "textVerbosity"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-07", "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 128000, "maxOutput": 128000, "description": "更快、更经济高效的 GPT-5 版本，适用于明确定义的任务。在保持高质量输出的同时，提供更快的响应速度。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'gpt-5-nano', 'GPT-5 nano', 'chat', 400000, 128000, 0.00005, 0.0004, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["gpt5ReasoningEffort", "textVerbosity"]}, "pricing": {"units": [{"name": "textInput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.01, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-07", "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 128000, "maxOutput": 128000, "description": "最快、最经济高效的 GPT-5 版本。非常适合需要快速响应且成本敏感的应用场景。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'gpt-5-chat-latest', 'GPT-5 Chat', 'chat', 400000, 128000, 0.00125, 0.01, '{"abilities": {"reasoning": true, "structuredOutput": false, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.125, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-07", "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 128000, "maxOutput": 128000, "description": "ChatGPT 中使用的 GPT-5 模型。结合了强大的语言理解与生成能力，适合对话式交互应用。", "vision": true, "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'o4-mini', 'o4-mini', 'chat', 200000, 100000, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.275, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o4-mini 是我们最新的小型 o 系列模型。 它专为快速有效的推理而优化，在编码和视觉任务中表现出极高的效率和性能。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'o4-mini-deep-research', 'o4-mini Deep Research', 'chat', 200000, 100000, 0.002, 0.008, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-26", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o4-mini-deep-research 是我们更快速、更实惠的深度研究模型——非常适合处理复杂的多步骤研究任务。它可以从互联网上搜索和综合信息，也可以通过 MCP 连接器访问并利用你的自有数据。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'o3-pro', 'o3-pro', 'chat', 200000, 100000, 0.02, 0.08, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 80, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-10", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3-pro 模型使用更多的计算来更深入地思考并始终提供更好的答案，仅支持 Responses API 下使用。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'o3', 'o3', 'chat', 200000, 100000, 0.002, 0.008, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-16", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3 是一款全能强大的模型，在多个领域表现出色。它为数学、科学、编程和视觉推理任务树立了新标杆。它也擅长技术写作和指令遵循。用户可利用它分析文本、代码和图像，解决多步骤的复杂问题。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'o3-deep-research', 'o3 Deep Research', 'chat', 200000, 100000, 0.01, 0.04, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 40, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-26", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3-deep-research 是我们最先进的深度研究模型，专为处理复杂的多步骤研究任务而设计。它可以从互联网上搜索和综合信息，也可以通过 MCP 连接器访问并利用你的自有数据。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'gpt-4.1', 'GPT-4.1', 'chat', 1047576, 32768, 0.002, 0.008, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 是我们用于复杂任务的旗舰模型。它非常适合跨领域解决问题。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'gpt-4.1-mini', 'GPT-4.1 mini', 'chat', 1047576, 32768, 0.0004, 0.0016, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 mini 提供了智能、速度和成本之间的平衡，使其成为许多用例中有吸引力的模型。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'gpt-4.1-nano', 'GPT-4.1 nano', 'chat', 1047576, 32768, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 nano 是最快，最具成本效益的GPT-4.1模型。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'chatgpt-4o-latest', 'ChatGPT-4o', 'chat', 128000, NULL, 0.005, 0.015, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'grok-4-fast-non-reasoning', 'Grok 4 Fast (Non-Reasoning)', 'chat', 2000000, NULL, 0.0002, 0.0005, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-09", "source": "builtin", "maxToken": 2000000, "contextWindowTokens": 2000000, "description": "我们很高兴发布 Grok 4 Fast，这是我们在成本效益推理模型方面的最新进展。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'grok-4-fast-reasoning', 'Grok 4 Fast', 'chat', 2000000, NULL, 0.0002, 0.0005, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-09", "source": "builtin", "maxToken": 2000000, "contextWindowTokens": 2000000, "description": "我们很高兴发布 Grok 4 Fast，这是我们在成本效益推理模型方面的最新进展。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'grok-4', 'Grok 4 0709', 'chat', 256000, NULL, 0.0033, 0.0165, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 3.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-09", "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "Grok最新旗舰模型，在自然语言、数学和推理方面提供了无与伦比的性能——堪称完美的‘多面手’。 当前指向模型版本为grok-4-0709；注意该模型由于资源有限暂时比官方贵 10% 预计后续会降至官方原价。", "vision": true, "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'grok-3', 'Grok 3', 'chat', 131072, NULL, 0.003, 0.015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.75, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-03", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "旗舰级模型，擅长数据提取、编程和文本摘要等企业级应用，拥有金融、医疗、法律和科学等领域的深厚知识。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'grok-3-mini', 'Grok 3 Mini', 'chat', 131072, NULL, 0.0003, 0.0005, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["reasoningEffort"]}, "pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-03", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "轻量级模型，回话前会先思考。运行快速、智能，适用于不需要深层领域知识的逻辑任务，并能获取原始的思维轨迹。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'claude-opus-4-1-20250805', 'Claude Opus 4.1', 'chat', 200000, 32000, 0.0165, 0.0825, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "structuredOutput": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching", "enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 16.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 82.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"5m": 20.625}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-08-05", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "Claude Opus 4.1 是 Anthropic 最新的用于处理高度复杂任务的最强大模型。它在性能、智能、流畅性和理解力方面表现卓越。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'claude-opus-4-20250514', 'Claude Opus 4', 'chat', 200000, 32000, 0.0168, 0.084, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "structuredOutput": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching", "enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 16.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 84, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"5m": 20.625}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-05-23", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "Claude Opus 4 是 Anthropic 用于处理高度复杂任务的最强大模型。它在性能、智能、流畅性和理解力方面表现卓越。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'claude-sonnet-4-5-20250929', 'Claude Sonnet 4.5', 'chat', 200000, 64000, 0.003, 0.015, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "structuredOutput": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching", "enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"1h": 6, "5m": 3.75}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-09-29", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Sonnet 4.5 是世界上最好的代理、编码和计算机使用模型。它也是我们在长时间运行任务中最准确、最详细的模型，具有增强的编码、金融和网络安全领域知识。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'claude-sonnet-4-20250514', 'Claude Sonnet 4', 'chat', 200000, 64000, 0.0033, 0.0165, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching", "enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 3.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"5m": 4.125}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-05-23", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Claude Sonnet 4 可以产生近乎即时的响应或延长的逐步思考，用户可以清晰地看到这些过程。API 用户还可以对模型思考的时间进行细致的控制", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'claude-3-7-sonnet-20250219', 'Claude 3.7 Sonnet', 'chat', 200000, 64000, 0.0033, 0.0165, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching", "enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 3.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"5m": 4.125}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-02-24", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Claude 3.7 Sonnet 是 Anthropic 迄今为止最智能的模型，也是市场上首个混合推理模型。Claude 3.7 Sonnet 可以产生近乎即时的响应或延长的逐步思考，用户可以清晰地看到这些过程。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'claude-haiku-4-5-20251001', 'Claude Haiku 4.5', 'chat', 200000, 64000, 0.001, 0.005, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "structuredOutput": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching", "enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"1h": 2, "5m": 1.25}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-10-16", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Claude Haiku 4.5 是 Anthropic 最快且最智能的 Haiku 模型，具有闪电般的速度和扩展思考能力。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'claude-3-5-haiku-20241022', 'Claude 3.5 Haiku', 'chat', 200000, 8192, 0.0011, 0.0055, '{"abilities": {"functionCall": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching"]}, "pricing": {"units": [{"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"5m": 1.1}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2024-11-05", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Claude 3.5 Haiku 是 Anthropic 最快的下一代模型。与 Claude 3 Haiku 相比，Claude 3.5 Haiku 在各项技能上都有所提升，并在许多智力基准测试中超越了上一代最大的模型 Claude 3 Opus。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'DeepSeek-V3.2-Exp', 'DeepSeek V3.2 Exp', 'chat', 131072, 8192, 0.00028, 0.00042, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.28, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.42, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-29", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "DeepSeek V3.2 是 DeepSeek 最新发布的通用大模型，支持混合推理架构，具备更强的 Agent 能力。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'DeepSeek-V3.2-Exp-Think', 'DeepSeek V3.2 Exp Thinking', 'chat', 131072, 65536, 0.00028, 0.00042, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.28, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.42, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-29", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "DeepSeek V3.2 思考模式。在输出最终回答之前，模型会先输出一段思维链内容，以提升最终答案的准确性。", "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'DeepSeek-V3.1', 'DeepSeek V3.1 (non-Think)', 'chat', 131072, NULL, 0.00056, 0.00168, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.56, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.68, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-V3.1-非思考模式；DeepSeek-V3.1 是深度求索全新推出的混合推理模型，支持思考与非思考2种推理模式，较 DeepSeek-R1-0528 思考效率更高。经 Post-Training 优化，Agent 工具使用与智能体任务表现大幅提升。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'DeepSeek-V3.1-Think', 'DeepSeek V3.1 (Think)', 'chat', 131072, NULL, 0.00056, 0.00168, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.56, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.68, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-V3.1-思考模式；DeepSeek-V3.1 是深度求索全新推出的混合推理模型，支持思考与非思考2种推理模式，较 DeepSeek-R1-0528 思考效率更高。经 Post-Training 优化，Agent 工具使用与智能体任务表现大幅提升。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'DeepSeek-V3.1-Fast', 'DeepSeek V3.1 (Fast)', 'chat', 131072, NULL, 0.001096, 0.003288, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.096, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3.288, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek V3.1 Fast 是 DeepSeek V3.1版本的高TPS极速版。 混合思考模式：通过更改聊天模板，一个模型可以同时支持思考模式和非思考模式。 更智能的工具调用：通过后训练优化，模型在工具使用和代理任务中的表现显著提升。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'DeepSeek-R1', 'DeepSeek R1', 'chat', 131072, NULL, 0.000546, 0.002184, '{"abilities": {"functionCall": true, "reasoning": true, "structuredOutput": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.546, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.184, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "已升级至最新版本250528；字节火山云开源部署的满血 R1，总参数量 671B，输入最高 64k。目前最稳定，推荐用这个。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'azure-DeepSeek-R1-0528', 'DeepSeek R1 0528 (Azure)', 'chat', 65536, NULL, 0.0004, 0.0016, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "由微软部署提供； DeepSeek R1型号已进行小版本升级，当前版本为DeepSeek-R1-0528。在最新的更新中，DeepSeek R1通过增加计算资源和引入后训练阶段的算法优化机制，大幅提升了推理深度和推断能力。该模型在数学、编程和通用逻辑等多个基准测试中表现出色，其整体性能已接近领先模型，如O3和Gemini 2.5 Pro 。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'DeepSeek-V3', 'DeepSeek V3', 'chat', 131072, NULL, 0.000272, 0.001088, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.272, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.088, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "字节火山云开源部署目前最稳定，推荐用这个。已经自动升级为最新发布的版本 250324 。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'DeepSeek-V3-Fast', 'DeepSeek V3 (Fast)', 'chat', 65536, NULL, 0.00055, 0.0022, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "模型供应商为：sophnet平台。DeepSeek V3 Fast 是 DeepSeek V3 0324 版本的高TPS极速版，满血非量化，代码与数学能力更强，响应更快！", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'gemini-2.5-pro', 'Gemini 2.5 Pro', 'chat', 1114112, 65536, 0.00125, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "structuredOutput": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget", "urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-17", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Pro 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'gemini-2.5-flash', 'Gemini 2.5 Flash', 'chat', 1114112, 65536, 0.0003, 0.0025, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "structuredOutput": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget", "urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-17", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Flash 是 Google 性价比最高的模型，提供全面的功能。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'gemini-2.5-flash-image', 'Nano Banana', 'chat', 40960, 8192, 0.0003, 0.0025, '{"abilities": {"imageOutput": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-26", "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Nano Banana 是 Google 最新、最快、最高效的原生多模态模型，它允许您通过对话生成和编辑图像。", "vision": true, "image_generation": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'gemini-2.5-flash-lite', 'Gemini 2.5 Flash-Lite', 'chat', 1114112, 65536, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget", "urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-22", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Flash-Lite 是 Google 最小、性价比最高的模型，专为大规模使用而设计。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'qwen3-235b-a22b-thinking-2507', 'Qwen3 235B A22B Thinking 2507', 'chat', 131072, 32768, 0.00028, 0.0028, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.28, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-25", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "基于Qwen3的思考模式开源模型，相较上一版本（通义千问3-235B-A22B）逻辑能力、通用能力、知识增强及创作能力均有大幅提升，适用于高难度强推理场景。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'qwen3-235b-a22b-instruct-2507', 'Qwen3 235B A22B Instruct 2507', 'chat', 131072, 32768, 0.00028, 0.00112, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.28, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.12, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-22", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "基于Qwen3的非思考模式开源模型，相较上一版本（通义千问3-235B-A22B）主观创作能力与模型安全性均有小幅度提升。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'qwen3-30b-a3b-thinking-2507', 'Qwen3 30B A3B Thinking 2507', 'chat', 131072, 32768, 0.00012, 0.0012, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.12, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-30", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "基于Qwen3的思考模式开源模型，相较上一版本（通义千问3-30B-A3B）逻辑能力、通用能力、知识增强及创作能力均有大幅提升，适用于高难度强推理场景。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'aihubmix'), 'qwen3-30b-a3b-instruct-2507', 'Qwen3 30B A3B Instruct 2507', 'chat', 131072, 32768, 0.00012, 0.00048, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.12, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.48, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-29", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "相较上一版本（Qwen3-30B-A3B）中英文和多语言整体通用能力有大幅提升。主观开放类任务专项优化，显著更加符合用户偏好，能够提供更有帮助性的回复。", "organization": "Qwen", "function_calling": true}', FALSE),
    -- akashchat
    ((SELECT id FROM ai_providers WHERE code = 'akashchat'), 'DeepSeek-V3-1', 'DeepSeek V3.1', 'chat', 65536, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["enableReasoning"]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "DeepSeek V3.1：下一代推理模型，提升了复杂推理与链路思考能力，适合需要深入分析的任务。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'akashchat'), 'gpt-oss-120b', 'GPT-OSS-120B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["reasoningEffort"]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "GPT-OSS-120B MXFP4 量化的 Transformer 结构，在资源受限时仍能保持强劲性能。", "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'akashchat'), 'Qwen3-235B-A22B-Instruct-2507-FP8', 'Qwen3 235B A22B Instruct 2507', 'chat', 262144, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "Qwen3 235B A22B Instruct 2507：面向高级推理与对话指令优化的模型，混合专家架构以在大规模参数下保持推理效率。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'akashchat'), 'DeepSeek-R1-Distill-Qwen-32B', 'DeepSeek R1 Distill Qwen 32B', 'chat', 65536, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'akashchat'), 'Meta-Llama-4-Maverick-17B-128E-Instruct-FP8', 'Llama 4 Maverick (17Bx128E)', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Llama 4 Maverick：基于 Mixture-of-Experts 的大规模模型，提供高效的专家激活策略以在推理中表现优异。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'akashchat'), 'Meta-Llama-3-3-70B-Instruct', 'Llama 3.3 70B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Llama 3.3 70B：通用性强的 Transformer 模型，适用于对话和生成任务。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'akashchat'), 'Meta-Llama-3-1-8B-Instruct-FP8', 'Llama 3.1 8B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "function_calling": true}', FALSE),
    -- anthropic
    ((SELECT id FROM ai_providers WHERE code = 'anthropic'), 'claude-sonnet-4-5-20250929', 'Claude Sonnet 4.5', 'chat', 200000, 64000, 0.003, 0.015, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "structuredOutput": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching", "enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheWrite", "rate": 3.75, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-29", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Claude Sonnet 4.5 是 Anthropic 迄今为止最智能的模型。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'anthropic'), 'claude-haiku-4-5-20251001', 'Claude Haiku 4.5', 'chat', 200000, 64000, 0.001, 0.005, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "structuredOutput": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching", "enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"1h": 2, "5m": 1.25}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-10-16", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Claude Haiku 4.5 是 Anthropic 最快且最智能的 Haiku 模型，具有闪电般的速度和扩展思考能力。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'anthropic'), 'claude-opus-4-1-20250805', 'Claude Opus 4.1', 'chat', 200000, 32000, 0.015, 0.075, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching", "enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 75, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"1h": 30, "5m": 18.75}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-08-05", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "Claude Opus 4.1 是 Anthropic 最新的用于处理高度复杂任务的最强大模型。它在性能、智能、流畅性和理解力方面表现卓越。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'anthropic'), 'claude-opus-4-20250514', 'Claude Opus 4', 'chat', 200000, 32000, 0.015, 0.075, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching", "enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 75, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"1h": 30, "5m": 18.75}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-05-23", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "Claude Opus 4 是 Anthropic 用于处理高度复杂任务的最强大模型。它在性能、智能、流畅性和理解力方面表现卓越。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'anthropic'), 'claude-sonnet-4-20250514', 'Claude Sonnet 4', 'chat', 200000, 64000, 0.003, 0.015, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching", "enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"1h": 6, "5m": 3.75}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-05-23", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Claude Sonnet 4 可以产生近乎即时的响应或延长的逐步思考，用户可以清晰地看到这些过程。API 用户还可以对模型思考的时间进行细致的控制", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'anthropic'), 'claude-3-7-sonnet-20250219', 'Claude 3.7 Sonnet', 'chat', 200000, 64000, 0.003, 0.015, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching", "enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"1h": 6, "5m": 3.75}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-02-24", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Claude 3.7 Sonnet 是 Anthropic 迄今为止最智能的模型，也是市场上首个混合推理模型。Claude 3.7 Sonnet 可以产生近乎即时的响应或延长的逐步思考，用户可以清晰地看到这些过程。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'anthropic'), 'claude-3-5-sonnet-20241022', 'Claude 3.5 Sonnet (New)', 'chat', 200000, 8192, 0.003, 0.015, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"1h": 6, "5m": 3.75}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2024-10-22", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Claude 3.5 Sonnet 提供了超越 Opus 的能力和比 Sonnet 更快的速度，同时保持与 Sonnet 相同的价格。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'anthropic'), 'claude-3-5-sonnet-20240620', 'Claude 3.5 Sonnet (Old)', 'chat', 200000, 8192, 0.003, 0.015, '{"abilities": {"functionCall": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"1h": 6, "5m": 3.75}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2024-06-20", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Claude 3.5 Sonnet 提供了超越 Opus 的能力和比 Sonnet 更快的速度，同时保持与 Sonnet 相同的价格。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'anthropic'), 'claude-3-5-haiku-20241022', 'Claude 3.5 Haiku', 'chat', 200000, 8192, 0.0008, 0.004, '{"abilities": {"functionCall": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching"]}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.08, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"1h": 1.6, "5m": 1}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2024-11-05", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Claude 3.5 Haiku 是 Anthropic 最快的下一代模型。与 Claude 3 Haiku 相比，Claude 3.5 Haiku 在各项技能上都有所提升，并在许多智力基准测试中超越了上一代最大的模型 Claude 3 Opus。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'anthropic'), 'claude-3-haiku-20240307', 'Claude 3 Haiku', 'chat', 200000, 4096, 0.00025, 0.00125, '{"abilities": {"functionCall": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching"]}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.03, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"1h": 0.5, "5m": 0.3}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2024-03-07", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Claude 3 Haiku 是 Anthropic 的最快且最紧凑的模型，旨在实现近乎即时的响应。它具有快速且准确的定向性能。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'anthropic'), 'claude-3-opus-20240229', 'Claude 3 Opus', 'chat', 200000, 4096, 0.015, 0.075, '{"abilities": {"functionCall": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching"]}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 75, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"1h": 30, "5m": 18.75}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2024-02-29", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Claude 3 Opus 是 Anthropic 用于处理高度复杂任务的最强大模型。它在性能、智能、流畅性和理解力方面表现卓越。", "vision": true, "function_calling": true}', FALSE),
    -- azure
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'o3', 'o3', 'chat', 200000, 100000, 0.01, 0.04, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "config": {"deploymentName": "o3"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 40, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3 是一款全能强大的模型，在多个领域表现出色。它为数学、科学、编程和视觉推理任务树立了新标杆。它也擅长技术写作和指令遵循。用户可利用它分析文本、代码和图像，解决多步骤的复杂问题。", "vision": true, "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'o4-mini', 'o4-mini', 'chat', 200000, 100000, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "config": {"deploymentName": "o4-mini"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.275, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o4-mini 是我们最新的小型 o 系列模型。 它专为快速有效的推理而优化，在编码和视觉任务中表现出极高的效率和性能。", "vision": true, "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'gpt-4.1', 'GPT-4.1', 'chat', 1047576, 32768, 0.002, 0.008, '{"abilities": {"functionCall": true, "structuredOutput": true, "vision": true}, "config": {"deploymentName": "gpt-4.1"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 是我们用于复杂任务的旗舰模型。它非常适合跨领域解决问题。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'gpt-4.1-mini', 'GPT-4.1 mini', 'chat', 1047576, 32768, 0.0004, 0.0016, '{"abilities": {"functionCall": true, "vision": true}, "config": {"deploymentName": "gpt-4.1-mini"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 mini 提供了智能、速度和成本之间的平衡，使其成为许多用例中有吸引力的模型。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'gpt-4.1-nano', 'GPT-4.1 nano', 'chat', 1047576, 32768, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "vision": true}, "config": {"deploymentName": "gpt-4.1-nano"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 mini 提供了智能、速度和成本之间的平衡，使其成为许多用例中有吸引力的模型。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'o3-mini', 'o3-mini', 'chat', 200000, 100000, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "reasoning": true}, "config": {"deploymentName": "o3-mini"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-31", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3-mini 是我们最新的小型推理模型，在与 o1-mini 相同的成本和延迟目标下提供高智能。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'o1-mini', 'o1-mini', 'chat', 128000, 65536, 0.0011, 0.0044, '{"abilities": {"reasoning": true}, "config": {"deploymentName": "o1-mini"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-12", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "o1-mini是一款针对编程、数学和科学应用场景而设计的快速、经济高效的推理模型。该模型具有128K上下文和2023年10月的知识截止日期。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'o1', 'o1', 'chat', 200000, 100000, 0.015, 0.06, '{"abilities": {"reasoning": true}, "config": {"deploymentName": "o1"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 7.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-12-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o1是OpenAI新的推理模型，支持图文输入并输出文本，适用于需要广泛通用知识的复杂任务。该模型具有200K上下文和2023年10月的知识截止日期。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'o1-preview', 'o1-preview', 'chat', 128000, 32768, 0.015, 0.06, '{"abilities": {"reasoning": true}, "config": {"deploymentName": "o1-preview"}, "pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-12", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "o1是OpenAI新的推理模型，适用于需要广泛通用知识的复杂任务。该模型具有128K上下文和2023年10月的知识截止日期。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'gpt-4o', 'GPT-4o', 'chat', 128000, 4096, 0.0025, 0.01, '{"abilities": {"functionCall": true, "vision": true}, "config": {"deploymentName": "gpt-4o"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-05-13", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'gpt-4', 'GPT 4 Turbo', 'chat', 128000, 4096, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "config": {"deploymentName": "gpt-4-turbo"}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "GPT 4 Turbo，多模态模型，提供杰出的语言理解和生成能力，同时支持图像输入。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'gpt-4o-mini', 'GPT 4o Mini', 'chat', 128000, 4096, 0.00015, 0.0006, '{"abilities": {"functionCall": true, "vision": true}, "config": {"deploymentName": "gpt-4o-mini"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "GPT-4o Mini，小型高效模型，具备与GPT-4o相似的卓越性能。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'gpt-image-1', 'GPT Image 1', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "size": {"default": "auto", "enum": ["auto", "1024x1024", "1536x1024", "1024x1536"]}}, "source": "builtin", "description": "ChatGPT Image 1"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'dall-e-3', 'DALL·E 3', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "size": {"default": "auto", "enum": ["auto", "1024x1024", "1792x1024", "1024x1792"]}}, "source": "builtin", "description": "DALL·E 3", "resolutions": ["1024x1024", "1024x1792", "1792x1024"]}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'FLUX.1-Kontext-pro', 'FLUX.1 Kontext [pro]', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "size": {"default": "auto", "enum": ["auto", "1024x1024", "1792x1024", "1024x1792"]}}, "released_at": "2025-06-23", "source": "builtin", "description": "FLUX.1 Kontext [pro]"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'azure'), 'FLUX-1.1-pro', 'FLUX.1.1 Pro', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}}, "released_at": "2025-06-23", "source": "builtin", "description": "FLUX.1.1 Pro"}', TRUE),
    -- azureai
    ((SELECT id FROM ai_providers WHERE code = 'azureai'), 'DeepSeek-R1', 'DeepSeek R1', 'chat', 128000, NULL, 0.00135, 0.0054, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.35, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azureai'), 'DeepSeek-V3', 'DeepSeek V3', 'chat', 128000, NULL, 0.00114, 0.00456, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.14, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.56, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azureai'), 'o3', 'o3', 'chat', 200000, 100000, 0.01, 0.04, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 40, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3 是一款全能强大的模型，在多个领域表现出色。它为数学、科学、编程和视觉推理任务树立了新标杆。它也擅长技术写作和指令遵循。用户可利用它分析文本、代码和图像，解决多步骤的复杂问题。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azureai'), 'o4-mini', 'o4-mini', 'chat', 200000, 100000, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.275, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o4-mini 是我们最新的小型 o 系列模型。 它专为快速有效的推理而优化，在编码和视觉任务中表现出极高的效率和性能。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azureai'), 'gpt-4.1', 'GPT-4.1', 'chat', 1047576, 32768, 0.002, 0.008, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 是我们用于复杂任务的旗舰模型。它非常适合跨领域解决问题。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'azureai'), 'gpt-4.1-mini', 'GPT-4.1 mini', 'chat', 1047576, 32768, 0.0004, 0.0016, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 mini 提供了智能、速度和成本之间的平衡，使其成为许多用例中有吸引力的模型。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'azureai'), 'gpt-4.1-nano', 'GPT-4.1 nano', 'chat', 1047576, 32768, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 mini 提供了智能、速度和成本之间的平衡，使其成为许多用例中有吸引力的模型。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azureai'), 'gpt-4.5-preview', 'GPT 4.5 Preview', 'chat', 128000, NULL, 0.075, 0.15, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 37.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 150, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-27", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GPT-4.5-preview 是最新的通用模型，具有深厚的世界知识和对用户意图的更好理解，擅长创意任务和代理规划。该模型的知识截止2023年10月。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azureai'), 'o3-mini', 'o3-mini', 'chat', 200000, NULL, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-31", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "o3-mini 是我们最新的小型推理模型，在与 o1-mini 相同的成本和延迟目标下提供高智能。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azureai'), 'o1-mini', 'o1-mini', 'chat', 128000, NULL, 0.0011, 0.0044, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-12", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "o1-mini是一款针对编程、数学和科学应用场景而设计的快速、经济高效的推理模型。该模型具有128K上下文和2023年10月的知识截止日期。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azureai'), 'o1', 'o1', 'chat', 200000, NULL, 0.015, 0.06, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 7.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-12-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "o1是OpenAI新的推理模型，支持图文输入并输出文本，适用于需要广泛通用知识的复杂任务。该模型具有200K上下文和2023年10月的知识截止日期。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azureai'), 'gpt-4o', 'GPT-4o', 'chat', 128000, 4096, 0.0025, 0.01, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-05-13", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'azureai'), 'gpt-4o-mini', 'GPT 4o Mini', 'chat', 128000, 16384, 0.00015, 0.0006, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "GPT-4o Mini，小型高效模型，具备与GPT-4o相似的卓越性能。", "vision": true, "function_calling": true}', FALSE),
    -- baichuan
    ((SELECT id FROM ai_providers WHERE code = 'baichuan'), 'Baichuan4', 'Baichuan 4', 'chat', 32768, 4096, 0.1, 0.1, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 100, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 100, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "模型能力国内第一，在知识百科、长文本、生成创作等中文任务上超越国外主流模型。还具备行业领先的多模态能力，多项权威评测基准表现优异。", "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'baichuan'), 'Baichuan4-Turbo', 'Baichuan 4 Turbo', 'chat', 32768, 4096, 0.015, 0.015, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "模型能力国内第一，在知识百科、长文本、生成创作等中文任务上超越国外主流模型。还具备行业领先的多模态能力，多项权威评测基准表现优异。", "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'baichuan'), 'Baichuan4-Air', 'Baichuan 4 Air', 'chat', 32768, 4096, 0.00098, 0.00098, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.98, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.98, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "模型能力国内第一，在知识百科、长文本、生成创作等中文任务上超越国外主流模型。还具备行业领先的多模态能力，多项权威评测基准表现优异。", "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'baichuan'), 'Baichuan3-Turbo', 'Baichuan 3 Turbo', 'chat', 32768, 8192, 0.012, 0.012, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "针对企业高频场景优化，效果大幅提升，高性价比。相对于Baichuan2模型，内容创作提升20%，知识问答提升17%， 角色扮演能力提升40%。整体效果比GPT3.5更优。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'baichuan'), 'Baichuan3-Turbo-128k', 'Baichuan 3 Turbo 128k', 'chat', 128000, 4096, 0.024, 0.024, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 24, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 24, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "具备 128K 超长上下文窗口，针对企业高频场景优化，效果大幅提升，高性价比。相对于Baichuan2模型，内容创作提升20%，知识问答提升17%， 角色扮演能力提升40%。整体效果比GPT3.5更优。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'baichuan'), 'Baichuan2-Turbo', 'Baichuan 2 Turbo', 'chat', 32768, 8192, 0.008, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "采用搜索增强技术实现大模型与领域知识、全网知识的全面链接。支持PDF、Word等多种文档上传及网址输入，信息获取及时、全面，输出结果准确、专业。"}', FALSE),
    -- bedrock
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'us.anthropic.claude-3-7-sonnet-20250219-v1:0', 'Claude 3.7 Sonnet', 'chat', 200000, 8192, 0.003, 0.015, '{"abilities": {"functionCall": true, "reasoning": true, "structuredOutput": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-24", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Claude 3.7 sonnet 是 Anthropic 最快的下一代模型。与 Claude 3 Haiku 相比，Claude 3.7 Sonnet 在各项技能上都有所提升，并在许多智力基准测试中超越了上一代最大的模型 Claude 3 Opus。", "vision": true, "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'anthropic.claude-3-5-sonnet-20241022-v2:0', 'Claude 3.5 Sonnet', 'chat', 200000, 8192, 0.003, 0.015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-10-22", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Claude 3.5 Sonnet 提升了行业标准，性能超过竞争对手模型和 Claude 3 Opus，在广泛的评估中表现出色，同时具有我们中等层级模型的速度和成本。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'us.anthropic.claude-3-5-sonnet-20241022-v2:0', 'Claude 3.5 Sonnet v2 (Inference profile)', 'chat', 200000, 8192, 0.003, 0.015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-10-22", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Claude 3.5 Sonnet 提升了行业标准，性能超过竞争对手模型和 Claude 3 Opus，在广泛的评估中表现出色，同时具有我们中等层级模型的速度和成本。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'anthropic.claude-3-5-sonnet-20240620-v1:0', 'Claude 3.5 Sonnet 0620', 'chat', 200000, 8192, 0.003, 0.015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-06-20", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Claude 3.5 Sonnet 提升了行业标准，性能超过竞争对手模型和 Claude 3 Opus，在广泛的评估中表现出色，同时具有我们中等层级模型的速度和成本。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'anthropic.claude-3-haiku-20240307-v1:0', 'Claude 3 Haiku', 'chat', 200000, 4096, 0.00025, 0.00125, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-03-07", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Claude 3 Haiku 是 Anthropic 最快、最紧凑的模型，提供近乎即时的响应速度。它可以快速回答简单的查询和请求。客户将能够构建模仿人类互动的无缝 AI 体验。Claude 3 Haiku 可以处理图像并返回文本输出，具有 200K 的上下文窗口。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'anthropic.claude-3-sonnet-20240229-v1:0', 'Claude 3 Sonnet', 'chat', 200000, NULL, 0.003, 0.015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "Anthropic 的 Claude 3 Sonnet 在智能和速度之间达到了理想的平衡——特别适合企业工作负载。它以低于竞争对手的价格提供最大的效用，并被设计成为可靠的、高耐用的主力机，适用于规模化的 AI 部署。Claude 3 Sonnet 可以处理图像并返回文本输出，具有 200K 的上下文窗口。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'anthropic.claude-3-opus-20240229-v1:0', 'Claude 3 Opus', 'chat', 200000, 4096, 0.015, 0.075, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 75, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-02-29", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Claude 3 Opus 是 Anthropic 最强大的 AI 模型，具有在高度复杂任务上的最先进性能。它可以处理开放式提示和未见过的场景，具有出色的流畅性和类人的理解能力。Claude 3 Opus 展示了生成 AI 可能性的前沿。Claude 3 Opus 可以处理图像并返回文本输出，具有 200K 的上下文窗口。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'anthropic.claude-v2:1', 'Claude 2.1', 'chat', 200000, NULL, 0.008, 0.024, '{"pricing": {"units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 24, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "Claude 2 的更新版，具有双倍的上下文窗口，以及在长文档和 RAG 上下文中的可靠性、幻觉率和基于证据的准确性的改进。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'anthropic.claude-v2', 'Claude 2.0', 'chat', 100000, NULL, 0.008, 0.024, '{"pricing": {"units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 24, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 100000, "contextWindowTokens": 100000, "description": "Anthropic 在从复杂对话和创意内容生成到详细指令跟随的广泛任务中都表现出高度能力的模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'anthropic.claude-instant-v1', 'Claude Instant', 'chat', 100000, NULL, 0.0008, 0.0024, '{"pricing": {"units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 100000, "contextWindowTokens": 100000, "description": "一款快速、经济且仍然非常有能力的模型，可以处理包括日常对话、文本分析、总结和文档问答在内的一系列任务。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'meta.llama3-1-8b-instruct-v1:0', 'Llama 3.1 8B Instruct', 'chat', 128000, NULL, 0.00022, 0.00022, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.22, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.22, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Meta Llama 3.1 8B Instruct 的更新版，包括扩展的 128K 上下文长度、多语言性和改进的推理能力。Llama 3.1 提供的多语言大型语言模型 (LLMs) 是一组预训练的、指令调整的生成模型，包括 8B、70B 和 405B 大小 (文本输入/输出)。Llama 3.1 指令调整的文本模型 (8B、70B、405B) 专为多语言对话用例进行了优化，并在常见的行业基准测试中超过了许多可用的开源聊天模型。Llama 3.1 旨在用于多种语言的商业和研究用途。指令调整的文本模型适用于类似助手的聊天，而预训练模型可以适应各种自然语言生成任务。Llama 3.1 模型还支持利用其模型的输出来改进其他模型，包括合成数据生成和精炼。Llama 3.1 是使用优化的变压器架构的自回归语言模型。调整版本使用监督微调 (SFT) 和带有人类反馈的强化学习 (RLHF) 来符合人类对帮助性和安全性的偏好。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'meta.llama3-1-70b-instruct-v1:0', 'Llama 3.1 70B Instruct', 'chat', 128000, NULL, 0.00099, 0.00099, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.99, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.99, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Meta Llama 3.1 70B Instruct 的更新版，包括扩展的 128K 上下文长度、多语言性和改进的推理能力。Llama 3.1 提供的多语言大型语言模型 (LLMs) 是一组预训练的、指令调整的生成模型，包括 8B、70B 和 405B 大小 (文本输入/输出)。Llama 3.1 指令调整的文本模型 (8B、70B、405B) 专为多语言对话用例进行了优化，并在常见的行业基准测试中超过了许多可用的开源聊天模型。Llama 3.1 旨在用于多种语言的商业和研究用途。指令调整的文本模型适用于类似助手的聊天，而预训练模型可以适应各种自然语言生成任务。Llama 3.1 模型还支持利用其模型的输出来改进其他模型，包括合成数据生成和精炼。Llama 3.1 是使用优化的变压器架构的自回归语言模型。调整版本使用监督微调 (SFT) 和带有人类反馈的强化学习 (RLHF) 来符合人类对帮助性和安全性的偏好。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'meta.llama3-1-405b-instruct-v1:0', 'Llama 3.1 405B Instruct', 'chat', 128000, NULL, 0.00532, 0.016, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 5.32, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Meta Llama 3.1 405B Instruct 是 Llama 3.1 Instruct 模型中最大、最强大的模型，是一款高度先进的对话推理和合成数据生成模型，也可以用作在特定领域进行专业持续预训练或微调的基础。Llama 3.1 提供的多语言大型语言模型 (LLMs) 是一组预训练的、指令调整的生成模型，包括 8B、70B 和 405B 大小 (文本输入/输出)。Llama 3.1 指令调整的文本模型 (8B、70B、405B) 专为多语言对话用例进行了优化，并在常见的行业基准测试中超过了许多可用的开源聊天模型。Llama 3.1 旨在用于多种语言的商业和研究用途。指令调整的文本模型适用于类似助手的聊天，而预训练模型可以适应各种自然语言生成任务。Llama 3.1 模型还支持利用其模型的输出来改进其他模型，包括合成数据生成和精炼。Llama 3.1 是使用优化的变压器架构的自回归语言模型。调整版本使用监督微调 (SFT) 和带有人类反馈的强化学习 (RLHF) 来符合人类对帮助性和安全性的偏好。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'meta.llama3-8b-instruct-v1:0', 'Llama 3 8B Instruct', 'chat', 8000, NULL, 0.0003, 0.0006, '{"pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "Meta Llama 3 是一款面向开发者、研究人员和企业的开放大型语言模型 (LLM)，旨在帮助他们构建、实验并负责任地扩展他们的生成 AI 想法。作为全球社区创新的基础系统的一部分，它非常适合计算能力和资源有限、边缘设备和更快的训练时间。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'bedrock'), 'meta.llama3-70b-instruct-v1:0', 'Llama 3 70B Instruct', 'chat', 8000, NULL, 0.00265, 0.0035, '{"pricing": {"units": [{"name": "textInput", "rate": 2.65, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "Meta Llama 3 是一款面向开发者、研究人员和企业的开放大型语言模型 (LLM)，旨在帮助他们构建、实验并负责任地扩展他们的生成 AI 想法。作为全球社区创新的基础系统的一部分，它非常适合内容创建、对话 AI、语言理解、研发和企业应用。"}', FALSE),
    -- bfl
    ((SELECT id FROM ai_providers WHERE code = 'bfl'), 'flux-kontext-pro', 'FLUX.1 Kontext [pro]', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.04, "strategy": "fixed", "unit": "image"}]}, "parameters": {"aspectRatio": {"default": "1:1", "enum": ["1:1", "4:3", "16:9", "3:2", "2:3", "9:16", "21:9"]}, "imageUrls": {"default": []}, "prompt": {"default": ""}, "seed": {"default": null}}, "released_at": "2025-05-29", "source": "builtin", "description": "最先进的上下文图像生成和编辑——结合文本和图像以获得精确、连贯的结果。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bfl'), 'flux-kontext-max', 'FLUX.1 Kontext [max]', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.08, "strategy": "fixed", "unit": "image"}]}, "parameters": {"aspectRatio": {"default": "1:1", "enum": ["1:1", "4:3", "16:9", "3:2", "2:3", "9:16", "21:9"]}, "imageUrls": {"default": []}, "prompt": {"default": ""}, "seed": {"default": null}}, "released_at": "2025-05-29", "source": "builtin", "description": "最先进的上下文图像生成和编辑——结合文本和图像以获得精确、连贯的结果。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bfl'), 'flux-pro-1.1', 'FLUX1.1 [pro] ', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.06, "strategy": "fixed", "unit": "image"}]}, "parameters": {"height": {"default": 768, "max": 1440, "min": 256, "step": 32}, "imageUrl": {"default": null}, "prompt": {"default": ""}, "seed": {"default": null}, "width": {"default": 1024, "max": 1440, "min": 256, "step": 32}}, "released_at": "2024-10-02", "source": "builtin", "description": "升级版专业级AI图像生成模型——提供卓越的图像质量和精确的提示词遵循能力。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bfl'), 'flux-pro-1.1-ultra', 'FLUX1.1 [pro] Ultra', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.06, "strategy": "fixed", "unit": "image"}]}, "parameters": {"aspectRatio": {"default": "16:9", "enum": ["1:1", "4:3", "16:9", "3:2", "2:3", "9:16", "21:9"]}, "imageUrl": {"default": null}, "prompt": {"default": ""}, "seed": {"default": null}}, "released_at": "2024-11-06", "source": "builtin", "description": "超高分辨率AI图像生成——支持4兆像素输出，10秒内生成超清图像。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bfl'), 'flux-pro', 'FLUX.1 [pro]', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.025, "strategy": "fixed", "unit": "image"}]}, "parameters": {"cfg": {"default": 2.5, "max": 5, "min": 1.5, "step": 0.1}, "height": {"default": 768, "max": 1440, "min": 256, "step": 32}, "imageUrl": {"default": null}, "prompt": {"default": ""}, "seed": {"default": null}, "steps": {"default": 40, "max": 50, "min": 1}, "width": {"default": 1024, "max": 1440, "min": 256, "step": 32}}, "released_at": "2024-08-01", "source": "builtin", "description": "顶级商用AI图像生成模型——无与伦比的图像质量和多样化输出表现。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'bfl'), 'flux-dev', 'FLUX.1 [dev]', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.025, "strategy": "fixed", "unit": "image"}]}, "parameters": {"cfg": {"default": 3, "max": 5, "min": 1.5, "step": 0.1}, "height": {"default": 768, "max": 1440, "min": 256, "step": 32}, "imageUrl": {"default": null}, "prompt": {"default": ""}, "seed": {"default": null}, "steps": {"default": 28, "max": 50, "min": 1}, "width": {"default": 1024, "max": 1440, "min": 256, "step": 32}}, "released_at": "2024-08-01", "source": "builtin", "description": "开源研发版AI图像生成模型——高效优化，适合非商业用途的创新研究。"}', TRUE),
    -- cerebras
    ((SELECT id FROM ai_providers WHERE code = 'cerebras'), 'llama-4-scout-17b-16e-instruct', 'Llama 4 Scout', 'chat', 32768, NULL, 0.00065, 0.00085, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.65, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.85, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Llama 4 Scout：高性能的 Llama 系列模型，适合需高吞吐与低延迟的场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cerebras'), 'llama3.1-8b', 'Llama 3.1 8B', 'chat', 32768, NULL, 0.0001, 0.0001, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Llama 3.1 8B：小体量、低延迟的 Llama 变体，适合轻量在线推理与交互场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cerebras'), 'llama-3.3-70b', 'Llama 3.3 70B', 'chat', 131072, NULL, 0.00085, 0.0012, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.85, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Llama 3.3 70B：中大型 Llama 模型，兼顾推理能力与吞吐。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cerebras'), 'gpt-oss-120b', 'GPT OSS 120B', 'chat', 131072, NULL, 0.00035, 0.00075, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["reasoningEffort"]}, "pricing": {"units": [{"name": "textInput", "rate": 0.35, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.75, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cerebras'), 'qwen-3-32b', 'Qwen 3 32B', 'chat', 131072, NULL, 0.0004, 0.0008, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Qwen 3 32B：Qwen 系列在多语言与编码任务上表现优良，适合中等规模生产化使用。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cerebras'), 'qwen-3-235b-a22b-instruct-2507', 'Qwen 3 235B Instruct', 'chat', 131072, NULL, 0.0006, 0.0012, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cerebras'), 'qwen-3-235b-a22b-thinking-2507', 'Qwen 3 235B Thinking', 'chat', 131072, NULL, 0.0006, 0.0029, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cerebras'), 'qwen-3-coder-480b', 'Qwen 3 Coder 480B', 'chat', 131072, NULL, 0.002, 0.002, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Qwen 3 Coder 480B：面向代码生成与复杂编程任务的长上下文模型。", "function_calling": true}', FALSE),
    -- cloudflare
    ((SELECT id FROM ai_providers WHERE code = 'cloudflare'), '@cf/deepseek-ai/deepseek-r1-distill-qwen-32b', 'deepseek r1 (distill qwen 32b)', 'chat', 80000, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 80000, "contextWindowTokens": 80000, "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cloudflare'), '@cf/qwen/qwq-32b', 'qwq 32b', 'chat', 24000, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 24000, "contextWindowTokens": 24000, "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cloudflare'), '@cf/qwen/qwen2.5-coder-32b-instruct', 'qwen2.5 coder 32b', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cloudflare'), '@cf/google/gemma-3-12b-it', 'gemma 3 12b', 'chat', 80000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 80000, "contextWindowTokens": 80000}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cloudflare'), '@cf/meta/llama-3.3-70b-instruct-fp8-fast', 'llama 3.3 70b', 'chat', 24000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 24000, "contextWindowTokens": 24000, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cloudflare'), '@cf/meta/llama-4-scout-17b-16e-instruct', 'llama 4 17b', 'chat', 131000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 131000, "contextWindowTokens": 131000, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cloudflare'), '@cf/mistralai/mistral-small-3.1-24b-instruct', 'mistral small 3.1 24b', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cloudflare'), '@cf/openchat/openchat-3.5-0106', 'openchat-3.5-0106', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cloudflare'), '@cf/qwen/qwen1.5-14b-chat-awq', 'qwen1.5-14b-chat-awq', 'chat', 7500, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 7500, "contextWindowTokens": 7500}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cloudflare'), '@cf/meta/llama-3.1-8b-instruct-fast', 'llama 3.1 8b', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000}', FALSE),
    -- cohere
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'command-a-03-2025', 'Command A 2503', 'chat', 256000, 8000, 0.0025, 0.01, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "maxOutputTokens": 8000, "maxOutput": 8000, "description": "Command A 是我们迄今为止性能最强的模型，在工具使用、代理、检索增强生成（RAG）和多语言应用场景方面表现出色。Command A 具有 256K 的上下文长度，仅需两块 GPU 即可运行，并且相比于 Command R+ 08-2024，吞吐量提高了 150%。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'command-r-plus-04-2024', 'Command R+ 2404', 'chat', 128000, 4000, 0.003, 0.015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "command-r-plus 是 command-r-plus-04-2024 的别名，因此如果您在 API 中使用 command-r-plus，实际上指向的就是该模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'command-r-plus-08-2024', 'Command R+ 2408', 'chat', 128000, 4000, 0.0025, 0.01, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "Command R+ 是一个遵循指令的对话模型，在语言任务方面表现出更高的质量、更可靠，并且相比以往模型具有更长的上下文长度。它最适用于复杂的 RAG 工作流和多步工具使用。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'command-r-03-2024', 'Command R 2403', 'chat', 128000, 4000, 0.00015, 0.0006, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "command-r 是一种遵循指令的会话模型，与以前的模型相比，它以更高的质量、更可靠的方式和更长的上下文执行语言任务。它可用于复杂的工作流程，如代码生成、检索增强生成（RAG）、工具使用和代理。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'command-r-08-2024', 'Command R 2408', 'chat', 128000, 4000, 0.00015, 0.0006, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "command-r-08-2024 是 Command R 模型的更新版本，于 2024 年 8 月发布。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'command-r-03-2024', 'Command R 2403', 'chat', 128000, 4000, 0.0005, 0.0015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "Command R 是一个遵循指令的对话模型，在语言任务方面表现出更高的质量、更可靠，并且相比以往模型具有更长的上下文长度。它可用于复杂的工作流程，如代码生成、检索增强生成（RAG）、工具使用和代理。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'command-r7b-12-2024', 'Command R7B 2412', 'chat', 128000, 4000, 0.0000375, 0.00015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.0375, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "command-r7b-12-2024 是一个小型且高效的更新版本，于 2024 年 12 月发布。它在 RAG、工具使用、代理等需要复杂推理和多步处理的任务中表现出色。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'command', 'Command', 'chat', 4000, 4000, 0.001, 0.002, '{"pricing": {"units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4000, "contextWindowTokens": 4000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "一个遵循指令的对话模型，在语言任务中表现出高质量、更可靠，并且相比我们的基础生成模型具有更长的上下文长度。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'command-nightly', 'Command Nightly', 'chat', 128000, 4000, 0.001, 0.002, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "为了缩短主要版本发布之间的时间间隔，我们推出了 Command 模型的每夜版本。对于 Command 系列，这一版本称为 command-cightly。请注意，command-nightly 是最新、最具实验性且（可能）不稳定的版本。每夜版本会定期更新，且不会提前通知，因此不建议在生产环境中使用。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'command-light', 'Command Light', 'chat', 4000, 4000, 0.0003, 0.0006, '{"pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4000, "contextWindowTokens": 4000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "一个更小、更快的 Command 版本，几乎同样强大，但速度更快。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'command-light-nightly', 'Command Light Nightly', 'chat', 4000, 4000, 0.0003, 0.0006, '{"pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4000, "contextWindowTokens": 4000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "为了缩短主要版本发布之间的时间间隔，我们推出了 Command 模型的每夜版本。对于 command-light 系列，这一版本称为 command-light-nightly。请注意，command-light-nightly 是最新、最具实验性且（可能）不稳定的版本。每夜版本会定期更新，且不会提前通知，因此不建议在生产环境中使用。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'c4ai-aya-expanse-32b', 'Aya Expanse 32B', 'chat', 128000, 4000, 0.0005, 0.0015, '{"pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "Aya Expanse 是一款高性能的 32B 多语言模型，旨在通过指令调优、数据套利、偏好训练和模型合并的创新，挑战单语言模型的表现。它支持 23 种语言。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'c4ai-aya-expanse-8b', 'Aya Expanse 8B', 'chat', 8000, 4000, 0.0005, 0.0015, '{"pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "Aya Expanse 是一款高性能的 8B 多语言模型，旨在通过指令调优、数据套利、偏好训练和模型合并的创新，挑战单语言模型的表现。它支持 23 种语言。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'c4ai-aya-vision-32b', 'Aya Vision 32B', 'chat', 16000, 4000, 0.0005, 0.0015, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "Aya Vision 是一款最先进的多模态模型，在语言、文本和图像能力的多个关键基准上表现出色。它支持 23 种语言。这个 320 亿参数的版本专注于最先进的多语言表现。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cohere'), 'c4ai-aya-vision-8b', 'Aya Vision 8B', 'chat', 16000, 4000, 0.0005, 0.0015, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "Aya Vision 是一款最先进的多模态模型，在语言、文本和图像能力的多个关键基准上表现出色。这个 80 亿参数的版本专注于低延迟和最佳性能。", "vision": true}', TRUE),
    -- cometapi
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'gpt-5-chat-latest', 'GPT-5-Chat-Latest', 'chat', 400000, 128000, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "released_at": "2025-08-07", "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 128000, "maxOutput": 128000, "description": "GPT-5 是 CometAPI 提供的最新旗舰模型，适用于跨领域编码和代理任务。GPT-5 在准确性、速度、推理、上下文识别、结构化思维和问题解决方面实现了飞跃。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'gpt-5-mini', 'GPT-5 Mini', 'chat', 400000, 128000, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 128000, "maxOutput": 128000, "description": "GPT-5 迷你版本，性价比极高的智能模型。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'gpt-5-nano', 'GPT-5 Nano', 'chat', 400000, 128000, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 128000, "maxOutput": 128000, "description": "GPT-5 的纳米版本，适合轻量级任务。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'gpt-5', 'GPT-5', 'chat', 400000, 128000, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 128000, "maxOutput": 128000, "description": "GPT-5", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'gpt-4.1', 'GPT-4.1', 'chat', 1047576, 32768, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 提供了更强大的推理和生成能力。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'gpt-4.1-mini', 'GPT-4.1 mini', 'chat', 1047576, 32768, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 mini 提供了智能、速度和成本之间的平衡，使其成为许多用例中有吸引力的模型。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'gpt-4.1-nano', 'GPT-4.1 Nano', 'chat', 128000, 16384, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "GPT-4.1 nano 是最轻量级的版本，提供快速响应。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'gpt-4o-mini', 'GPT-4o Mini', 'chat', 128000, 16384, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "GPT-4o 的小型版本，提供更快的响应速度。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'chatgpt-4o-latest', 'ChatGPT-4o', 'chat', 128000, 16384, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'o4-mini-2025-04-16', 'o4-mini', 'chat', 200000, 200000, NULL, NULL, '{"abilities": {"vision": true}, "released_at": "2025-4-16", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 200000, "maxOutput": 200000, "description": "o4-mini 是 OpenAI 的推理模型，支持图文输入并输出文本，适用于需要广泛通用知识的复杂任务。该模型具有200K上下文", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'o3-pro-2025-06-10', 'o3 Pro', 'chat', 200000, 200000, NULL, NULL, '{"abilities": {"vision": true}, "released_at": "2025-6-10", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 200000, "maxOutput": 200000, "description": "o3 Pro 是OpenAI新的推理模型，支持图文输入并输出文本，适用于需要广泛通用知识的复杂任务", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'o3-2025-04-16', 'o3', 'chat', 200000, 200000, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "released_at": "2025-4-16", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 200000, "maxOutput": 200000, "description": "o3 是OpenAI新的推理模型，支持图文输入并输出文本，适用于需要广泛通用知识的复杂任务", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'claude-opus-4-1-20250805', 'Claude Opus 4.1', 'chat', 200000, 32000, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "released_at": "2025-08-05", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "Claude Opus 4.1 是 Anthropic 最新的用于处理高度复杂任务的最强大模型。它在性能、智能、流畅性和理解力方面表现卓越。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'claude-opus-4-1-20250805-thinking', 'Claude Opus 4.1 Thinking', 'chat', 200000, 32000, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "released_at": "2025-08-05", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "Claude Opus 4.1 思考模型，可以展示其推理过程的高级版本。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'claude-sonnet-4-20250514', 'Claude Sonnet 4', 'chat', 200000, 64000, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "released_at": "2025-05-23", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Claude Sonnet 4 可以产生近乎即时的响应或延长的逐步思考，用户可以清晰地看到这些过程。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'claude-sonnet-4-20250514-thinking', 'Claude Sonnet 4 Thinking', 'chat', 200000, 64000, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "released_at": "2025-05-23", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Claude Sonnet 4 思考模型可以产生近乎即时的响应或延长的逐步思考，用户可以清晰地看到这些过程。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'claude-3-7-sonnet-latest', 'Claude 3.7 Sonnet Latest', 'chat', 200000, 64000, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "released_at": "2025-08-05", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Claude 3.7 Sonnet 是 Anthropic 最新的用于处理高度复杂任务的最强大模型。它在性能、智能、流畅性和理解力方面表现卓越。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'claude-3-5-haiku-latest', 'Claude 3.5 Haiku', 'chat', 200000, 64000, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Claude 3.5 Haiku 提供快速响应，适合轻量级任务。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'gemini-2.5-pro', 'Gemini 2.5 Pro', 'chat', 1114112, 65536, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "released_at": "2025-03-25", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Pro 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'gemini-2.5-flash', 'Gemini 2.5 flash', 'chat', 65536, 65536, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "released_at": "2025-03-25", "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 flash 是 Google 快速响应的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'gemini-2.5-flash-lite', 'Gemini 2.5 Flash-Lite', 'chat', 1048576, 8192, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "released_at": "2025-06-17", "source": "builtin", "maxToken": 1048576, "contextWindowTokens": 1048576, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 2.5 Flash 模型，针对成本效益和低延迟等目标进行了优化。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'gemini-2.0-flash', 'Gemini 2.0 Flash', 'chat', 1000000, 8192, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Google 最新的 Gemini 2.0 Flash 模型，拥有超大上下文窗口。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'grok-4-0709', 'Grok 4', 'chat', 131072, 4096, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "xAI 的 Grok 4，具备强大的推理能力。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'grok-3', 'Grok 3', 'chat', 131072, 4096, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "xAI 的 Grok 3，具备强大的推理能力。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'grok-3-mini', 'Grok 3 Mini', 'chat', 100000, 32000, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 100000, "contextWindowTokens": 100000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "xAI 的 Grok 3 Mini，具备强大的推理能力和快速响应。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'deepseek-v3.1', 'deepseek-v3.1', 'chat', 128000, 8000, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 8000, "maxOutput": 8000, "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'deepseek-v3', 'DeepSeek V3', 'chat', 64000, 64000, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "DeepSeek V3 是最新的大规模语言模型，在推理、代码生成和多语言理解方面表现优异。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'deepseek-r1-0528', 'DeepSeek R1', 'chat', 64000, 64000, NULL, NULL, '{"abilities": {"functionCall": true}, "released_at": "2025-05-28", "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "DeepSeek R1 推理模型，专门用于复杂的逻辑推理和数学计算任务。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'deepseek-reasoner', 'DeepSeek Reasoner', 'chat', 64000, 64000, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "DeepSeek 推理模型，专注于复杂的逻辑推理任务。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'cometapi'), 'deepseek-chat', 'DeepSeek Chat', 'chat', 64000, 64000, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "DeepSeek 聊天模型，在代码和推理方面表现优秀。", "function_calling": true}', TRUE),
    -- comfyui
    ((SELECT id FROM ai_providers WHERE code = 'comfyui'), 'comfyui/flux-schnell', 'FLUX.1 Schnell', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"aspectRatio": {"default": "1:1", "enum": ["21:9", "16:9", "8:7", "4:3", "3:2", "1:1", "2:3", "3:4", "7:8", "9:16", "9:21"]}, "cfg": {"default": 1, "max": 1, "min": 1, "step": 0}, "height": {"default": 1024, "max": 1536, "min": 512, "step": 8}, "prompt": {"default": ""}, "samplerName": {"default": "euler"}, "scheduler": {"default": "simple"}, "seed": {"default": null}, "steps": {"default": 4, "max": 4, "min": 1, "step": 1}, "width": {"default": 1024, "max": 1536, "min": 512, "step": 8}}, "released_at": "2024-08-01", "source": "builtin", "description": "FLUX.1 Schnell - 超快速文生图模型，1-4步即可生成高质量图像，适合实时应用和快速原型制作"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'comfyui'), 'comfyui/flux-dev', 'FLUX.1 Dev', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"aspectRatio": {"default": "1:1", "enum": ["21:9", "16:9", "8:7", "4:3", "3:2", "1:1", "2:3", "3:4", "7:8", "9:16", "9:21"]}, "cfg": {"default": 3.5, "max": 10, "min": 1, "step": 0.5}, "height": {"default": 1024, "max": 2048, "min": 512, "step": 8}, "prompt": {"default": ""}, "samplerName": {"default": "euler"}, "scheduler": {"default": "simple"}, "seed": {"default": null}, "steps": {"default": 20, "max": 50, "min": 10, "step": 1}, "width": {"default": 1024, "max": 2048, "min": 512, "step": 8}}, "released_at": "2024-08-01", "source": "builtin", "description": "FLUX.1 Dev - 高质量文生图模型，10-50步生成，适合高质量创作和艺术作品生成"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'comfyui'), 'comfyui/flux-krea-dev', 'FLUX.1 Krea-dev', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"aspectRatio": {"default": "1:1", "enum": ["21:9", "16:9", "8:7", "4:3", "3:2", "1:1", "2:3", "3:4", "7:8", "9:16", "9:21"]}, "cfg": {"default": 3.5, "max": 10, "min": 1, "step": 0.5}, "height": {"default": 1024, "max": 2048, "min": 512, "step": 8}, "prompt": {"default": ""}, "samplerName": {"default": "dpmpp_2m_sde"}, "scheduler": {"default": "karras"}, "seed": {"default": null}, "steps": {"default": 15, "max": 50, "min": 10, "step": 1}, "width": {"default": 1024, "max": 2048, "min": 512, "step": 8}}, "released_at": "2025-07-31", "source": "builtin", "description": "FLUX.1 Krea-dev - 增强安全的文生图模型，与 Krea 合作开发，内置安全过滤"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'comfyui'), 'comfyui/flux-kontext-dev', 'FLUX.1 Kontext-dev', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"cfg": {"default": 3.5, "max": 10, "min": 1, "step": 0.5}, "imageUrl": {"default": ""}, "prompt": {"default": ""}, "seed": {"default": null}, "steps": {"default": 28, "max": 50, "min": 10, "step": 1}, "strength": {"default": 0.85, "max": 1, "min": 0, "step": 0.05}}, "released_at": "2025-05-29", "source": "builtin", "description": "FLUX.1 Kontext-dev - 图像编辑模型，支持基于文本指令修改现有图像，支持局部修改和风格迁移"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'comfyui'), 'comfyui/stable-diffusion-35', 'Stable Diffusion 3.5', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"aspectRatio": {"default": "1:1", "enum": ["21:9", "16:9", "8:7", "4:3", "3:2", "1:1", "2:3", "3:4", "7:8", "9:16", "9:21"]}, "cfg": {"default": 4, "max": 20, "min": 1, "step": 0.5}, "height": {"default": 1024, "max": 2048, "min": 512, "step": 8}, "prompt": {"default": ""}, "samplerName": {"default": "euler"}, "scheduler": {"default": "sgm_uniform"}, "seed": {"default": null}, "steps": {"default": 20, "max": 50, "min": 10, "step": 1}, "width": {"default": 1024, "max": 2048, "min": 512, "step": 8}}, "released_at": "2024-10-22", "source": "builtin", "description": "Stable Diffusion 3.5 新一代文生图模型，支持 Large 和 Medium 两个版本，需要外部 CLIP 编码器文件，提供卓越的图像质量和提示词匹配度。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'comfyui'), 'comfyui/stable-diffusion-35-inclclip', 'Stable Diffusion 3.5 (内置编码器)', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"aspectRatio": {"default": "1:1", "enum": ["21:9", "16:9", "8:7", "4:3", "3:2", "1:1", "2:3", "3:4", "7:8", "9:16", "9:21"]}, "cfg": {"default": 4, "max": 20, "min": 1, "step": 0.5}, "height": {"default": 1024, "max": 2048, "min": 512, "step": 8}, "prompt": {"default": ""}, "samplerName": {"default": "euler"}, "scheduler": {"default": "sgm_uniform"}, "seed": {"default": null}, "steps": {"default": 20, "max": 50, "min": 10, "step": 1}, "width": {"default": 1024, "max": 2048, "min": 512, "step": 8}}, "released_at": "2024-10-22", "source": "builtin", "description": "Stable Diffusion 3.5 内置 CLIP/T5 编码器版本，无需外部编码器文件，适用于 sd3.5_medium_incl_clips 等模型，资源占用更少。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'comfyui'), 'comfyui/stable-diffusion-15', 'SD 1.5', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"aspectRatio": {"default": "1:1", "enum": ["1:1", "4:3", "16:9", "3:2", "2:3", "9:16", "21:9"]}, "cfg": {"default": 7, "max": 20, "min": 1, "step": 0.5}, "height": {"default": 512, "max": 1024, "min": 256, "step": 8}, "prompt": {"default": ""}, "samplerName": {"default": "euler"}, "scheduler": {"default": "normal"}, "seed": {"default": null}, "steps": {"default": 25, "max": 50, "min": 10, "step": 1}, "width": {"default": 512, "max": 1024, "min": 256, "step": 8}}, "released_at": "2022-08-22", "source": "builtin", "description": "Stable Diffusion 1.5 文生图模型，经典的512x512分辨率文本到图像生成，适合快速原型和创意实验"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'comfyui'), 'comfyui/stable-diffusion-xl', 'SDXL 文生图', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"aspectRatio": {"default": "1:1", "enum": ["16:9", "4:3", "3:2", "1:1", "2:3", "3:4", "9:16"]}, "cfg": {"default": 8, "max": 20, "min": 1, "step": 0.5}, "height": {"default": 1024, "max": 2048, "min": 512, "step": 8}, "prompt": {"default": ""}, "samplerName": {"default": "euler"}, "scheduler": {"default": "normal"}, "seed": {"default": null}, "steps": {"default": 30, "max": 50, "min": 10, "step": 1}, "width": {"default": 1024, "max": 2048, "min": 512, "step": 8}}, "released_at": "2023-07-26", "source": "builtin", "description": "SDXL 文生图模型，支持1024x1024高分辨率文本到图像生成，提供更好的图像质量和细节表现"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'comfyui'), 'comfyui/stable-diffusion-refiner', 'SDXL Refiner', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"cfg": {"default": 8, "max": 20, "min": 1, "step": 0.5}, "imageUrl": {"default": ""}, "prompt": {"default": ""}, "samplerName": {"default": "euler"}, "scheduler": {"default": "normal"}, "seed": {"default": null}, "steps": {"default": 30, "max": 50, "min": 10, "step": 1}, "strength": {"default": 0.75, "max": 1, "min": 0, "step": 0.05}}, "released_at": "2023-07-26", "source": "builtin", "description": "SDXL 图生图模型，基于输入图像进行高质量的图像到图像转换，支持风格迁移、图像修复和创意变换。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'comfyui'), 'comfyui/stable-diffusion-custom', '自定义 SD 文生图', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"aspectRatio": {"default": "1:1", "enum": ["16:9", "4:3", "3:2", "1:1", "2:3", "3:4", "9:16"]}, "cfg": {"default": 7, "max": 30, "min": 1, "step": 0.5}, "height": {"default": 768, "max": 2048, "min": 256, "step": 8}, "prompt": {"default": ""}, "samplerName": {"default": "euler"}, "scheduler": {"default": "normal"}, "seed": {"default": null}, "steps": {"default": 25, "max": 100, "min": 5, "step": 1}, "width": {"default": 768, "max": 2048, "min": 256, "step": 8}}, "released_at": "2023-01-01", "source": "builtin", "description": "自定义 SD 文生图模型，模型文件名请使用 custom_sd_lobe.safetensors，如有 VAE 请使用 custom_sd_vae_lobe.safetensors，模型文件需要按照 Comfy 的要求放入对应文件夹"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'comfyui'), 'comfyui/stable-diffusion-custom-refiner', '自定义 SDXL Refiner', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"cfg": {"default": 7, "max": 30, "min": 1, "step": 0.5}, "imageUrl": {"default": ""}, "prompt": {"default": ""}, "samplerName": {"default": "euler"}, "scheduler": {"default": "normal"}, "seed": {"default": null}, "steps": {"default": 25, "max": 100, "min": 5, "step": 1}, "strength": {"default": 0.75, "max": 1, "min": 0, "step": 0.05}}, "released_at": "2023-01-01", "source": "builtin", "description": "自定义 SDXL 图生图模型，模型文件名请使用 custom_sd_lobe.safetensors，如有 VAE 请使用 custom_sd_vae_lobe.safetensors，模型文件需要按照 Comfy 的要求放入对应文件夹"}', FALSE),
    -- deepseek
    ((SELECT id FROM ai_providers WHERE code = 'deepseek'), 'deepseek-chat', 'DeepSeek V3.2 Exp', 'chat', 131072, 8192, 0.002, 0.003, '{"abilities": {"functionCall": true, "structuredOutput": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput_cacheRead", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-29", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "DeepSeek V3.2 是 DeepSeek 最新发布的通用大模型，支持混合推理架构，具备更强的 Agent 能力。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'deepseek'), 'deepseek-reasoner', 'DeepSeek V3.2 Exp Thinking', 'chat', 131072, 65536, 0.002, 0.003, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput_cacheRead", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-29", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "DeepSeek V3.2 思考模式。在输出最终回答之前，模型会先输出一段思维链内容，以提升最终答案的准确性。", "reasoning": true, "function_calling": true}', TRUE),
    -- fal
    ((SELECT id FROM ai_providers WHERE code = 'fal'), 'fal-ai/nano-banana', 'Nano Banana', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.039, "strategy": "fixed", "unit": "image"}]}, "parameters": {"imageUrls": {"default": [], "maxCount": 10}, "prompt": {"default": ""}}, "released_at": "2025-08-26", "source": "builtin", "description": "Nano Banana 是 Google 最新、最快、最高效的原生多模态模型，它允许您通过对话生成和编辑图像。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fal'), 'fal-ai/bytedance/seedream/v4', 'Seedream 4.0', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.03, "strategy": "fixed", "unit": "image"}]}, "parameters": {"height": {"default": 1024, "max": 4096, "min": 1024, "step": 1}, "imageUrls": {"default": [], "maxCount": 10, "maxFileSize": 10485760}, "prompt": {"default": ""}, "seed": {"default": null}, "width": {"default": 1024, "max": 4096, "min": 1024, "step": 1}}, "released_at": "2025-09-09", "source": "builtin", "description": "Seedream 4.0 图片生成模型由字节跳动 Seed 团队研发，支持文字与图片输入，提供高可控、高质量的图片生成体验。基于文本提示词生成图片。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fal'), 'fal-ai/hunyuan-image/v3', 'HunyuanImage 3.0', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.1, "strategy": "fixed", "unit": "megapixel"}]}, "parameters": {"cfg": {"default": 7.5, "max": 20, "min": 1, "step": 0.1}, "prompt": {"default": ""}, "seed": {"default": null}, "size": {"default": "square_hd", "enum": ["square_hd", "square", "portrait_4_3", "portrait_16_9", "landscape_4_3", "landscape_16_9"]}, "steps": {"default": 28, "max": 50, "min": 1, "step": 1}}, "released_at": "2025-09-28", "source": "builtin", "description": "一个强大的原生多模态图像生成模型"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fal'), 'fal-ai/flux-kontext/dev', 'FLUX.1 Kontext [dev]', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.025, "strategy": "fixed", "unit": "megapixel"}]}, "parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "seed": {"default": null}, "steps": {"default": 28, "max": 50, "min": 10}}, "released_at": "2025-06-28", "source": "builtin", "description": "专注于图像编辑任务的FLUX.1模型，支持文本和图像输入。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fal'), 'fal-ai/flux-pro/kontext', 'FLUX.1 Kontext [pro]', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.04, "strategy": "fixed", "unit": "image"}]}, "parameters": {"aspectRatio": {"default": "1:1", "enum": ["21:9", "16:9", "4:3", "3:2", "1:1", "2:3", "3:4", "9:16", "9:21"]}, "imageUrl": {"default": null}, "prompt": {"default": ""}, "seed": {"default": null}}, "released_at": "2025-05-01", "source": "builtin", "description": "FLUX.1 Kontext [pro] 能够处理文本和参考图像作为输入，无缝实现目标性的局部编辑和复杂的整体场景变换。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fal'), 'fal-ai/flux/schnell', 'FLUX.1 Schnell', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.003, "strategy": "fixed", "unit": "megapixel"}]}, "parameters": {"height": {"default": 1024, "max": 1536, "min": 512, "step": 1}, "prompt": {"default": ""}, "seed": {"default": null}, "steps": {"default": 4, "max": 12, "min": 1, "step": 1}, "width": {"default": 1024, "max": 1536, "min": 512, "step": 1}}, "released_at": "2024-08-01", "source": "builtin", "description": "FLUX.1 [schnell] 是一个具有120亿参数的图像生成模型，专注于快速生成高质量图像。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fal'), 'fal-ai/flux/krea', 'FLUX.1 Krea [dev]', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.025, "strategy": "fixed", "unit": "megapixel"}]}, "parameters": {"cfg": {"default": 7.5, "max": 20, "min": 0, "step": 0.1}, "height": {"default": 1248, "max": 2048, "min": 512, "step": 1}, "prompt": {"default": ""}, "seed": {"default": null}, "steps": {"default": 28, "max": 50, "min": 1, "step": 1}, "width": {"default": 832, "max": 2048, "min": 512, "step": 1}}, "released_at": "2025-07-31", "source": "builtin", "description": "Flux Krea [dev] 是一个有美学偏好的图像生成模型，目标是生成更加真实、自然的图像。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fal'), 'fal-ai/imagen4/preview', 'Imagen 4', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.05, "strategy": "fixed", "unit": "image"}]}, "parameters": {"aspectRatio": {"default": "1:1", "enum": ["1:1", "16:9", "9:16", "3:4", "4:3"]}, "prompt": {"default": ""}, "seed": {"default": null}}, "released_at": "2025-05-21", "source": "builtin", "description": "Google 提供的高质量的图像生成模型", "organization": "Deepmind"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fal'), 'fal-ai/qwen-image-edit', 'Qwen Edit', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.03, "strategy": "fixed", "unit": "megapixel"}]}, "parameters": {"cfg": {"default": 4, "max": 20, "min": 0, "step": 0.1}, "height": {"default": 1328, "max": 1536, "min": 512, "step": 1}, "imageUrl": {"default": null}, "prompt": {"default": ""}, "seed": {"default": null}, "steps": {"default": 30, "max": 50, "min": 2, "step": 1}, "width": {"default": 1328, "max": 1536, "min": 512, "step": 1}}, "released_at": "2025-08-19", "source": "builtin", "description": "Qwen 团队发布的专业图像编辑模型，支持语义编辑和外观编辑，能够精确编辑中英文文字，实现风格转换、对象旋转等高质量图像编辑。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fal'), 'fal-ai/qwen-image', 'Qwen Image', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.02, "strategy": "fixed", "unit": "megapixel"}]}, "parameters": {"cfg": {"default": 2.5, "max": 20, "min": 0, "step": 0.1}, "height": {"default": 1328, "max": 1536, "min": 512, "step": 1}, "prompt": {"default": ""}, "seed": {"default": null}, "steps": {"default": 30, "max": 50, "min": 2, "step": 1}, "width": {"default": 1328, "max": 1536, "min": 512, "step": 1}}, "released_at": "2025-08-04", "source": "builtin", "description": "Qwen 团队带来的强大生图模型，具有令人印象深刻的中文文字生成能力和多样图片视觉风格。"}', TRUE),
    -- fireworksai
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/llama-v3p3-70b-instruct', 'Llama 3.3 70B Instruct', 'chat', 131072, NULL, 0.0009, 0.0009, '{"pricing": {"units": [{"name": "textInput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Llama 3.3 70B Instruct 是 Llama 3.1 70B 的 12 月更新版本。该模型在 Llama 3.1 70B（于 2024 年 7 月发布）的基础上进行了改进，增强了工具调用、多语言文本支持、数学和编程能力。该模型在推理、数学和指令遵循方面达到了行业领先水平，并且能够提供与 3.1 405B 相似的性能，同时在速度和成本上具有显著优势。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/llama-v3p2-3b-instruct', 'Llama 3.2 3B Instruct', 'chat', 131072, NULL, 0.0001, 0.0001, '{"pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Llama 3.2 3B Instruct 是 Meta 推出的轻量级多语言模型。该模型专为高效运行而设计，相较于更大型的模型，具有显著的延迟和成本优势。其典型应用场景包括查询和提示重写，以及写作辅助。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/llama-v3p2-11b-vision-instruct', 'Llama 3.2 11B Vision Instruct', 'chat', 131072, NULL, 0.0002, 0.0002, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Meta 推出的指令微调图像推理模型，拥有 110 亿参数。该模型针对视觉识别、图像推理、图片字幕生成以及图片相关的常规问答进行了优化。它能够理解视觉数据，如图表和图形，并通过生成文本描述图像细节，弥合视觉与语言之间的鸿沟。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/llama-v3p2-90b-vision-instruct', 'Llama 3.2 90B Vision Instruct', 'chat', 131072, NULL, 0.0009, 0.0009, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Meta 推出的指令微调图像推理模型，拥有 900 亿参数。该模型针对视觉识别、图像推理、图片字幕生成以及图片相关的常规问答进行了优化。它能够理解视觉数据，如图表和图形，并通过生成文本描述图像细节，弥合视觉与语言之间的鸿沟。注意：该模型目前作为无服务器模型进行实验性提供。如果用于生产环境，请注意 Fireworks 可能会在短时间内取消部署该模型。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/llama-v3p1-8b-instruct', 'Llama 3.1 8B Instruct', 'chat', 131072, NULL, 0.0002, 0.0002, '{"pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Meta Llama 3.1 系列是多语言大语言模型（LLM）集合，包含 8B、70B 和 405B 三种参数规模的预训练和指令微调生成模型。Llama 3.1 指令微调文本模型（8B、70B、405B）专为多语言对话应用优化，并在常见的行业基准测试中优于许多现有的开源和闭源聊天模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/llama-v3p1-70b-instruct', 'Llama 3.1 70B Instruct', 'chat', 131072, NULL, 0.0009, 0.0009, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Meta Llama 3.1 系列是多语言大语言模型（LLM）集合，包含 8B、70B 和 405B 三种参数规模的预训练和指令微调生成模型。Llama 3.1 指令微调文本模型（8B、70B、405B）专为多语言对话应用优化，并在常见的行业基准测试中优于许多现有的开源和闭源聊天模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/llama-v3p1-405b-instruct', 'Llama 3.1 405B Instruct', 'chat', 131072, NULL, 0.003, 0.003, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Meta Llama 3.1 系列是多语言大语言模型（LLM）集合，包含 8B、70B 和 405B 参数规模的预训练和指令微调生成模型。Llama 3.1 指令微调文本模型（8B、70B、405B）专为多语言对话场景优化，在常见的行业基准测试中优于许多现有的开源和闭源聊天模型。405B 是 Llama 3.1 家族中能力最强的模型。该模型采用 FP8 进行推理，与参考实现高度匹配。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/llama-v3-8b-instruct', 'Llama 3 8B Instruct', 'chat', 8192, NULL, 0.0002, 0.0002, '{"pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Meta 开发并发布了 Meta Llama 3 系列大语言模型（LLM），这是一个包含 8B 和 70B 参数规模的预训练和指令微调生成文本模型的集合。Llama 3 指令微调模型专为对话应用场景优化，并在常见的行业基准测试中优于许多现有的开源聊天模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/llama-v3-70b-instruct', 'Llama 3 70B Instruct', 'chat', 8192, NULL, 0.0009, 0.0009, '{"pricing": {"units": [{"name": "textInput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Meta 开发并发布了 Meta Llama 3 系列大语言模型（LLM），该系列包含 8B 和 70B 参数规模的预训练和指令微调生成文本模型。Llama 3 指令微调模型专为对话应用场景优化，并在常见的行业基准测试中优于许多现有的开源聊天模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/llama-v3-8b-instruct-hf', 'Llama 3 8B Instruct (HF version)', 'chat', 8192, NULL, 0.0002, 0.0002, '{"pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Meta Llama 3 指令微调模型专为对话应用场景优化，并在常见的行业基准测试中优于许多现有的开源聊天模型。Llama 3 8B Instruct（HF 版本）是 Llama 3 8B Instruct 的原始 FP16 版本，其结果应与官方 Hugging Face 实现一致。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/mistral-small-24b-instruct-2501', 'Mistral Small 3 Instruct', 'chat', 32768, NULL, 0.0009, 0.0009, '{"pricing": {"units": [{"name": "textInput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "24B 参数模型，具备与更大型模型相当的最先进能力。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/mixtral-8x7b-instruct', 'Mixtral MoE 8x7B Instruct', 'chat', 32768, NULL, 0.0005, 0.0005, '{"pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Mixtral MoE 8x7B Instruct 是 Mixtral MoE 8x7B 的指令微调版本，已启用聊天完成功能 API。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/mixtral-8x22b-instruct', 'Mixtral MoE 8x22B Instruct', 'chat', 65536, NULL, 0.0012, 0.0012, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "Mixtral MoE 8x22B Instruct v0.1 是 Mixtral MoE 8x22B v0.1 的指令微调版本，已启用聊天完成功能 API。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/phi-3-vision-128k-instruct', 'Phi 3.5 Vision Instruct', 'chat', 32064, NULL, 0.0002, 0.0002, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32064, "contextWindowTokens": 32064, "description": "Phi-3-Vision-128K-Instruct 是一个轻量级的、最先进的开放多模态模型，基于包括合成数据和筛选后的公开网站数据集构建，重点关注文本和视觉方面的高质量、推理密集型数据。该模型属于 Phi-3 模型家族，其多模态版本支持 128K 上下文长度（以标记为单位）。该模型经过严格的增强过程，包括监督微调和直接偏好优化，以确保精确的指令遵循和强大的安全措施。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/mythomax-l2-13b', 'MythoMax L2 13b', 'chat', 32768, NULL, 0.0002, 0.0002, '{"pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "MythoMix 的改进版，可能是其更为完善的变体，是 MythoLogic-L2 和 Huginn 的合并，采用了高度实验性的张量类型合并技术。由于其独特的性质，该模型在讲故事和角色扮演方面表现出色。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/deepseek-v3', 'Deepseek V3', 'chat', 131072, NULL, 0.0009, 0.0009, '{"pricing": {"units": [{"name": "textInput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Deepseek 提供的强大 Mixture-of-Experts (MoE) 语言模型，总参数量为 671B，每个标记激活 37B 参数。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/deepseek-r1', 'Deepseek R1', 'chat', 163840, NULL, 0.008, 0.008, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek-R1 是一款最先进的大型语言模型，经过强化学习和冷启动数据的优化，具有出色的推理、数学和编程性能。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/qwen-qwq-32b-preview', 'Qwen Qwq 32b Preview', 'chat', 32768, NULL, 0.0009, 0.0009, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen QwQ 模型专注于推动 AI 推理，并展示了开放模型在推理能力上与闭源前沿模型匹敌的力量。QwQ-32B-Preview 是一个实验性发布版本，在 GPQA、AIME、MATH-500 和 LiveCodeBench 基准测试中，在分析和推理能力上可与 o1 相媲美，并超越 GPT-4o 和 Claude 3.5 Sonnet。注意：该模型目前作为无服务器模型进行实验性提供。如果用于生产环境，请注意 Fireworks 可能会在短时间内取消部署该模型。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/qwen2p5-72b-instruct', 'Qwen2.5 72B Instruct', 'chat', 32768, NULL, 0.0009, 0.0009, '{"pricing": {"units": [{"name": "textInput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5 是由 Qwen 团队和阿里云开发的一系列仅解码语言模型，提供 0.5B、1.5B、3B、7B、14B、32B 和 72B 不同参数规模，并包含基础版和指令微调版。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/qwen2-vl-72b-instruct', 'Qwen2 VL 72B Instruct', 'chat', 32768, NULL, 0.0009, 0.0009, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen-VL 模型的 72B 版本是阿里巴巴最新迭代的成果，代表了近一年的创新。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/fireworks/models/qwen2p5-coder-32b-instruct', 'Qwen2.5-Coder-32B-Instruct', 'chat', 32768, NULL, 0.0009, 0.0009, '{"pricing": {"units": [{"name": "textInput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5-Coder 是最新一代专为代码设计的 Qwen 大型语言模型（前称为 CodeQwen）。注意：该模型目前作为无服务器模型进行实验性提供。如果用于生产环境，请注意 Fireworks 可能会在短时间内取消部署该模型。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'fireworksai'), 'accounts/yi-01-ai/models/yi-large', 'Yi-Large', 'chat', 32768, NULL, 0.003, 0.003, '{"pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Yi-Large 是顶尖的大型语言模型之一，在 LMSYS 基准测试排行榜上，其表现仅次于 GPT-4、Gemini 1.5 Pro 和 Claude 3 Opus。它在多语言能力方面表现卓越，特别是在西班牙语、中文、日语、德语和法语方面。Yi-Large 还具有用户友好性，采用与 OpenAI 相同的 API 定义，便于集成。"}', TRUE),
    -- giteeai
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'DeepSeek-R1-Distill-Qwen-1.5B', 'DeepSeek R1 Distill Qwen 1.5B', 'chat', 32000, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "基于 Qwen2.5-Math-1.5B 的 DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'DeepSeek-R1-Distill-Qwen-7B', 'DeepSeek R1 Distill Qwen 7B', 'chat', 32000, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "基于 Qwen2.5-Math-7B 的 DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'DeepSeek-R1-Distill-Qwen-14B', 'DeepSeek R1 Distill Qwen 14B', 'chat', 32000, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "基于 Qwen2.5-14B 的 DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'DeepSeek-R1-Distill-Qwen-32B', 'DeepSeek R1 Distill Qwen 32B', 'chat', 32000, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "DeepSeek-R1 系列通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆，超越 OpenAI-o1-mini 水平。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'QwQ-32B-Preview', 'QwQ 32B Preview', 'chat', 32000, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "QwQ-32B-Preview 是一款独具创新的自然语言处理模型，能够高效处理复杂的对话生成与上下文理解任务。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'Qwen2.5-72B-Instruct', 'Qwen2.5 72B Instruct', 'chat', 16000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "description": "Qwen2.5-72B-Instruct  支持 16k 上下文, 生成长文本超过 8K 。支持 function call 与外部系统无缝交互，极大提升了灵活性和扩展性。模型知识明显增加，并且大大提高了编码和数学能力, 多语言支持超过 29 种", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'Qwen2.5-32B-Instruct', 'Qwen2.5 32B Instruct', 'chat', 32000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "Qwen2.5-32B-Instruct 是一款 320 亿参数的大语言模型，性能表现均衡，优化中文和多语言场景，支持智能问答、内容生成等应用。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'Qwen2.5-14B-Instruct', 'Qwen2.5 14B Instruct', 'chat', 24000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 24000, "contextWindowTokens": 24000, "description": "Qwen2.5-14B-Instruct 是一款 140 亿参数的大语言模型，性能表现优秀，优化中文和多语言场景，支持智能问答、内容生成等应用。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'Qwen2.5-7B-Instruct', 'Qwen2.5 7B Instruct', 'chat', 32000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "Qwen2.5-7B-Instruct 是一款 70 亿参数的大语言模型，支持 function call 与外部系统无缝交互，极大提升了灵活性和扩展性。优化中文和多语言场景，支持智能问答、内容生成等应用。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'Qwen2-72B-Instruct', 'Qwen2 72B Instruct', 'chat', 32000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "Qwen2 是 Qwen 模型的最新系列，支持 128k 上下文，对比当前最优的开源模型，Qwen2-72B 在自然语言理解、知识、代码、数学及多语言等多项能力上均显著超越当前领先的模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'Qwen2-7B-Instruct', 'Qwen2 7B Instruct', 'chat', 24000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 24000, "contextWindowTokens": 24000, "description": "Qwen2 是 Qwen 模型的最新系列，能够超越同等规模的最优开源模型甚至更大规模的模型，Qwen2 7B 在多个评测上取得显著的优势，尤其是代码及中文理解上。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'Qwen2.5-Coder-32B-Instruct', 'Qwen2.5 Coder 32B Instruct', 'chat', 32000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "Qwen2.5-Coder-32B-Instruct 是一款专为代码生成、代码理解和高效开发场景设计的大型语言模型，采用了业界领先的32B参数规模，能够满足多样化的编程需求。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'Qwen2.5-Coder-14B-Instruct', 'Qwen2.5 Coder 14B Instruct', 'chat', 24000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 24000, "contextWindowTokens": 24000, "description": "Qwen2.5-Coder-14B-Instruct 是一款基于大规模预训练的编程指令模型，具备强大的代码理解和生成能力，能够高效地处理各种编程任务，特别适合智能代码编写、自动化脚本生成和编程问题解答。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'Qwen2-VL-72B', 'Qwen2 VL 72B', 'chat', 32000, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "Qwen2-VL-72B是一款强大的视觉语言模型，支持图像与文本的多模态处理，能够精确识别图像内容并生成相关描述或回答。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'InternVL2.5-26B', 'InternVL2.5 26B', 'chat', 32000, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "InternVL2.5-26B 是一款强大的视觉语言模型，支持图像与文本的多模态处理，能够精确识别图像内容并生成相关描述或回答。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'InternVL2-8B', 'InternVL2 8B', 'chat', 32000, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "InternVL2-8B 是一款强大的视觉语言模型，支持图像与文本的多模态处理，能够精确识别图像内容并生成相关描述或回答。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'glm-4-9b-chat', 'GLM4 9B Chat', 'chat', 32000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "GLM-4-9B-Chat 在语义、数学、推理、代码和知识等多方面均表现出较高性能。还具备网页浏览、代码执行、自定义工具调用和长文本推理。 支持包括日语，韩语，德语在内的 26 种语言。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'Yi-34B-Chat', 'Yi 34B Chat', 'chat', 4000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 4000, "contextWindowTokens": 4000, "description": "Yi-1.5-34B 在保持原系列模型优秀的通用语言能力的前提下，通过增量训练 5 千亿高质量 token，大幅提高了数学逻辑、代码能力。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'deepseek-coder-33B-instruct', 'DeepSeek Coder 33B Instruct', 'chat', 8000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "DeepSeek Coder 33B 是一个代码语言模型， 基于 2 万亿数据训练而成，其中 87% 为代码， 13% 为中英文语言。模型引入 16K 窗口大小和填空任务，提供项目级别的代码补全和片段填充功能。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'codegeex4-all-9b', 'CodeGeeX4 All 9B', 'chat', 32000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "CodeGeeX4-ALL-9B 是一个多语言代码生成模型，支持包括代码补全和生成、代码解释器、网络搜索、函数调用、仓库级代码问答在内的全面功能，覆盖软件开发的各种场景。是参数少于 10B 的顶尖代码生成模型。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'FLUX.1-dev', 'FLUX.1-dev', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024", "1536x1536"]}}, "source": "builtin", "description": "FLUX.1-dev 是由 Black Forest Labs 开发的一款开源 多模态语言模型（Multimodal Language Model, MLLM），专为图文任务优化，融合了图像和文本的理解与生成能力。它建立在先进的大语言模型（如 Mistral-7B）基础上，通过精心设计的视觉编码器与多阶段指令微调，实现了图文协同处理与复杂任务推理的能力。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'flux-1-schnell', 'flux-1-schnell', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024", "1536x1536", "2048x2048"]}}, "source": "builtin", "description": "由 Black Forest Labs 开发的 120 亿参数文生图模型，采用潜在对抗扩散蒸馏技术，能够在 1 到 4 步内生成高质量图像。该模型性能媲美闭源替代品，并在 Apache-2.0 许可证下发布，适用于个人、科研和商业用途。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'FLUX.1-Kontext-dev', 'FLUX.1-Kontext-dev', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024", "1536x1536", "2048x2048"]}}, "source": "builtin", "description": "FLUX.1-Kontext-dev 是由 Black Forest Labs 开发的一款基于 Rectified Flow Transformer 架构 的多模态图像生成与编辑模型，拥有 12B（120 亿）参数规模，专注于在给定上下文条件下生成、重构、增强或编辑图像。该模型结合了扩散模型的可控生成优势与 Transformer 的上下文建模能力，支持高质量图像输出，广泛适用于图像修复、图像补全、视觉场景重构等任务。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'stable-diffusion-3.5-large-turbo', 'stable-diffusion-3.5-large-turbo', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024"]}}, "source": "builtin", "description": "Stable Diffusion 3.5 Large Turbo 专注于高质量图像生成，具备强大的细节表现力和场景还原能力。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'stable-diffusion-3-medium', 'stable-diffusion-3-medium', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024"]}}, "source": "builtin", "description": "由 Stability AI 推出的最新文生图大模型。这一版本在继承了前代的优点上，对图像质量、文本理解和风格多样性等方面进行了显著改进，能够更准确地解读复杂的自然语言提示，并生成更为精确和多样化的图像。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'stable-diffusion-xl-base-1.0', 'stable-diffusion-xl-base-1.0', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024"]}}, "source": "builtin", "description": "由 Stability AI 开发并开源的文生图大模型，其创意图像生成能力位居行业前列。具备出色的指令理解能力，能够支持反向 Prompt 定义来精确生成内容。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'Kolors', 'Kolors', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024"]}}, "source": "builtin", "description": "Kolors 是由快手 Kolors 团队开发的文生图模型。由数十亿的参数训练，在视觉质量、中文语义理解和文本渲染方面有显著优势。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'HunyuanDiT-v1.2-Diffusers-Distilled', 'HunyuanDiT-v1.2-Diffusers-Distilled', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024"]}}, "source": "builtin", "description": "hunyuandit-v1.2-distilled 是一款轻量级的文生图模型，经过蒸馏优化，能够快速生成高质量的图像，特别适用于低资源环境和实时生成任务。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'HiDream-I1-Full', 'HiDream-I1-Full', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024"]}}, "source": "builtin", "description": "HiDream-I1 是一个全新的开源图像生成基础模型，是由国内企业智象未来开源的。拥有 170 亿参数(Flux是12B参数)，能够在几秒内实现行业领先的图像生成质量。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'HiDream-I1-Full', 'HiDream-E1-Full', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024"]}}, "source": "builtin", "description": "HiDream-E1-Full 是由智象未来（HiDream.ai）推出的一款 开源多模态图像编辑大模型，基于先进的 Diffusion Transformer 架构，并结合强大的语言理解能力（内嵌 LLaMA 3.1-8B-Instruct），支持通过自然语言指令进行图像生成、风格迁移、局部编辑和内容重绘，具备出色的图文理解与执行能力。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'HelloMeme', 'HelloMeme', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024"]}}, "source": "builtin", "description": "HelloMeme 是一个可以根据你提供的图片或动作，自动生成表情包、动图或短视频的 AI 工具。它不需要你有任何绘画或编程基础，只需要准备好参考图片，它就能帮你做出好看、有趣、风格一致的内容。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'OmniConsistency', 'OmniConsistency', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024"]}}, "source": "builtin", "description": "OmniConsistency 通过引入大规模 Diffusion Transformers（DiTs）和配对风格化数据，提升图像到图像（Image-to-Image）任务中的风格一致性和泛化能力，避免风格退化。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'InstantCharacter', 'InstantCharacter', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024"]}}, "source": "builtin", "description": "InstantCharacter 是由腾讯 AI 团队在 2025 年发布的一款 无需微调（tuning-free） 的个性化角色生成模型，旨在实现高保真、跨场景的一致角色生成。该模型支持仅基于 一张参考图像 对角色进行建模，并能够将该角色灵活迁移到各种风格、动作和背景中。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'DreamO', 'DreamO', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024"]}}, "source": "builtin", "description": "DreamO 是由字节跳动与北京大学联合研发的开源图像定制生成模型，旨在通过统一架构支持多任务图像生成。它采用高效的组合建模方法，可根据用户指定的身份、主体、风格、背景等多个条件生成高度一致且定制化的图像。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'giteeai'), 'AnimeSharp', 'AnimeSharp', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024"]}}, "source": "builtin", "description": "AnimeSharp（又名 “4x‑AnimeSharp”） 是 Kim2091 基于 ESRGAN 架构开发的开源超分辨率模型，专注于动漫风格图像的放大与锐化。它于 2022 年 2 月重命名自 “4x-TextSharpV1”，原本也适用于文字图像但性能针对动漫内容进行了大幅优化"}', TRUE),
    -- github
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'openai/o3', 'o3', 'chat', 200000, 100000, 0.01, 0.04, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 40, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3 是一款全能强大的模型，在多个领域表现出色。它为数学、科学、编程和视觉推理任务树立了新标杆。它也擅长技术写作和指令遵循。用户可利用它分析文本、代码和图像，解决多步骤的复杂问题。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'openai/o4-mini', 'o4-mini', 'chat', 200000, 100000, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.275, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o4-mini 是我们最新的小型 o 系列模型。 它专为快速有效的推理而优化，在编码和视觉任务中表现出极高的效率和性能。", "vision": true, "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'openai/gpt-4.1', 'GPT-4.1', 'chat', 1047576, 32768, 0.002, 0.008, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 是我们用于复杂任务的旗舰模型。它非常适合跨领域解决问题。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'openai/gpt-4.1-mini', 'GPT-4.1 mini', 'chat', 1047576, 32768, 0.0004, 0.0016, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 mini 提供了智能、速度和成本之间的平衡，使其成为许多用例中有吸引力的模型。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'openai/gpt-4.1-nano', 'GPT-4.1 nano', 'chat', 1047576, 32768, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 nano 是最快，最具成本效益的GPT-4.1模型。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'openai/o3-mini', 'o3-mini', 'chat', 200000, 100000, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-31", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3-mini 是我们最新的小型推理模型，在与 o1-mini 相同的成本和延迟目标下提供高智能。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'openai/o1-mini', 'o1-mini', 'chat', 128000, 65536, 0.0011, 0.0044, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-12", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "o1-mini是一款针对编程、数学和科学应用场景而设计的快速、经济高效的推理模型。该模型具有128K上下文和2023年10月的知识截止日期。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'openai/o1', 'o1', 'chat', 200000, 100000, 0.015, 0.06, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 7.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-12-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o1是OpenAI新的推理模型，支持图文输入并输出文本，适用于需要广泛通用知识的复杂任务。该模型具有200K上下文和2023年10月的知识截止日期。", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'openai/o1-preview', 'o1-preview', 'chat', 128000, 32768, 0.015, 0.06, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-12", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "o1是OpenAI新的推理模型，适用于需要广泛通用知识的复杂任务。该模型具有128K上下文和2023年10月的知识截止日期。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'openai/gpt-4o-mini', 'GPT-4o mini', 'chat', 134144, 4096, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 134144, "contextWindowTokens": 134144, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "一种经济高效的AI解决方案，适用于多种文本和图像任务。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'openai/gpt-4o', 'GPT-4o', 'chat', 134144, 16384, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 134144, "contextWindowTokens": 134144, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "OpenAI GPT-4系列中最先进的多模态模型，可以处理文本和图像输入。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'xai/grok-3', 'Grok 3', 'chat', 134144, 4096, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 134144, "contextWindowTokens": 134144, "maxOutputTokens": 4096, "maxOutput": 4096, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'xai/grok-3-mini', 'Grok 3 mini', 'chat', 134144, 4096, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "source": "builtin", "maxToken": 134144, "contextWindowTokens": 134144, "maxOutputTokens": 4096, "maxOutput": 4096, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'microsoft/MAI-DS-R1', 'MAI DS R1', 'chat', 128000, 4096, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4096, "maxOutput": 4096, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'deepseek/DeepSeek-R1', 'DeepSeek R1', 'chat', 128000, 4096, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4096, "maxOutput": 4096, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'deepseek/DeepSeek-V3-0324', 'DeepSeek V3', 'chat', 128000, 4096, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4096, "maxOutput": 4096, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'ai21-labs/AI21-Jamba-1.5-Mini', 'AI21 Jamba 1.5 Mini', 'chat', 262144, 4096, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "一个52B参数（12B活跃）的多语言模型，提供256K长上下文窗口、函数调用、结构化输出和基于事实的生成。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'ai21-labs/AI21-Jamba-1.5-Large', 'AI21 Jamba 1.5 Large', 'chat', 262144, 4096, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "一个398B参数（94B活跃）的多语言模型，提供256K长上下文窗口、函数调用、结构化输出和基于事实的生成。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'cohere/Cohere-command-r', 'Cohere Command R', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Command R是一个可扩展的生成模型，旨在针对RAG和工具使用，使企业能够实现生产级AI。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'cohere/Cohere-command-r-plus', 'Cohere Command R+', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Command R+是一个最先进的RAG优化模型，旨在应对企业级工作负载。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'mistral-ai/Mistral-Nemo', 'Mistral Nemo', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Mistral Nemo是一种尖端的语言模型（LLM），在其尺寸类别中拥有最先进的推理、世界知识和编码能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'mistral-ai/mistral-small-2503', 'Mistral Small', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Mistral Small可用于任何需要高效率和低延迟的基于语言的任务。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'mistral-ai/Mistral-Large-2411', 'Mistral Large', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Mistral的旗舰模型，适合需要大规模推理能力或高度专业化的复杂任务（合成文本生成、代码生成、RAG或代理）。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'mistral-ai/Codestral-2501', 'Codestral', 'chat', 262144, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "maxOutputTokens": 4096, "maxOutput": 4096}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'meta/Llama-3.2-11B-Vision-Instruct', 'Llama 3.2 11B Vision', 'chat', 131072, 4096, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "在高分辨率图像上表现出色的图像推理能力，适用于视觉理解应用。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'meta/Llama-3.2-90B-Vision-Instruct', 'Llama 3.2 90B Vision', 'chat', 131072, 4096, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "适用于视觉理解代理应用的高级图像推理能力。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'meta/Llama-3.3-70B-Instruct', 'Llama 3.3 70B Instruct', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Llama 3.3 是 Llama 系列最先进的多语言开源大型语言模型，以极低成本体验媲美 405B 模型的性能。基于 Transformer 结构，并通过监督微调（SFT）和人类反馈强化学习（RLHF）提升有用性和安全性。其指令调优版本专为多语言对话优化，在多项行业基准上表现优于众多开源和封闭聊天模型。知识截止日期为 2023 年 12 月", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'llama-4-Scout-17B-16E-Instruct', 'Meta Llama 4 Scout 17B', 'chat', 10240000, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 10240000, "contextWindowTokens": 10240000, "maxOutputTokens": 4096, "maxOutput": 4096}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'meta/Llama-4-Maverick-17B-128E-Instruct-FP8', 'Meta Llama 4 Maverick 17B', 'chat', 10240000, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 10240000, "contextWindowTokens": 10240000, "maxOutputTokens": 4096, "maxOutput": 4096}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'meta/Meta-Llama-3.1-8B-Instruct', 'Meta Llama 3.1 8B', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'meta/Meta-Llama-3.1-70B-Instruct', 'Meta Llama 3.1 70B', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'meta/Meta-Llama-3.1-405B-Instruct', 'Meta Llama 3.1 405B', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'meta/Meta-Llama-3-8B-Instruct', 'Meta Llama 3 8B', 'chat', 8192, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "一个多功能的80亿参数模型，针对对话和文本生成任务进行了优化。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'meta/Meta-Llama-3-70B-Instruct', 'Meta Llama 3 70B', 'chat', 8192, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "一个强大的700亿参数模型，在推理、编码和广泛的语言应用方面表现出色。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'microsoft/Phi-4', 'Phi 4', 'chat', 16384, 16384, NULL, NULL, '{"source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "maxOutputTokens": 16384, "maxOutput": 16384}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'microsoft/Phi-3.5-MoE-instruct', 'Phi 3.5 MoE', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'microsoft/Phi-3.5-mini-instruct', 'Phi-3.5-mini 128K', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Phi-3-mini模型的更新版。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'microsoft/Phi-3.5-vision-instruct', 'Phi-3.5-vision 128K', 'chat', 131072, 4096, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Phi-3-vision模型的更新版。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'microsoft/Phi-3-mini-4k-instruct', 'Phi-3-mini 4K', 'chat', 4096, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Phi-3家族中最小的成员，针对质量和低延迟进行了优化。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'microsoft/Phi-3-mini-128k-instruct', 'Phi-3-mini 128K', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "相同的Phi-3-mini模型，但具有更大的上下文大小，适用于RAG或少量提示。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'microsoft/Phi-3-small-8k-instruct', 'Phi-3-small 8K', 'chat', 8192, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "一个70亿参数模型，质量优于Phi-3-mini，重点关注高质量、推理密集型数据。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'microsoft/Phi-3-small-128k-instruct', 'Phi-3-small 128K', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "相同的Phi-3-small模型，但具有更大的上下文大小，适用于RAG或少量提示。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'microsoft/Phi-3-medium-4k-instruct', 'Phi-3-medium 4K', 'chat', 4096, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "一个140亿参数模型，质量优于Phi-3-mini，重点关注高质量、推理密集型数据。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'github'), 'microsoft/Phi-3-medium-128k-instruct', 'Phi-3-medium 128K', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "相同的Phi-3-medium模型，但具有更大的上下文大小，适用于RAG或少量提示。"}', FALSE),
    -- google
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-pro-latest', 'Gemini Pro Latest', 'chat', 1114112, 65536, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "structuredOutput": true, "video": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget", "urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "strategy": "tiered", "tiers": [{"rate": 0.31, "upTo": 200000}, {"rate": 0.625, "upTo": "infinity"}], "unit": "millionTokens"}, {"name": "textInput", "strategy": "tiered", "tiers": [{"rate": 1.25, "upTo": 200000}, {"rate": 2.5, "upTo": "infinity"}], "unit": "millionTokens"}, {"name": "textOutput", "strategy": "tiered", "tiers": [{"rate": 10, "upTo": 200000}, {"rate": 15, "upTo": "infinity"}], "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Latest release of Gemini Pro", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-flash-latest', 'Gemini Flash Latest', 'chat', 1114112, 65536, 0.0003, 0.0025, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "video": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget", "urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Latest release of Gemini Flash", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-flash-lite-latest', 'Gemini Flash-Lite Latest', 'chat', 1114112, 65536, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "video": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget", "urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Latest release of Gemini Flash-Lite", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.5-pro', 'Gemini 2.5 Pro', 'chat', 1114112, 65536, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "video": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget", "urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "strategy": "tiered", "tiers": [{"rate": 0.31, "upTo": 200000}, {"rate": 0.625, "upTo": "infinity"}], "unit": "millionTokens"}, {"name": "textInput", "strategy": "tiered", "tiers": [{"rate": 1.25, "upTo": 200000}, {"rate": 2.5, "upTo": "infinity"}], "unit": "millionTokens"}, {"name": "textOutput", "strategy": "tiered", "tiers": [{"rate": 10, "upTo": 200000}, {"rate": 15, "upTo": "infinity"}], "unit": "millionTokens"}]}, "released_at": "2025-06-17", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Pro 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.5-pro-preview-06-05', 'Gemini 2.5 Pro Preview 06-05', 'chat', 1114112, 65536, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "video": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget", "urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "strategy": "tiered", "tiers": [{"rate": 0.31, "upTo": 200000}, {"rate": 0.625, "upTo": "infinity"}], "unit": "millionTokens"}, {"name": "textInput", "strategy": "tiered", "tiers": [{"rate": 1.25, "upTo": 200000}, {"rate": 2.5, "upTo": "infinity"}], "unit": "millionTokens"}, {"name": "textOutput", "strategy": "tiered", "tiers": [{"rate": 10, "upTo": 200000}, {"rate": 15, "upTo": "infinity"}], "unit": "millionTokens"}]}, "released_at": "2025-06-05", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Pro Preview 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.5-pro-preview-05-06', 'Gemini 2.5 Pro Preview 05-06', 'chat', 1114112, 65536, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "video": true, "vision": true}, "settings": {"searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "strategy": "tiered", "tiers": [{"rate": 0.31, "upTo": 200000}, {"rate": 0.625, "upTo": "infinity"}], "unit": "millionTokens"}, {"name": "textInput", "strategy": "tiered", "tiers": [{"rate": 1.25, "upTo": 200000}, {"rate": 2.5, "upTo": "infinity"}], "unit": "millionTokens"}, {"name": "textOutput", "strategy": "tiered", "tiers": [{"rate": 10, "upTo": 200000}, {"rate": 15, "upTo": "infinity"}], "unit": "millionTokens"}]}, "released_at": "2025-05-06", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Pro Preview 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.5-flash', 'Gemini 2.5 Flash', 'chat', 1114112, 65536, 0.0003, 0.0025, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "video": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget", "urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-17", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Flash 是 Google 性价比最高的模型，提供全面的功能。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.5-flash-preview-09-2025', 'Gemini 2.5 Flash Preview Sep 2025', 'chat', 1114112, 65536, 0.0003, 0.0025, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "video": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget", "urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-25", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Preview release (Septempber 25th, 2025) of Gemini 2.5 Flash", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.5-flash-preview-05-20', 'Gemini 2.5 Flash Preview 05-20', 'chat', 1114112, 65536, 0.00015, 0.0035, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "video": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget", "urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.0375, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-05-20", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Flash Preview 是 Google 性价比最高的模型，提供全面的功能。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.5-flash-image', 'Nano Banana', 'chat', 40960, 8192, 0.0003, 0.0025, '{"abilities": {"imageOutput": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-26", "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Nano Banana 是 Google 最新、最快、最高效的原生多模态模型，它允许您通过对话生成和编辑图像。", "vision": true, "image_generation": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.5-flash-image-preview', 'Nano Banana (Preview)', 'chat', 40960, 8192, 0.0003, 0.0025, '{"abilities": {"imageOutput": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-26", "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Nano Banana 是 Google 最新、最快、最高效的原生多模态模型，它允许您通过对话生成和编辑图像。", "vision": true, "image_generation": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.5-flash-lite', 'Gemini 2.5 Flash-Lite', 'chat', 1114112, 65536, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "video": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget", "urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-22", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Flash-Lite 是 Google 最小、性价比最高的模型，专为大规模使用而设计。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.5-flash-lite-preview-09-2025', 'Gemini 2.5 Flash-Lite Preview Sep 2025', 'chat', 1114112, 65536, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "video": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget", "urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-25", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Preview release (September 25th, 2025) of Gemini 2.5 Flash-Lite", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.5-flash-lite-preview-06-17', 'Gemini 2.5 Flash-Lite Preview 06-17', 'chat', 1114112, 65536, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "video": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget", "urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-11", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Flash-Lite Preview 是 Google 最小、性价比最高的模型，专为大规模使用而设计。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.0-flash', 'Gemini 2.0 Flash', 'chat', 1056768, 8192, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"extendParams": ["urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-05", "source": "builtin", "maxToken": 1056768, "contextWindowTokens": 1056768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 2.0 Flash 提供下一代功能和改进，包括卓越的速度、原生工具使用、多模态生成和1M令牌上下文窗口。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.0-flash-001', 'Gemini 2.0 Flash 001', 'chat', 1056768, 8192, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"extendParams": ["urlContext"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-05", "source": "builtin", "maxToken": 1056768, "contextWindowTokens": 1056768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 2.0 Flash 提供下一代功能和改进，包括卓越的速度、原生工具使用、多模态生成和1M令牌上下文窗口。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.0-flash-preview-image-generation', 'Gemini 2.0 Flash Preview Image Generation', 'chat', 40960, 8192, 0.0001, 0.0004, '{"abilities": {"imageOutput": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageGeneration", "rate": 0.039, "strategy": "fixed", "unit": "image"}]}, "released_at": "2025-05-07", "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 2.0 Flash 预览模型，支持图像生成", "vision": true, "image_generation": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.0-flash-exp-image-generation', 'Gemini 2.0 Flash (Image Generation) Experimental', 'chat', 1056768, 8192, 0, 0, '{"abilities": {"imageOutput": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-14", "source": "builtin", "maxToken": 1056768, "contextWindowTokens": 1056768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 2.0 Flash 实验模型，支持图像生成", "vision": true, "image_generation": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.0-flash-lite', 'Gemini 2.0 Flash-Lite', 'chat', 1056768, 8192, 0.000075, 0.0003, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-05", "source": "builtin", "maxToken": 1056768, "contextWindowTokens": 1056768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 2.0 Flash 模型变体，针对成本效益和低延迟等目标进行了优化。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.0-flash-lite-001', 'Gemini 2.0 Flash-Lite 001', 'chat', 1056768, 8192, 0.000075, 0.0003, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-05", "source": "builtin", "maxToken": 1056768, "contextWindowTokens": 1056768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 2.0 Flash 模型变体，针对成本效益和低延迟等目标进行了优化。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.0-flash-exp', 'Gemini 2.0 Flash Exp', 'chat', 1056768, 8192, 0, 0, '{"abilities": {"imageOutput": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-05", "source": "builtin", "maxToken": 1056768, "contextWindowTokens": 1056768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 2.0 Flash 模型变体，针对成本效益和低延迟等目标进行了优化。", "vision": true, "image_generation": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'learnlm-2.0-flash-experimental', 'LearnLM 2.0 Flash Experimental', 'chat', 1081344, 32768, 0, 0, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1081344, "contextWindowTokens": 1081344, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "LearnLM 是一个实验性的、特定于任务的语言模型，经过训练以符合学习科学原则，可在教学和学习场景中遵循系统指令，充当专家导师等。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'learnlm-1.5-pro-experimental', 'LearnLM 1.5 Pro Experimental', 'chat', 40959, 8192, 0, 0, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-11-19", "source": "builtin", "maxToken": 40959, "contextWindowTokens": 40959, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "LearnLM 是一个实验性的、特定于任务的语言模型，经过训练以符合学习科学原则，可在教学和学习场景中遵循系统指令，充当专家导师等。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-1.5-flash-002', 'Gemini 1.5 Flash 002', 'chat', 1008192, 8192, 0.000075, 0.0003, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.018, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-25", "source": "builtin", "maxToken": 1008192, "contextWindowTokens": 1008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Flash 002 是一款高效的多模态模型，支持广泛应用的扩展。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-1.5-pro-002', 'Gemini 1.5 Pro 002', 'chat', 2008192, 8192, 0.00125, 0.005, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.3125, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-24", "source": "builtin", "maxToken": 2008192, "contextWindowTokens": 2008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Pro 002 是最新的生产就绪模型，提供更高质量的输出，特别在数学、长上下文和视觉任务方面有显著提升。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-1.5-flash-8b-latest', 'Gemini 1.5 Flash 8B', 'chat', 1008192, 8192, 0.0000375, 0.00015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.01, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.0375, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-10-03", "source": "builtin", "maxToken": 1008192, "contextWindowTokens": 1008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Flash 8B 是一款高效的多模态模型，支持广泛应用的扩展。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemma-3-1b-it', 'Gemma 3 1B', 'chat', 40960, 8192, 0, 0, '{"pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "maxOutputTokens": 8192, "maxOutput": 8192}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemma-3-4b-it', 'Gemma 3 4B', 'chat', 40960, 8192, 0, 0, '{"pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "maxOutputTokens": 8192, "maxOutput": 8192}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemma-3-12b-it', 'Gemma 3 12B', 'chat', 40960, 8192, 0, 0, '{"pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "maxOutputTokens": 8192, "maxOutput": 8192}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemma-3-27b-it', 'Gemma 3 27B', 'chat', 139264, 8192, 0, 0, '{"pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 139264, "contextWindowTokens": 139264, "maxOutputTokens": 8192, "maxOutput": 8192}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemma-3n-e2b-it', 'Gemma 3n E2B', 'chat', 10240, 2048, 0, 0, '{"pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 10240, "contextWindowTokens": 10240, "maxOutputTokens": 2048, "maxOutput": 2048}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemma-3n-e4b-it', 'Gemma 3n E4B', 'chat', 10240, 2048, 0, 0, '{"pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 10240, "contextWindowTokens": 10240, "maxOutputTokens": 2048, "maxOutput": 2048}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.5-flash-image:image', 'Nano Banana', 'image', NULL, NULL, 0.0003, 0.0025, '{"pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "parameters": {"aspectRatio": {"default": "1:1", "enum": ["1:1", "2:3", "3:2", "3:4", "4:3", "4:5", "5:4", "9:16", "16:9", "21:9"]}, "imageUrls": {"default": []}, "prompt": {"default": ""}}, "released_at": "2025-08-26", "source": "builtin", "description": "Nano Banana 是 Google 最新、最快、最高效的原生多模态模型，它允许您通过对话生成和编辑图像。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'gemini-2.5-flash-image-preview:image', 'Nano Banana (Preview)', 'image', NULL, NULL, 0.0003, 0.0025, '{"pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-26", "source": "builtin", "description": "Nano Banana 是 Google 最新、最快、最高效的原生多模态模型，它允许您通过对话生成和编辑图像。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'imagen-4.0-generate-001', 'Imagen 4', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.04, "strategy": "fixed", "unit": "image"}]}, "parameters": {"aspectRatio": {"default": "1:1", "enum": ["1:1", "16:9", "9:16", "3:4", "4:3"]}, "prompt": {"default": ""}}, "released_at": "2025-08-15", "source": "builtin", "description": "Imagen 4th generation text-to-image model series", "organization": "Deepmind"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'imagen-4.0-ultra-generate-001', 'Imagen 4 Ultra', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.06, "strategy": "fixed", "unit": "image"}]}, "parameters": {"aspectRatio": {"default": "1:1", "enum": ["1:1", "16:9", "9:16", "3:4", "4:3"]}, "prompt": {"default": ""}}, "released_at": "2025-08-15", "source": "builtin", "description": "Imagen 4th generation text-to-image model series Ultra version", "organization": "Deepmind"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'imagen-4.0-fast-generate-001', 'Imagen 4 Fast', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.02, "strategy": "fixed", "unit": "image"}]}, "parameters": {"aspectRatio": {"default": "1:1", "enum": ["1:1", "16:9", "9:16", "3:4", "4:3"]}, "prompt": {"default": ""}}, "released_at": "2025-08-15", "source": "builtin", "description": "Imagen 4th generation text-to-image model series Fast version", "organization": "Deepmind"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'imagen-4.0-generate-preview-06-06', 'Imagen 4 Preview 06-06', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.04, "strategy": "fixed", "unit": "image"}]}, "parameters": {"aspectRatio": {"default": "1:1", "enum": ["1:1", "16:9", "9:16", "3:4", "4:3"]}, "prompt": {"default": ""}}, "released_at": "2024-06-06", "source": "builtin", "description": "Imagen 4th generation text-to-image model series", "organization": "Deepmind"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'google'), 'imagen-4.0-ultra-generate-preview-06-06', 'Imagen 4 Ultra Preview 06-06', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.06, "strategy": "fixed", "unit": "image"}]}, "parameters": {"aspectRatio": {"default": "1:1", "enum": ["1:1", "16:9", "9:16", "3:4", "4:3"]}, "prompt": {"default": ""}}, "released_at": "2025-06-11", "source": "builtin", "description": "Imagen 4th generation text-to-image model series Ultra version", "organization": "Deepmind"}', FALSE),
    -- groq
    ((SELECT id FROM ai_providers WHERE code = 'groq'), 'groq/compound', 'Compound', 'chat', 131072, 8192, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Compound 是一个复合 AI 系统，由 GroqCloud 中已经支持的多个开放可用的模型提供支持，可以智能地、有选择地使用工具来回答用户查询。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'groq'), 'groq/compound-mini', 'Compound Mini', 'chat', 131072, 8192, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Compound-mini 是一个复合 AI 系统，由 GroqCloud 中已经支持的公开可用模型提供支持，可以智能地、有选择地使用工具来回答用户查询。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'groq'), 'openai/gpt-oss-120b', 'GPT OSS 120B', 'chat', 131072, 65536, 0.00015, 0.0006, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-06", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "OpenAI GPT-OSS 120B 是一款拥有 1200 亿参数的顶尖语言模型，内置浏览器搜索和代码执行功能，并具备推理能力。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'groq'), 'openai/gpt-oss-20b', 'GPT OSS 20B', 'chat', 131072, 65536, 0.000075, 0.0003, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-06", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "OpenAI GPT-OSS 20B 是一款拥有 200 亿参数的顶尖语言模型，内置浏览器搜索和代码执行功能，并具备推理能力。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'groq'), 'moonshotai/kimi-k2-instruct-0905', 'Kimi K2 0905', 'chat', 262144, 16384, 0.001, 0.003, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-05", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "kimi-k2-0905-preview 模型上下文长度为 256k，具备更强的 Agentic Coding 能力、更突出的前端代码的美观度和实用性、以及更好的上下文理解能力。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'groq'), 'meta-llama/llama-4-scout-17b-16e-instruct', 'Llama 4 Scout (17Bx16E)', 'chat', 131072, 8192, 0.00011, 0.00034, '{"pricing": {"units": [{"name": "textInput", "rate": 0.11, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.34, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'groq'), 'meta-llama/llama-4-maverick-17b-128e-instruct', 'Llama 4 Maverick (17Bx128E)', 'chat', 131072, 8192, 0.0002, 0.0006, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'groq'), 'qwen/qwen3-32b', 'Qwen3 32B', 'chat', 131072, 40960, 0.00029, 0.00059, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.29, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.59, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 40960, "maxOutput": 40960, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'groq'), 'llama-3.1-8b-instant', 'Llama 3.1 8B Instant', 'chat', 131072, 131072, 0.00005, 0.00008, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.08, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 131072, "maxOutput": 131072, "description": "Llama 3.1 8B 是一款高效能模型，提供了快速的文本生成能力，非常适合需要大规模效率和成本效益的应用场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'groq'), 'llama-3.3-70b-versatile', 'Llama 3.3 70B Versatile', 'chat', 131072, 32768, 0.00059, 0.00079, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.59, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.79, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "Meta Llama 3.3 多语言大语言模型 ( LLM ) 是 70B（文本输入/文本输出）中的预训练和指令调整生成模型。 Llama 3.3 指令调整的纯文本模型针对多语言对话用例进行了优化，并且在常见行业基准上优于许多可用的开源和封闭式聊天模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'groq'), 'mistral-saba-24b', 'Mistral Saba 24B', 'chat', 32768, 32768, 0.00079, 0.00079, '{"pricing": {"units": [{"name": "textInput", "rate": 0.79, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.79, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 32768, "maxOutput": 32768}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'groq'), 'meta-llama/llama-guard-4-12b', 'Llama Guard 4 12B', 'chat', 131072, 1024, 0.0002, 0.0002, '{"pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 1024, "maxOutput": 1024}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'groq'), 'meta-llama/llama-prompt-guard-2-22m', 'Llama Prompt Guard 2 22M', 'chat', 512, 512, NULL, NULL, '{"source": "builtin", "maxToken": 512, "contextWindowTokens": 512, "maxOutputTokens": 512, "maxOutput": 512}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'groq'), 'meta-llama/llama-prompt-guard-2-86m', 'Llama Prompt Guard 2 86M', 'chat', 512, 512, NULL, NULL, '{"source": "builtin", "maxToken": 512, "contextWindowTokens": 512, "maxOutputTokens": 512, "maxOutput": 512}', FALSE),
    -- higress
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen-turbo', 'Qwen Turbo', 'chat', 131072, NULL, 0.0003, 0.0006, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "通义千问超大规模语言模型，支持中文、英文等不同语言输入。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen-plus', 'Qwen Plus', 'chat', 131072, NULL, 0.0008, 0.002, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "通义千问超大规模语言模型增强版，支持中文、英文等不同语言输入。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen-max', 'Qwen Max', 'chat', 32768, NULL, 0.02, 0.06, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "通义千问千亿级别超大规模语言模型，支持中文、英文等不同语言输入，当前通义千问2.5产品版本背后的API模型。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen-long', 'Qwen Long', 'chat', 1000000, NULL, 0.0005, 0.002, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000, "description": "通义千问超大规模语言模型，支持长文本上下文，以及基于长文档、多文档等多个场景的对话功能。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen-vl-plus-latest', 'Qwen VL Plus', 'chat', 32000, NULL, 0.008, 0.008, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "通义千问大规模视觉语言模型增强版。大幅提升细节识别能力和文字识别能力，支持超百万像素分辨率和任意长宽比规格的图像。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen-vl-max-latest', 'Qwen VL Max', 'chat', 32000, NULL, 0.02, 0.02, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "通义千问超大规模视觉语言模型。相比增强版，再次提升视觉推理能力和指令遵循能力，提供更高的视觉感知和认知水平。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen-math-turbo-latest', 'Qwen Math Turbo', 'chat', 4096, NULL, 0.002, 0.006, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "通义千问数学模型是专门用于数学解题的语言模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen-math-plus-latest', 'Qwen Math Plus', 'chat', 4096, NULL, 0.004, 0.012, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "通义千问数学模型是专门用于数学解题的语言模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen-coder-turbo-latest', 'Qwen Coder Turbo', 'chat', 131072, NULL, 0.002, 0.006, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "通义千问代码模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen2.5-7b-instruct', 'Qwen2.5 7B', 'chat', 131072, NULL, 0.001, 0.002, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "通义千问2.5对外开源的7B规模的模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen2.5-14b-instruct', 'Qwen2.5 14B', 'chat', 131072, NULL, 0.002, 0.006, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "通义千问2.5对外开源的14B规模的模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen2.5-32b-instruct', 'Qwen2.5 32B', 'chat', 131072, NULL, 0.0035, 0.007, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 7, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "通义千问2.5对外开源的32B规模的模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen2.5-72b-instruct', 'Qwen2.5 72B', 'chat', 131072, NULL, 0.004, 0.012, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "通义千问2.5对外开源的72B规模的模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen2.5-math-1.5b-instruct', 'Qwen2.5 Math 1.5B', 'chat', 4096, NULL, 0, 0, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "Qwen-Math 模型具有强大的数学解题能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen2.5-math-7b-instruct', 'Qwen2.5 Math 7B', 'chat', 4096, NULL, 0.001, 0.002, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "Qwen-Math 模型具有强大的数学解题能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen2.5-math-72b-instruct', 'Qwen2.5 Math 72B', 'chat', 4096, NULL, 0.004, 0.012, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "Qwen-Math 模型具有强大的数学解题能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen2.5-coder-1.5b-instruct', 'Qwen2.5 Coder 1.5B', 'chat', 131072, NULL, 0, 0, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "通义千问代码模型开源版。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen2.5-coder-7b-instruct', 'Qwen2.5 Coder 7B', 'chat', 131072, NULL, 0.001, 0.002, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "通义千问代码模型开源版。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen-vl-v1', 'Qwen VL', 'chat', 8000, NULL, 0, 0, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "以 Qwen-7B 语言模型初始化，添加图像模型，图像输入分辨率为448的预训练模型。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'qwen-vl-chat-v1', 'Qwen VL Chat', 'chat', 8000, NULL, 0, 0, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "通义千问VL支持灵活的交互方式，包括多图、多轮问答、创作等能力的模型。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'moonshot-v1-8k', 'Moonshot V1 8K', 'chat', 8192, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Moonshot V1 8K 专为生成短文本任务设计，具有高效的处理性能，能够处理8,192个tokens，非常适合简短对话、速记和快速内容生成。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'moonshot-v1-32k', 'Moonshot V1 32K', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Moonshot V1 32K 提供中等长度的上下文处理能力，能够处理32,768个tokens，特别适合生成各种长文档和复杂对话，应用于内容创作、报告生成和对话系统等领域。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'moonshot-v1-128k', 'Moonshot V1 128K', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Moonshot V1 128K 是一款拥有超长上下文处理能力的模型，适用于生成超长文本，满足复杂的生成任务需求，能够处理多达128,000个tokens的内容，非常适合科研、学术和大型文档生成等应用场景。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Baichuan4', 'Baichuan 4', 'chat', 32768, 4096, 0.1, 0.1, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 100, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 100, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "模型能力国内第一，在知识百科、长文本、生成创作等中文任务上超越国外主流模型。还具备行业领先的多模态能力，多项权威评测基准表现优异。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Baichuan4-Turbo', 'Baichuan 4 Turbo', 'chat', NULL, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "description": "", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Baichuan4-Air', 'Baichuan 4 Air', 'chat', NULL, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "description": "", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Baichuan3-Turbo', 'Baichuan 3 Turbo', 'chat', 32768, 8192, 0.012, 0.012, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "针对企业高频场景优化，效果大幅提升，高性价比。相对于Baichuan2模型，内容创作提升20%，知识问答提升17%， 角色扮演能力提升40%。整体效果比GPT3.5更优。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Baichuan3-Turbo-128k', 'Baichuan 3 Turbo 128k', 'chat', 128000, 4096, 0.024, 0.024, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 24, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 24, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "具备 128K 超长上下文窗口，针对企业高频场景优化，效果大幅提升，高性价比。相对于Baichuan2模型，内容创作提升20%，知识问答提升17%， 角色扮演能力提升40%。整体效果比GPT3.5更优。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Baichuan2-Turbo', 'Baichuan 2 Turbo', 'chat', 32768, 8192, 0.008, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "采用搜索增强技术实现大模型与领域知识、全网知识的全面链接。支持PDF、Word等多种文档上传及网址输入，信息获取及时、全面，输出结果准确、专业。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'yi-lightning', 'Yi Lightning', 'chat', 16384, NULL, 0.00099, 0.00099, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.99, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.99, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "最新高性能模型，保证高质量输出同时，推理速度大幅提升。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'yi-spark', 'Yi Spark', 'chat', 16384, NULL, 0.001, 0.001, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "小而精悍，轻量极速模型。提供强化数学运算和代码编写能力。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'yi-medium', 'Yi Medium', 'chat', 16384, NULL, 0.0025, 0.0025, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "中型尺寸模型升级微调，能力均衡，性价比高。深度优化指令遵循能力。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'yi-medium-200k', 'Yi Medium 200K', 'chat', 200000, NULL, 0.012, 0.012, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "200K 超长上下文窗口，提供长文本深度理解和生成能力。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'yi-large-turbo', 'Yi Large Turbo', 'chat', 16384, NULL, 0.012, 0.012, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "超高性价比、卓越性能。根据性能和推理速度、成本，进行平衡性高精度调优。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'yi-large-rag', 'Yi Large RAG', 'chat', 16384, NULL, 0.025, 0.025, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 25, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "基于 yi-large 超强模型的高阶服务，结合检索与生成技术提供精准答案，实时全网检索信息服务。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'yi-large-fc', 'Yi Large FC', 'chat', 32768, NULL, 0.02, 0.02, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "在 yi-large 模型的基础上支持并强化了工具调用的能力，适用于各种需要搭建 agent 或 workflow 的业务场景。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'yi-large', 'Yi Large', 'chat', 32768, NULL, 0.02, 0.02, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "全新千亿参数模型，提供超强问答及文本生成能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'yi-vision', 'Yi Vision', 'chat', 16384, NULL, 0.006, 0.006, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "复杂视觉任务模型，提供高性能图片理解、分析能力。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'yi-large-preview', 'Yi Large Preview', 'chat', 16384, NULL, 0.02, 0.02, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "初期版本，推荐使用 yi-large（新版本）。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'yi-lightning-lite', 'Yi Lightning Lite', 'chat', 16384, NULL, 0.00099, 0.00099, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.99, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.99, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "轻量化版本，推荐使用 yi-lightning。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'glm-4-flash', 'GLM-4-Flash', 'chat', 128000, NULL, 0, 0, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GLM-4-Flash 是处理简单任务的理想选择，速度最快且免费。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'glm-4-flashx', 'GLM-4-FlashX', 'chat', 128000, NULL, 0.0001, 0.0001, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GLM-4-FlashX 是Flash的增强版本，超快推理速度。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'glm-4-long', 'GLM-4-Long', 'chat', 1024000, NULL, 0.001, 0.001, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1024000, "contextWindowTokens": 1024000, "description": "GLM-4-Long 支持超长文本输入，适合记忆型任务与大规模文档处理。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'glm-4-air', 'GLM-4-Air', 'chat', 128000, NULL, 0.001, 0.001, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GLM-4-Air 是性价比高的版本，性能接近GLM-4，提供快速度和实惠的价格。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'glm-4-airx', 'GLM-4-AirX', 'chat', 8192, NULL, 0.01, 0.01, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "GLM-4-AirX 提供 GLM-4-Air 的高效版本，推理速度可达其2.6倍。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'glm-4-alltools', 'GLM-4-AllTools', 'chat', 128000, NULL, 0.1, 0.1, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 100, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 100, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GLM-4-AllTools 是一个多功能智能体模型，优化以支持复杂指令规划与工具调用，如网络浏览、代码解释和文本生成，适用于多任务执行。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'glm-4-plus', 'GLM-4-Plus', 'chat', 128000, NULL, 0.05, 0.05, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 50, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 50, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GLM-4-Plus 作为高智能旗舰，具备强大的处理长文本和复杂任务的能力，性能全面提升。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'glm-4-0520', 'GLM-4-0520', 'chat', 128000, NULL, 0.1, 0.1, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 100, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 100, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GLM-4-0520 是最新模型版本，专为高度复杂和多样化任务设计，表现卓越。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'glm-4', 'GLM-4', 'chat', 128000, NULL, 0.1, 0.1, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 100, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 100, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GLM-4 是发布于2024年1月的旧旗舰版本，目前已被更强的 GLM-4-0520 取代。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'glm-4v-plus', 'GLM-4V-Plus', 'chat', 8192, NULL, 0.01, 0.01, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "GLM-4V-Plus 具备对视频内容及多图片的理解能力，适合多模态任务。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'glm-4v', 'GLM-4V', 'chat', 2048, NULL, 0.05, 0.05, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 50, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 50, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 2048, "contextWindowTokens": 2048, "description": "GLM-4V 提供强大的图像理解与推理能力，支持多种视觉任务。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'charglm-3', 'CharGLM-3', 'chat', 4096, NULL, 0.015, 0.015, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "CharGLM-3 专为角色扮演与情感陪伴设计，支持超长多轮记忆与个性化对话，应用广泛。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'emohaa', 'Emohaa', 'chat', 8192, NULL, 0.015, 0.015, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Emohaa 是心理模型，具备专业咨询能力，帮助用户理解情感问题。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), '360gpt2-pro', '360GPT2 Pro', 'chat', 8192, 7000, 0.005, 0.005, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 7000, "maxOutput": 7000, "description": "360GPT2 Pro 是 360 公司推出的高级自然语言处理模型，具备卓越的文本生成和理解能力，尤其在生成与创作领域表现出色，能够处理复杂的语言转换和角色演绎任务。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), '360gpt-pro', '360GPT Pro', 'chat', 8192, 7000, 0.005, 0.005, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 7000, "maxOutput": 7000, "description": "360GPT Pro 作为 360 AI 模型系列的重要成员，以高效的文本处理能力满足多样化的自然语言应用场景，支持长文本理解和多轮对话等功能。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), '360gpt-turbo', '360GPT Turbo', 'chat', 8192, 7000, 0.002, 0.002, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 7000, "maxOutput": 7000, "description": "360GPT Turbo 提供强大的计算和对话能力，具备出色的语义理解和生成效率，是企业和开发者理想的智能助理解决方案。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), '360gpt-turbo-responsibility-8k', '360GPT Turbo Responsibility 8K', 'chat', 8192, 2048, 0.002, 0.002, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 2048, "maxOutput": 2048, "description": "360GPT Turbo Responsibility 8K 强调语义安全和责任导向，专为对内容安全有高度要求的应用场景设计，确保用户体验的准确性与稳健性。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ERNIE-3.5-8K', 'ERNIE 3.5 8K', 'chat', 8192, NULL, 0.0008, 0.002, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的旗舰级大规模⼤语⾔模型，覆盖海量中英文语料，具有强大的通用能力，可满足绝大部分对话问答、创作生成、插件应用场景要求；支持自动对接百度搜索插件，保障问答信息时效。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ERNIE-3.5-8K-Preview', 'ERNIE 3.5 8K Preview', 'chat', 8192, NULL, 0.0008, 0.002, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的旗舰级大规模⼤语⾔模型，覆盖海量中英文语料，具有强大的通用能力，可满足绝大部分对话问答、创作生成、插件应用场景要求；支持自动对接百度搜索插件，保障问答信息时效。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ERNIE-3.5-128K', 'ERNIE 3.5 128K', 'chat', 128000, NULL, 0.0008, 0.002, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "百度自研的旗舰级大规模⼤语⾔模型，覆盖海量中英文语料，具有强大的通用能力，可满足绝大部分对话问答、创作生成、插件应用场景要求；支持自动对接百度搜索插件，保障问答信息时效。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ERNIE-4.0-8K-Latest', 'ERNIE 4.0 8K', 'chat', 8192, NULL, 0.03, 0.09, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 90, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的旗舰级超大规模⼤语⾔模型，相较ERNIE 3.5实现了模型能力全面升级，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ERNIE-4.0-8K-Preview', 'ERNIE 4.0 8K Preview', 'chat', 8192, NULL, 0.03, 0.09, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 90, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的旗舰级超大规模⼤语⾔模型，相较ERNIE 3.5实现了模型能力全面升级，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ERNIE-4.0-Turbo-8K-Latest', 'ERNIE 4.0 Turbo 8K', 'chat', 8192, NULL, 0.02, 0.06, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的旗舰级超大规模⼤语⾔模型，综合效果表现出色，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。相较于ERNIE 4.0在性能表现上更优秀"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ERNIE-4.0-Turbo-8K-Preview', 'ERNIE 4.0 Turbo 8K Preview', 'chat', 8192, NULL, 0.02, 0.06, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的旗舰级超大规模⼤语⾔模型，综合效果表现出色，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。相较于ERNIE 4.0在性能表现上更优秀"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ERNIE-Lite-Pro-128K', 'ERNIE Lite Pro 128K', 'chat', 128000, NULL, 0.0002, 0.0004, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "百度自研的轻量级大语言模型，兼顾优异的模型效果与推理性能，效果比ERNIE Lite更优，适合低算力AI加速卡推理使用。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ERNIE-Speed-Pro-128K', 'ERNIE Speed Pro 128K', 'chat', 128000, NULL, 0.0003, 0.0006, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "百度2024年最新发布的自研高性能大语言模型，通用能力优异，效果比ERNIE Speed更优，适合作为基座模型进行精调，更好地处理特定场景问题，同时具备极佳的推理性能。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ERNIE-Speed-128K', 'ERNIE Speed 128K', 'chat', 128000, NULL, 0, 0, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "百度2024年最新发布的自研高性能大语言模型，通用能力优异，适合作为基座模型进行精调，更好地处理特定场景问题，同时具备极佳的推理性能。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ERNIE-Character-8K', 'ERNIE Character 8K', 'chat', 8192, NULL, 0.004, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的垂直场景大语言模型，适合游戏NPC、客服对话、对话角色扮演等应用场景，人设风格更为鲜明、一致，指令遵循能力更强，推理性能更优。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'hunyuan-lite', 'Hunyuan Lite', 'chat', 256000, 6000, 0, 0, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "maxOutputTokens": 6000, "maxOutput": 6000, "description": "升级为 MOE 结构，上下文窗口为 256k ，在 NLP，代码，数学，行业等多项评测集上领先众多开源模型。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'hunyuan-standard', 'Hunyuan Standard', 'chat', 32000, 2000, 0.0045, 0.005, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 2000, "maxOutput": 2000, "description": "采用更优的路由策略，同时缓解了负载均衡和专家趋同的问题。长文方面，大海捞针指标达到99.9%。MOE-32K 性价比相对更高，在平衡效果、价格的同时，可对实现对长文本输入的处理。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'hunyuan-standard-256K', 'Hunyuan Standard 256K', 'chat', 256000, 6000, 0.015, 0.06, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "maxOutputTokens": 6000, "maxOutput": 6000, "description": "采用更优的路由策略，同时缓解了负载均衡和专家趋同的问题。长文方面，大海捞针指标达到99.9%。MOE-256K 在长度和效果上进一步突破，极大的扩展了可输入长度。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'hunyuan-turbo', 'Hunyuan Turbo', 'chat', 32000, 4000, 0.015, 0.05, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 50, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "混元全新一代大语言模型的预览版，采用全新的混合专家模型（MoE）结构，相比hunyuan-pro推理效率更快，效果表现更强。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'hunyuan-pro', 'Hunyuan Pro', 'chat', 32000, 4000, 0.03, 0.1, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 100, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "万亿级参数规模 MOE-32K 长文模型。在各种 benchmark 上达到绝对领先的水平，复杂指令和推理，具备复杂数学能力，支持 functioncall，在多语言翻译、金融法律医疗等领域应用重点优化。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'hunyuan-large', 'Hunyuan Large', 'chat', NULL, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "description": "", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'hunyuan-vision', 'Hunyuan Vision', 'chat', 8000, 4000, 0.018, 0.018, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 18, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 18, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "混元最新多模态模型，支持图片+文本输入生成文本内容。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'hunyuan-code', 'Hunyuan Code', 'chat', 8000, 4000, 0.004, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "混元最新代码生成模型，经过 200B 高质量代码数据增训基座模型，迭代半年高质量 SFT 数据训练，上下文长窗口长度增大到 8K，五大语言代码生成自动评测指标上位居前列；五大语言10项考量各方面综合代码任务人工高质量评测上，性能处于第一梯队"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'hunyuan-functioncall', 'Hunyuan FunctionCall', 'chat', 32000, 4000, 0.004, 0.008, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "混元最新 MOE 架构 FunctionCall 模型，经过高质量的 FunctionCall 数据训练，上下文窗口达 32K，在多个维度的评测指标上处于领先。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'hunyuan-role', 'Hunyuan Role', 'chat', 8000, 4000, 0.004, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "混元最新版角色扮演模型，混元官方精调训练推出的角色扮演模型，基于混元模型结合角色扮演场景数据集进行增训，在角色扮演场景具有更好的基础效果。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'step-1-flash', 'Step 1 Flash', 'chat', 8000, NULL, 0.001, 0.004, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "高速模型，适合实时对话。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'step-1-8k', 'Step 1 8K', 'chat', 8000, NULL, 0.005, 0.02, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "小型模型，适合轻量级任务。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'step-1-32k', 'Step 1 32K', 'chat', 32000, NULL, 0.015, 0.07, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 70, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "支持中等长度的对话，适用于多种应用场景。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'step-1-128k', 'Step 1 128K', 'chat', 128000, NULL, 0.04, 0.2, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 40, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 200, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "平衡性能与成本，适合一般场景。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'step-1-256k', 'Step 1 256K', 'chat', 256000, NULL, 0.095, 0.3, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 95, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 300, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "具备超长上下文处理能力，尤其适合长文档分析。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'step-2-16k', 'Step 2 16K', 'chat', 16000, NULL, 0.038, 0.12, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 38, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 120, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "description": "支持大规模上下文交互，适合复杂对话场景。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'step-1v-8k', 'Step 1V 8K', 'chat', 8000, NULL, 0.005, 0.02, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "小型视觉模型，适合基本的图文任务。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'step-1v-32k', 'Step 1V 32K', 'chat', 32000, NULL, 0.015, 0.07, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 70, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "支持视觉输入，增强多模态交互体验。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'step-1.5v-mini', 'Step 1.5V Mini', 'chat', 32000, NULL, 0.008, 0.035, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 35, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "该模型拥有强大的视频理解能力。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'lite', 'Spark Lite', 'chat', 8192, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Spark Lite 是一款轻量级大语言模型，具备极低的延迟与高效的处理能力，完全免费开放，支持实时在线搜索功能。其快速响应的特性使其在低算力设备上的推理应用和模型微调中表现出色，为用户带来出色的成本效益和智能体验，尤其在知识问答、内容生成及搜索场景下表现不俗。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'generalv3', 'Spark Pro', 'chat', 8192, 8192, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Spark Pro 是一款为专业领域优化的高性能大语言模型，专注数学、编程、医疗、教育等多个领域，并支持联网搜索及内置天气、日期等插件。其优化后模型在复杂知识问答、语言理解及高层次文本创作中展现出色表现和高效性能，是适合专业应用场景的理想选择。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'pro-128k', 'Spark Pro 128K', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Spark Pro 128K 配置了特大上下文处理能力，能够处理多达128K的上下文信息，特别适合需通篇分析和长期逻辑关联处理的长文内容，可在复杂文本沟通中提供流畅一致的逻辑与多样的引用支持。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'generalv3.5', 'Spark Max', 'chat', 8192, 8192, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Spark Max 为功能最为全面的版本，支持联网搜索及众多内置插件。其全面优化的核心能力以及系统角色设定和函数调用功能，使其在各种复杂应用场景中的表现极为优异和出色。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'max-32k', 'Spark Max 32K', 'chat', 32768, 8192, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Spark Max 32K 配置了大上下文处理能力，更强的上下文理解和逻辑推理能力，支持32K tokens的文本输入，适用于长文档阅读、私有知识问答等场景"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), '4.0Ultra', 'Spark 4.0 Ultra', 'chat', 8192, 8192, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Spark Ultra 是星火大模型系列中最为强大的版本，在升级联网搜索链路同时，提升对文本内容的理解和总结能力。它是用于提升办公生产力和准确响应需求的全方位解决方案，是引领行业的智能产品。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'o1-mini', 'OpenAI o1-mini', 'chat', 128000, 65536, 0.003, 0.012, '{"pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-12", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "o1-mini是一款针对编程、数学和科学应用场景而设计的快速、经济高效的推理模型。该模型具有128K上下文和2023年10月的知识截止日期。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'o1-preview', 'OpenAI o1-preview', 'chat', 128000, 32768, 0.015, 0.06, '{"pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-12", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "o1是OpenAI新的推理模型，适用于需要广泛通用知识的复杂任务。该模型具有128K上下文和2023年10月的知识截止日期。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4o-mini', 'GPT-4o mini', 'chat', 128000, 16385, 0.00015, 0.0006, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16385, "maxOutput": 16385, "description": "GPT-4o mini是OpenAI在GPT-4 Omni之后推出的最新模型，支持图文输入并输出文本。作为他们最先进的小型模型，它比其他近期的前沿模型便宜很多，并且比GPT-3.5 Turbo便宜超过60%。它保持了最先进的智能，同时具有显著的性价比。GPT-4o mini在MMLU测试中获得了 82% 的得分，目前在聊天偏好上排名高于 GPT-4。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4o', 'GPT-4o', 'chat', 128000, NULL, 0.0025, 0.01, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4o-2024-08-06', 'GPT-4o 0806', 'chat', 128000, NULL, 0.0025, 0.01, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4o-2024-05-13', 'GPT-4o 0513', 'chat', 128000, NULL, 0.005, 0.015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'chatgpt-4o-latest', 'ChatGPT-4o', 'chat', 128000, NULL, 0.005, 0.015, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4-turbo', 'GPT-4 Turbo', 'chat', 128000, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4-turbo-2024-04-09', 'GPT-4 Turbo Vision 0409', 'chat', 128000, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4-turbo-preview', 'GPT-4 Turbo Preview', 'chat', 128000, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4-0125-preview', 'GPT-4 Turbo Preview 0125', 'chat', 128000, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4-1106-preview', 'GPT-4 Turbo Preview 1106', 'chat', 128000, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4', 'GPT-4', 'chat', 8192, NULL, 0.03, 0.06, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4-0613', 'GPT-4 0613', 'chat', 8192, NULL, 0.03, 0.06, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4-32k', 'GPT-4 32K', 'chat', 32768, NULL, 0.06, 0.12, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 120, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4-32k-0613', 'GPT-4 32K 0613', 'chat', 32768, NULL, 0.06, 0.12, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 120, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-3.5-turbo', 'GPT-3.5 Turbo', 'chat', 16385, NULL, 0.0005, 0.0015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16385, "contextWindowTokens": 16385, "description": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-3.5-turbo-0125', 'GPT-3.5 Turbo 0125', 'chat', 16385, NULL, 0.0005, 0.0015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16385, "contextWindowTokens": 16385, "description": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-3.5-turbo-1106', 'GPT-3.5 Turbo 1106', 'chat', 16385, NULL, 0.001, 0.002, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16385, "contextWindowTokens": 16385, "description": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-3.5-turbo-instruct', 'GPT-3.5 Turbo Instruct', 'chat', 4096, NULL, 0.0015, 0.002, '{"pricing": {"units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-35-turbo', 'GPT 3.5 Turbo', 'chat', 16385, 4096, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 16385, "contextWindowTokens": 16385, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "GPT 3.5 Turbo，OpenAI提供的高效模型，适用于聊天和文本生成任务，支持并行函数调用。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-35-turbo-16k', 'GPT 3.5 Turbo', 'chat', 16384, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "GPT 3.5 Turbo 16k，高容量文本生成模型，适合复杂任务。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4', 'GPT 4 Turbo', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GPT 4 Turbo，多模态模型，提供杰出的语言理解和生成能力，同时支持图像输入。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4-vision-preview', 'GPT 4 Turbo with Vision Preview', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GPT-4 视觉预览版，专为图像分析和处理任务设计。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4o-mini', 'GPT 4o Mini', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GPT-4o Mini，小型高效模型，具备与GPT-4o相似的卓越性能。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4o', 'GPT 4o', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GPT-4o 是最新的多模态模型，结合高级文本和图像处理能力。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'o1-mini', 'OpenAI o1-mini', 'chat', 128000, 65536, NULL, NULL, '{"abilities": {"functionCall": false, "vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "比 o1-preview 更小、更快，成本低80%，在代码生成和小上下文操作方面表现良好。", "vision": true, "function_calling": false}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'o1-preview', 'OpenAI o1-preview', 'chat', 128000, 32768, NULL, NULL, '{"abilities": {"functionCall": false, "vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "专注于高级推理和解决复杂问题，包括数学和科学任务。非常适合需要深度上下文理解和自主工作流程的应用。", "vision": true, "function_calling": false}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4o-mini', 'OpenAI GPT-4o mini', 'chat', 128000, 4096, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "一种经济高效的AI解决方案，适用于多种文本和图像任务。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gpt-4o', 'OpenAI GPT-4o', 'chat', 128000, 4096, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "OpenAI GPT-4系列中最先进的多模态模型，可以处理文本和图像输入。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ai21-jamba-1.5-mini', 'AI21 Jamba 1.5 Mini', 'chat', 262144, 4096, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "一个52B参数（12B活跃）的多语言模型，提供256K长上下文窗口、函数调用、结构化输出和基于事实的生成。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ai21-jamba-1.5-large', 'AI21 Jamba 1.5 Large', 'chat', 262144, 4096, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "一个398B参数（94B活跃）的多语言模型，提供256K长上下文窗口、函数调用、结构化输出和基于事实的生成。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'cohere-command-r', 'Cohere Command R', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Command R是一个可扩展的生成模型，旨在针对RAG和工具使用，使企业能够实现生产级AI。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'cohere-command-r-plus', 'Cohere Command R+', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Command R+是一个最先进的RAG优化模型，旨在应对企业级工作负载。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'mistral-nemo', 'Mistral Nemo', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Mistral Nemo是一种尖端的语言模型（LLM），在其尺寸类别中拥有最先进的推理、世界知识和编码能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'mistral-small', 'Mistral Small', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Mistral Small可用于任何需要高效率和低延迟的基于语言的任务。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'mistral-large', 'Mistral Large', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Mistral的旗舰模型，适合需要大规模推理能力或高度专业化的复杂任务（合成文本生成、代码生成、RAG或代理）。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'llama-3.2-11b-vision-instruct', 'Llama 3.2 11B Vision', 'chat', 131072, 4096, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "在高分辨率图像上表现出色的图像推理能力，适用于视觉理解应用。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'llama-3.2-90b-vision-instruct', 'Llama 3.2 90B Vision', 'chat', 131072, 4096, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "适用于视觉理解代理应用的高级图像推理能力。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'meta-llama-3.1-8b-instruct', 'Meta Llama 3.1 8B', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'meta-llama-3.1-70b-instruct', 'Meta Llama 3.1 70B', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'meta-llama-3.1-405b-instruct', 'Meta Llama 3.1 405B', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'meta-llama-3-8b-instruct', 'Meta Llama 3 8B', 'chat', 8192, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "一个多功能的80亿参数模型，针对对话和文本生成任务进行了优化。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'meta-llama-3-70b-instruct', 'Meta Llama 3 70B', 'chat', 8192, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "一个强大的700亿参数模型，在推理、编码和广泛的语言应用方面表现出色。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Phi-3.5-mini-instruct', 'Phi-3.5-mini 128K', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Phi-3-mini模型的更新版。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Phi-3.5-vision-instrust', 'Phi-3.5-vision 128K', 'chat', 131072, 4096, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Phi-3-vision模型的更新版。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Phi-3-mini-4k-instruct', 'Phi-3-mini 4K', 'chat', 4096, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Phi-3家族中最小的成员，针对质量和低延迟进行了优化。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Phi-3-mini-128k-instruct', 'Phi-3-mini 128K', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "相同的Phi-3-mini模型，但具有更大的上下文大小，适用于RAG或少量提示。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Phi-3-small-8k-instruct', 'Phi-3-small 8K', 'chat', 8192, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "一个70亿参数模型，质量优于Phi-3-mini，重点关注高质量、推理密集型数据。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Phi-3-small-128k-instruct', 'Phi-3-small 128K', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "相同的Phi-3-small模型，但具有更大的上下文大小，适用于RAG或少量提示。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Phi-3-medium-4k-instruct', 'Phi-3-medium 4K', 'chat', 4096, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "一个140亿参数模型，质量优于Phi-3-mini，重点关注高质量、推理密集型数据。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Phi-3-medium-128k-instruct', 'Phi-3-medium 128K', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "相同的Phi-3-medium模型，但具有更大的上下文大小，适用于RAG或少量提示。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'llama-3.2-11b-vision-preview', 'Llama 3.2 11B Vision (Preview)', 'chat', 8192, 8192, 0.00005, 0.00008, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.08, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Llama 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'llama-3.2-90b-vision-preview', 'Llama 3.2 90B Vision (Preview)', 'chat', 8192, 8192, 0.00059, 0.00079, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.59, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.79, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Llama 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'llama-3.1-8b-instant', 'Llama 3.1 8B', 'chat', 131072, 8192, 0.00005, 0.00008, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.08, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Llama 3.1 8B 是一款高效能模型，提供了快速的文本生成能力，非常适合需要大规模效率和成本效益的应用场景。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'llama-3.1-70b-versatile', 'Llama 3.1 70B', 'chat', 131072, 8192, 0.00059, 0.00079, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.59, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.79, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Llama 3.1 70B 提供更强大的AI推理能力，适合复杂应用，支持超多的计算处理并保证高效和准确率。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'llama3-groq-8b-8192-tool-use-preview', 'Llama 3 Groq 8B Tool Use (Preview)', 'chat', 8192, NULL, 0.00019, 0.00019, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.19, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.19, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Llama 3 Groq 8B Tool Use 是针对高效工具使用优化的模型，支持快速并行计算。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'llama3-groq-70b-8192-tool-use-preview', 'Llama 3 Groq 70B Tool Use (Preview)', 'chat', 8192, NULL, 0.00089, 0.00089, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.89, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.89, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Llama 3 Groq 70B Tool Use 提供强大的工具调用能力，支持复杂任务的高效处理。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'llama3-8b-8192', 'Meta Llama 3 8B', 'chat', 8192, NULL, 0.00005, 0.00008, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.08, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Meta Llama 3 8B 带来优质的推理效能，适合多场景应用需求。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'llama3-70b-8192', 'Meta Llama 3 70B', 'chat', 8192, NULL, 0.00059, 0.00079, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.59, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.79, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Meta Llama 3 70B 提供无与伦比的复杂性处理能力，为高要求项目量身定制。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemma2-9b-it', 'Gemma 2 9B', 'chat', 8192, NULL, 0.0002, 0.0002, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Gemma 2 9B 是一款优化用于特定任务和工具整合的模型。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemma-7b-it', 'Gemma 7B', 'chat', 8192, NULL, 0.00007, 0.00007, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.07, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.07, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Gemma 7B 适合中小规模任务处理，兼具成本效益。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'mixtral-8x7b-32768', 'Mixtral 8x7B', 'chat', 32768, NULL, 0.00024, 0.00024, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.24, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.24, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Mixtral 8x7B 提供高容错的并行计算能力，适合复杂任务。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'llava-v1.5-7b-4096-preview', 'LLaVA 1.5 7B', 'chat', 4096, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "LLaVA 1.5 7B 提供视觉处理能力融合，通过视觉信息输入生成复杂输出。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'deepseek-chat', 'DeepSeek V2.5', 'chat', 128000, NULL, 0.00014, 0.00028, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.014, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.14, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.28, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-05", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "融合通用与代码能力的全新开源模型, 不仅保留了原有 Chat 模型的通用对话能力和 Coder 模型的强大代码处理能力，还更好地对齐了人类偏好。此外，DeepSeek-V2.5 在写作任务、指令跟随等多个方面也实现了大幅提升。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'claude-3-5-haiku-20241022', 'Claude 3.5 Haiku', 'chat', 200000, 8192, 0.001, 0.005, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"5m": 1.25}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2024-11-05", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Claude 3.5 Haiku 是 Anthropic 最快的下一代模型。与 Claude 3 Haiku 相比，Claude 3.5 Haiku 在各项技能上都有所提升，并在许多智力基准测试中超越了上一代最大的模型 Claude 3 Opus。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'claude-3-5-sonnet-20241022', 'Claude 3.5 Sonnet', 'chat', 200000, 8192, 0.003, 0.015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"5m": 3.75}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2024-10-22", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Claude 3.5 Sonnet 提供了超越 Opus 的能力和比 Sonnet 更快的速度，同时保持与 Sonnet 相同的价格。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'claude-3-5-sonnet-20240620', 'Claude 3.5 Sonnet 0620', 'chat', 200000, 8192, 0.003, 0.015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"5m": 3.75}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2024-06-20", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Claude 3.5 Sonnet 提供了超越 Opus 的能力和比 Sonnet 更快的速度，同时保持与 Sonnet 相同的价格。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'claude-3-haiku-20240307', 'Claude 3 Haiku', 'chat', 200000, 4096, 0.00025, 0.00125, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-03-07", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Claude 3 Haiku 是 Anthropic 的最快且最紧凑的模型，旨在实现近乎即时的响应。它具有快速且准确的定向性能。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'claude-3-sonnet-20240229', 'Claude 3 Sonnet', 'chat', 200000, 4096, 0.003, 0.015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-02-29", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Claude 3 Sonnet 在智能和速度方面为企业工作负载提供了理想的平衡。它以更低的价格提供最大效用，可靠且适合大规模部署。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'claude-3-opus-20240229', 'Claude 3 Opus', 'chat', 200000, 4096, 0.015, 0.075, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 75, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-02-29", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Claude 3 Opus 是 Anthropic 用于处理高度复杂任务的最强大模型。它在性能、智能、流畅性和理解力方面表现卓越。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'claude-2.1', 'Claude 2.1', 'chat', 200000, 4096, 0.008, 0.024, '{"pricing": {"units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 24, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2023-11-21", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Claude 2 为企业提供了关键能力的进步，包括业界领先的 200K token 上下文、大幅降低模型幻觉的发生率、系统提示以及一个新的测试功能：工具调用。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'claude-2.0', 'Claude 2.0', 'chat', 100000, 4096, 0.008, 0.024, '{"pricing": {"units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 24, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2023-07-11", "source": "builtin", "maxToken": 100000, "contextWindowTokens": 100000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Claude 2 为企业提供了关键能力的进步，包括业界领先的 200K token 上下文、大幅降低模型幻觉的发生率、系统提示以及一个新的测试功能：工具调用。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemini-1.5-flash-latest', 'Gemini 1.5 Flash', 'chat', 1008192, 8192, 0.000075, 0.0003, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.018, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1008192, "contextWindowTokens": 1008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Flash 是Google最新的多模态AI模型，具备快速处理能力，支持文本、图像和视频输入，适用于多种任务的高效扩展。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemini-1.5-flash-002', 'Gemini 1.5 Flash 002', 'chat', 1008192, 8192, 0.000075, 0.0003, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.018, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-25", "source": "builtin", "maxToken": 1008192, "contextWindowTokens": 1008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Flash 002 是一款高效的多模态模型，支持广泛应用的扩展。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemini-1.5-flash-001', 'Gemini 1.5 Flash 001', 'chat', 1008192, 8192, 0.000075, 0.0003, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.018, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1008192, "contextWindowTokens": 1008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Flash 001 是一款高效的多模态模型，支持广泛应用的扩展。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemini-1.5-flash-exp-0827', 'Gemini 1.5 Flash 0827', 'chat', 1008192, 8192, 0.000075, 0.0003, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.018, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-08-27", "source": "builtin", "maxToken": 1008192, "contextWindowTokens": 1008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Flash 0827 提供了优化后的多模态处理能力，适用多种复杂任务场景。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemini-1.5-flash-8b', 'Gemini 1.5 Flash 8B', 'chat', 1008192, 8192, 0.000075, 0.0003, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.02, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-10-03", "source": "builtin", "maxToken": 1008192, "contextWindowTokens": 1008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Flash 8B 是一款高效的多模态模型，支持广泛应用的扩展。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemini-1.5-flash-8b-exp-0924', 'Gemini 1.5 Flash 8B 0924', 'chat', 1008192, 8192, 0.000075, 0.0003, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.018, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-24", "source": "builtin", "maxToken": 1008192, "contextWindowTokens": 1008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Flash 8B 0924 是最新的实验性模型，在文本和多模态用例中都有显著的性能提升。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemini-1.5-pro-latest', 'Gemini 1.5 Pro', 'chat', 2008192, 8192, 0.0035, 0.0105, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.875, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-02-15", "source": "builtin", "maxToken": 2008192, "contextWindowTokens": 2008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Pro 支持高达200万个tokens，是中型多模态模型的理想选择，适用于复杂任务的多方面支持。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemini-1.5-pro-002', 'Gemini 1.5 Pro 002', 'chat', 2008192, 8192, 0.00125, 0.0025, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.315, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-24", "source": "builtin", "maxToken": 2008192, "contextWindowTokens": 2008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Pro 002 是最新的生产就绪模型，提供更高质量的输出，特别在数学、长上下文和视觉任务方面有显著提升。", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemini-1.5-pro-001', 'Gemini 1.5 Pro 001', 'chat', 2008192, 8192, 0.0035, 0.0105, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.875, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-02-15", "source": "builtin", "maxToken": 2008192, "contextWindowTokens": 2008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Pro 001 是可扩展的多模态AI解决方案，支持广泛的复杂任务。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemini-1.5-pro-exp-0827', 'Gemini 1.5 Pro 0827', 'chat', 2008192, 8192, 0.0035, 0.0105, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.875, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-08-27", "source": "builtin", "maxToken": 2008192, "contextWindowTokens": 2008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Pro 0827 结合最新优化技术，带来更高效的多模态数据处理能力。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemini-1.5-pro-exp-0801', 'Gemini 1.5 Pro 0801', 'chat', 2008192, 8192, 0.0035, 0.0105, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.875, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-08-01", "source": "builtin", "maxToken": 2008192, "contextWindowTokens": 2008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Pro 0801 提供出色的多模态处理能力，为应用开发带来更大灵活性。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemini-1.0-pro-latest', 'Gemini 1.0 Pro', 'chat', 32768, 2048, 0.0005, 0.0015, '{"pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2023-12-06", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 2048, "maxOutput": 2048, "description": "Gemini 1.0 Pro 是Google的高性能AI模型，专为广泛任务扩展而设计。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemini-1.0-pro-001', 'Gemini 1.0 Pro 001 (Tuning)', 'chat', 32768, 2048, 0.0005, 0.0015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2023-12-06", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 2048, "maxOutput": 2048, "description": "Gemini 1.0 Pro 001 (Tuning) 提供稳定并可调优的性能，是复杂任务解决方案的理想选择。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'gemini-1.0-pro-002', 'Gemini 1.0 Pro 002 (Tuning)', 'chat', 32768, 2048, 0.0005, 0.0015, '{"pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2023-12-06", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 2048, "maxOutput": 2048, "description": "Gemini 1.0 Pro 002 (Tuning) 提供出色的多模态支持，专注于复杂任务的有效解决。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'open-mistral-nemo', 'Mistral Nemo', 'chat', 128000, NULL, 0.00015, 0.00015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Mistral Nemo是一个与Nvidia合作开发的12B模型，提供出色的推理和编码性能，易于集成和替换。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'mistral-small-latest', 'Mistral Small', 'chat', 128000, NULL, 0.0002, 0.0006, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Mistral Small是成本效益高、快速且可靠的选项，适用于翻译、摘要和情感分析等用例。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'mistral-large-latest', 'Mistral Large', 'chat', 128000, NULL, 0.002, 0.006, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Mistral Large是旗舰大模型，擅长多语言任务、复杂推理和代码生成，是高端应用的理想选择。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'codestral-latest', 'Codestral', 'chat', 32768, NULL, 0.0002, 0.0006, '{"pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Codestral是专注于代码生成的尖端生成模型，优化了中间填充和代码补全任务。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'pixtral-12b-2409', 'Pixtral 12B', 'chat', 128000, NULL, 0.00015, 0.00015, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Pixtral 模型在图表和图理解、文档问答、多模态推理和指令遵循等任务上表现出强大的能力，能够以自然分辨率和宽高比摄入图像，还能够在长达 128K 令牌的长上下文窗口中处理任意数量的图像。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ministral-3b-latest', 'Ministral 3B', 'chat', 128000, NULL, 0.00004, 0.00004, '{"pricing": {"units": [{"name": "textInput", "rate": 0.04, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.04, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Ministral 3B 是Mistral的世界顶级边缘模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'ministral-8b-latest', 'Ministral 8B', 'chat', 128000, NULL, 0.0001, 0.0001, '{"pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Ministral 8B 是Mistral的性价比极高的边缘模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'open-mistral-7b', 'Mistral 7B', 'chat', 32768, NULL, 0.00025, 0.00025, '{"pricing": {"units": [{"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Mistral 7B是一款紧凑但高性能的模型，擅长批量处理和简单任务，如分类和文本生成，具有良好的推理能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'open-mixtral-8x7b', 'Mixtral 8x7B', 'chat', 32768, NULL, 0.0007, 0.0007, '{"pricing": {"units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Mixtral 8x7B是一个稀疏专家模型，利用多个参数提高推理速度，适合处理多语言和代码生成任务。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'open-mixtral-8x22b', 'Mixtral 8x22B', 'chat', 65536, NULL, 0.002, 0.006, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "Mixtral 8x22B是一个更大的专家模型，专注于复杂任务，提供出色的推理能力和更高的吞吐量。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'open-codestral-mamba', 'Codestral Mamba', 'chat', 256000, NULL, 0.00015, 0.00015, '{"pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "Codestral Mamba是专注于代码生成的Mamba 2语言模型，为先进的代码和推理任务提供强力支持。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'abab6.5s-chat', 'abab6.5s', 'chat', 245760, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 245760, "contextWindowTokens": 245760, "description": "适用于广泛的自然语言处理任务，包括文本生成、对话系统等。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'abab6.5g-chat', 'abab6.5g', 'chat', 8192, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "专为多语种人设对话设计，支持英文及其他多种语言的高质量对话生成。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'abab6.5t-chat', 'abab6.5t', 'chat', 8192, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "针对中文人设对话场景优化，提供流畅且符合中文表达习惯的对话生成能力。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'abab5.5-chat', 'abab5.5', 'chat', 16384, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "面向生产力场景，支持复杂任务处理和高效文本生成，适用于专业领域应用。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'abab5.5s-chat', 'abab5.5s', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "专为中文人设对话场景设计，提供高质量的中文对话生成能力，适用于多种应用场景。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'command-r', 'command-r', 'chat', NULL, NULL, NULL, NULL, '{"source": "builtin", "description": ""}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'command-r-plus', 'command-r-plus', 'chat', NULL, NULL, NULL, NULL, '{"source": "builtin", "description": ""}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'command-light', 'command-light', 'chat', NULL, NULL, NULL, NULL, '{"source": "builtin", "description": ""}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Doubao-lite-4k', 'Doubao-lite-4k', 'chat', NULL, NULL, NULL, NULL, '{"source": "builtin", "description": "Doubao-lite拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持4k上下文窗口的推理和精调。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Doubao-lite-32k', 'Doubao-lite-32k', 'chat', NULL, NULL, NULL, NULL, '{"source": "builtin", "description": "Doubao-lite拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持32k上下文窗口的推理和精调。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Doubao-lite-128k', 'Doubao-lite-128k', 'chat', NULL, NULL, NULL, NULL, '{"source": "builtin", "description": "Doubao-lite 拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持128k上下文窗口的推理和精调。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Doubao-pro-4k', 'Doubao-pro-4k', 'chat', NULL, NULL, NULL, NULL, '{"source": "builtin", "description": "效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持4k上下文窗口的推理和精调。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Doubao-pro-32k', 'Doubao-pro-32k', 'chat', NULL, NULL, NULL, NULL, '{"source": "builtin", "description": "效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持32k上下文窗口的推理和精调。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Doubao-pro-128k', 'Doubao-pro-128k', 'chat', NULL, NULL, NULL, NULL, '{"source": "builtin", "description": "效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持128k上下文窗口的推理和精调。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Skylark2-pro-character-4k', 'Skylark2-pro-character-4k', 'chat', NULL, NULL, NULL, NULL, '{"source": "builtin", "description": "云雀（Skylark）第二代模型，Skylark2-pro-character模型具有优秀的角色扮演和聊天能力，擅长根据用户prompt要求扮演不同角色与用户展开聊天，角色风格突出，对话内容自然流畅，适用于构建聊天机器人、虚拟助手和在线客服等场景，有较高的响应速度。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Skylark2-pro-32k', 'Skylark2-pro-32k', 'chat', NULL, NULL, NULL, NULL, '{"source": "builtin", "description": "云雀（Skylark）第二代模型，Skylark2-pro版本有较高的模型精度，适用于较为复杂的文本生成场景，如专业领域文案生成、小说创作、高质量翻译等，上下文窗口长度为32k。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Skylark2-pro-4k', 'Skylark2-pro-4k', 'chat', NULL, NULL, NULL, NULL, '{"source": "builtin", "description": "云雀（Skylark）第二代模型，Skylark2-pro模型有较高的模型精度，适用于较为复杂的文本生成场景，如专业领域文案生成、小说创作、高质量翻译等，上下文窗口长度为4k。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Skylark2-pro-turbo-8k', 'Skylark2-pro-turbo-8k', 'chat', NULL, NULL, NULL, NULL, '{"source": "builtin", "description": "云雀（Skylark）第二代模型，Skylark2-pro-turbo-8k推理更快，成本更低，上下文窗口长度为8k。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'higress'), 'Skylark2-lite-8k', 'Skylark2-lite-8k', 'chat', NULL, NULL, NULL, NULL, '{"source": "builtin", "description": "云雀（Skylark）第二代模型，Skylark2-lite模型有较高的响应速度，适用于实时性要求高、成本敏感、对模型精度要求不高的场景，上下文窗口长度为8k。"}', FALSE),
    -- huggingface
    ((SELECT id FROM ai_providers WHERE code = 'huggingface'), 'mistralai/Mistral-7B-Instruct-v0.3', 'Mistral 7B Instruct v0.3', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Mistral AI的指令调优模型"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'huggingface'), 'google/gemma-2-2b-it', 'Gemma 2 2B Instruct', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Google的轻量级指令调优模型"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'huggingface'), 'Qwen/Qwen2.5-72B-Instruct', 'Qwen 2.5 72B Instruct', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "阿里云通义千问团队开发的大型语言模型"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'huggingface'), 'Qwen/Qwen2.5-Coder-32B-Instruct', 'Qwen 2.5 Coder 32B Instruct', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5-Coder 专注于代码编写"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'huggingface'), 'Qwen/QwQ-32B-Preview', 'QwQ 32B Preview', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen QwQ 是由 Qwen 团队开发的实验研究模型，专注于提升AI推理能力。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'huggingface'), 'microsoft/Phi-3.5-mini-instruct', 'Phi 3.5 mini instruct', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'huggingface'), 'NousResearch/Hermes-3-Llama-3.1-8B', 'Hermes 3 Llama 3.1 8B', 'chat', 16384, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'huggingface'), 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B', 'DeepSeek R1 (Distill Qwen 32B)', 'chat', 16384, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'huggingface'), 'deepseek-ai/DeepSeek-R1', 'DeepSeek R1', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "reasoning": true}', FALSE),
    -- hunyuan
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-a13b', 'Hunyuan A13B', 'chat', 256000, 32000, NULL, NULL, '{"abilities": {"reasoning": true, "search": true}, "settings": {"extendParams": ["enableReasoning"], "searchImpl": "params"}, "released_at": "2025-06-25", "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "混元第一个混合推理模型，hunyuan-standard-256K 的升级版本，总参数80B，激活13B，默认是慢思考模式，支持通过参数或者指令进行快慢思考模式切换，慢快思考切换方式为 query 前加/ no_think；整体能力相对上一代全面提升，特别数学、科学、长文理解和 Agent 能力提升显著。", "reasoning": true, "web_search": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-t1-latest', 'Hunyuan T1', 'chat', 96000, 64000, 0.001, 0.004, '{"abilities": {"reasoning": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-22", "source": "builtin", "maxToken": 96000, "contextWindowTokens": 96000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "大幅提升主模型慢思考模型的高难数学、复杂推理、高难代码、指令遵循、文本创作质量等能力。", "reasoning": true, "web_search": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-t1-20250711', 'Hunyuan T1 20250711', 'chat', 92000, 64000, 0.001, 0.004, '{"abilities": {"reasoning": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-11", "source": "builtin", "maxToken": 92000, "contextWindowTokens": 92000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "大幅提升高难度数学、逻辑和代码能力，优化模型输出稳定性，提升模型长文能力。", "reasoning": true, "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-t1-20250529', 'Hunyuan T1 20250529', 'chat', 92000, 64000, 0.001, 0.004, '{"abilities": {"reasoning": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-05-29", "source": "builtin", "maxToken": 92000, "contextWindowTokens": 92000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "优化文本创作、作文写作，优化代码前端、数学、逻辑推理等理科能力，提升指令遵循能力。", "reasoning": true, "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-t1-20250403', 'Hunyuan T1 20250403', 'chat', 92000, 64000, 0.001, 0.004, '{"abilities": {"reasoning": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-03", "source": "builtin", "maxToken": 92000, "contextWindowTokens": 92000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "提升项目级别代码生成能力；提升文本生成写作质量；提升文本理解 topic 的多轮、tob 指令遵循和字词理解能力；优化繁简混杂和中英混杂输出问题。", "reasoning": true, "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-t1-20250321', 'Hunyuan T1 20250321', 'chat', 92000, 64000, 0.001, 0.004, '{"abilities": {"reasoning": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-21", "source": "builtin", "maxToken": 92000, "contextWindowTokens": 92000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "全面搭建模型文理科能力，长文本信息捕捉能力强。支持推理解答各种难度的数学/逻辑推理/科学/代码等科学问题。", "reasoning": true, "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-lite', 'Hunyuan Lite', 'chat', 256000, 6000, 0, 0, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-10-30", "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "maxOutputTokens": 6000, "maxOutput": 6000, "description": "升级为 MOE 结构，上下文窗口为 256k ，在 NLP，代码，数学，行业等多项评测集上领先众多开源模型。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-standard', 'Hunyuan Standard', 'chat', 32000, 2000, 0.0008, 0.002, '{"abilities": {"search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-10", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 2000, "maxOutput": 2000, "description": "采用更优的路由策略，同时缓解了负载均衡和专家趋同的问题。长文方面，大海捞针指标达到99.9%。MOE-32K 性价比相对更高，在平衡效果、价格的同时，可对实现对长文本输入的处理。", "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-standard-256K', 'Hunyuan Standard 256K', 'chat', 256000, 6000, 0.0005, 0.002, '{"abilities": {"search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-10", "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "maxOutputTokens": 6000, "maxOutput": 6000, "description": "采用更优的路由策略，同时缓解了负载均衡和专家趋同的问题。长文方面，大海捞针指标达到99.9%。MOE-256K 在长度和效果上进一步突破，极大的扩展了可输入长度。", "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-large', 'Hunyuan Large', 'chat', 32000, 4000, 0.004, 0.012, '{"abilities": {"search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-10", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "Hunyuan-large 模型总参数量约 389B，激活参数量约 52B，是当前业界参数规模最大、效果最好的 Transformer 架构的开源 MoE 模型。", "web_search": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-large-longcontext', 'Hunyuan Large Longcontext', 'chat', 134000, 6000, 0.006, 0.018, '{"abilities": {"search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 18, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-12-18", "source": "builtin", "maxToken": 134000, "contextWindowTokens": 134000, "maxOutputTokens": 6000, "maxOutput": 6000, "description": "擅长处理长文任务如文档摘要和文档问答等，同时也具备处理通用文本生成任务的能力。在长文本的分析和生成上表现优异，能有效应对复杂和详尽的长文内容处理需求。", "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-turbo-latest', 'Hunyuan Turbo', 'chat', 32000, 4000, 0.0024, 0.0096, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9.6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-10", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "通用体验优化，包括NLP理解、文本创作、闲聊、知识问答、翻译、领域等；提升拟人性，优化模型情商；提升意图模糊时模型主动澄清能力；提升字词解析类问题的处理能力；提升创作的质量和可互动性；提升多轮体验。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-turbo-20241223', 'Hunyuan Turbo 20241223', 'chat', 32000, 4000, 0.0024, 0.0096, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9.6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-10", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "本版本优化：数据指令scaling，大幅提升模型通用泛化能力；大幅提升数学、代码、逻辑推理能力；优化文本理解字词理解相关能力；优化文本创作内容生成质量", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-turbos-longtext-128k-20250325', 'Hunyuan TurboS LongText 128K', 'chat', 134000, 6000, 0.0015, 0.006, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-25", "source": "builtin", "maxToken": 134000, "contextWindowTokens": 134000, "maxOutputTokens": 6000, "maxOutput": 6000, "description": "擅长处理长文任务如文档摘要和文档问答等，同时也具备处理通用文本生成任务的能力。在长文本的分析和生成上表现优异，能有效应对复杂和详尽的长文内容处理需求。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-turbos-latest', 'Hunyuan TurboS', 'chat', 44000, 16000, 0.0008, 0.002, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-16", "source": "builtin", "maxToken": 44000, "contextWindowTokens": 44000, "maxOutputTokens": 16000, "maxOutput": 16000, "description": "hunyuan-TurboS 混元旗舰大模型最新版本，具备更强的思考能力，更优的体验效果。", "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-turbos-20250926', 'Hunyuan TurboS 20250926', 'chat', 44000, 16000, 0.0008, 0.002, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-26", "source": "builtin", "maxToken": 44000, "contextWindowTokens": 44000, "maxOutputTokens": 16000, "maxOutput": 16000, "description": "预训练底座数据质量升级。优化 posttrain 阶段训练策略，持续提升 Agent、英语小语种、指令遵循、代码和理科能力。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-turbos-20250604', 'Hunyuan TurboS 20250604', 'chat', 44000, 16000, 0.0008, 0.002, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-04", "source": "builtin", "maxToken": 44000, "contextWindowTokens": 44000, "maxOutputTokens": 16000, "maxOutput": 16000, "description": "预训练底座升级，写作、阅读理解能力提升，较大幅度提升代码和理科能力，复杂指令遵循等持续提升。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-turbos-20250416', 'Hunyuan TurboS 20250416', 'chat', 32000, 8000, 0.0008, 0.002, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-16", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 8000, "maxOutput": 8000, "description": "预训练底座升级，增强底座的指令理解及遵循能力；对齐阶段增强数学、代码、逻辑、科学等理科能力；提升文创写作质量、文本理解、翻译准确率、知识问答等文科能力；增强各领域 Agent 能力，重点加强多轮对话理解能力等。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-turbos-20250313', 'Hunyuan TurboS 20250313', 'chat', 32000, 8000, 0.0008, 0.002, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-13", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 8000, "maxOutput": 8000, "description": "统一数学解题步骤的风格，加强数学多轮问答。文本创作优化回答风格，去除AI味，增加文采。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-lite-vision', 'Hunyuan Lite Vision', 'chat', 36000, 4000, NULL, NULL, '{"abilities": {"vision": true}, "released_at": "2024-12-12", "source": "builtin", "maxToken": 36000, "contextWindowTokens": 36000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "混元最新7B多模态模型，上下文窗口32K，支持中英文场景的多模态对话、图像物体识别、文档表格理解、多模态数学等，在多个维度上评测指标优于7B竞品模型。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-standard-vision', 'Hunyuan Standard Vision', 'chat', 8000, 2000, NULL, NULL, '{"abilities": {"vision": true}, "released_at": "2024-12-31", "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "maxOutputTokens": 2000, "maxOutput": 2000, "description": "混元最新多模态模型，支持多语种作答，中英文能力均衡。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-turbo-vision', 'Hunyuan Turbo Vision', 'chat', 8000, 2000, 0.08, 0.08, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 80, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 80, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-11-26", "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "maxOutputTokens": 2000, "maxOutput": 2000, "description": "混元新一代视觉语言旗舰大模型，采用全新的混合专家模型（MoE）结构，在图文理解相关的基础识别、内容创作、知识问答、分析推理等能力上相比前一代模型全面提升。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-large-vision', 'Hunyuan Large Vision', 'chat', 16000, 8000, NULL, NULL, '{"abilities": {"vision": true}, "released_at": "2025-05-26", "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "maxOutputTokens": 8000, "maxOutput": 8000, "description": "此模型适用于图文理解场景，是基于混元Large训练的视觉语言大模型，支持任意分辨率多张图片+文本输入，生成文本内容，聚焦图文理解相关任务，在多语言图文理解能力上有显著提升。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-t1-vision-20250916', 'Hunyuan T1 Vision 20250916', 'chat', 40000, 16000, 0.003, 0.009, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-16", "source": "builtin", "maxToken": 40000, "contextWindowTokens": 40000, "maxOutputTokens": 16000, "maxOutput": 16000, "description": "混元最新版 t1-vision 视觉深度思考模型，相比上一版模型在通用图文问答、视觉定位、OCR、图表、拍题解题、看图创作等任务上全面提升，显著优化了英文和小语种能力。", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-t1-vision-20250619', 'Hunyuan T1 Vision 20250619', 'chat', 40000, 16000, 0.003, 0.009, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-19", "source": "builtin", "maxToken": 40000, "contextWindowTokens": 40000, "maxOutputTokens": 16000, "maxOutput": 16000, "description": "混元最新版t1-vision多模态理解深度思考模型，支持多模态原生长思维链，相比上一代默认版本模型全面提升。", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-turbos-vision-20250619', 'Hunyuan TurboS Vision 20250619', 'chat', 32000, 16000, 0.003, 0.009, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-19", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 16000, "maxOutput": 16000, "description": "混元最新版turbos-vision视觉语言旗舰大模型，在图文理解相关的任务上，包括基于图片的实体识别、知识问答、文案创作、拍照解题等上面相比上一代默认版本模型全面提升。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-turbos-vision', 'Hunyuan TurboS Vision', 'chat', 32000, 24000, 0.003, 0.009, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-05-23", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 24000, "maxOutput": 24000, "description": "此模型适用于图文理解场景，是基于混元最新 turbos 的新一代视觉语言旗舰大模型，聚焦图文理解相关任务，包括基于图片的实体识别、知识问答、文案创作、拍照解题等方面，相比前一代模型全面提升。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-vision', 'Hunyuan Vision', 'chat', 32000, 16000, 0.018, 0.018, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 18, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 18, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-03", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 16000, "maxOutput": 16000, "description": "混元最新多模态模型，支持图片+文本输入生成文本内容。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-code', 'Hunyuan Code', 'chat', 8000, 4000, 0.0035, 0.007, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 7, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-11-12", "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "混元最新代码生成模型，经过 200B 高质量代码数据增训基座模型，迭代半年高质量 SFT 数据训练，上下文长窗口长度增大到 8K，五大语言代码生成自动评测指标上位居前列；五大语言10项考量各方面综合代码任务人工高质量评测上，性能处于第一梯队"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-functioncall', 'Hunyuan FunctionCall', 'chat', 32000, 4000, 0.004, 0.008, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-22", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "混元最新 MOE 架构 FunctionCall 模型，经过高质量的 FunctionCall 数据训练，上下文窗口达 32K，在多个维度的评测指标上处于领先。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-role', 'Hunyuan Role', 'chat', 32000, 4000, 0.004, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-07-04", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "混元最新版角色扮演模型，混元官方精调训练推出的角色扮演模型，基于混元模型结合角色扮演场景数据集进行增训，在角色扮演场景具有更好的基础效果。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'hunyuan'), 'hunyuan-turbos-role-plus', 'Hunyuan TurboS Role Plus', 'chat', 32000, 4000, NULL, NULL, '{"source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "混元最新版角色扮演模型，混元官方精调训练推出的角色扮演模型，基于混元模型结合角色扮演场景数据集进行增训，在角色扮演场景具有更好的基础效果。"}', FALSE),
    -- infiniai
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'glm-4.6', 'GLM-4.6', 'chat', 131072, 4096, 0.004, 0.016, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "GLM-4.6 是智谱AI推出的最新大语言模型，具备更强的推理和生成能力。", "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'deepseek-v3.2-exp', 'DeepSeek V3.2 Exp', 'chat', 131072, 65536, 0.002, 0.003, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "DeepSeek-V3.2-Exp 是深度求索推出的实验性大语言模型，具有更强的推理和生成能力。", "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen3-vl-235b-a22b-instruct', 'Qwen3 VL 235B A22B Instruct', 'chat', 131072, 32768, 0.002, 0.008, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "Qwen3 VL 235B A22B Instruct 是通义千问推出的多模态模型，支持视觉理解和推理。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen3-vl-235b-a22b-thinking', 'Qwen3 VL 235B A22B Thinking', 'chat', 131072, 32768, 0.002, 0.02, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "Qwen3 VL 235B A22B Thinking 是通义千问推出的多模态推理模型，支持视觉理解和推理。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'deepseek-v3.1-terminus', 'DeepSeek V3.1 Terminus', 'chat', 131072, 65536, 0.004, 0.012, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "DeepSeek-V3.1-Terminus 是深度求索推出的终端优化版本大语言模型，专为终端设备优化。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen3-next-80b-a3b-thinking', 'Qwen3 Next 80B A3B Thinking', 'chat', 131072, 32768, 0.001, 0.01, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "基于 Qwen3 的新一代思考模式开源模型，相较上一版本（通义千问3-235B-A22B-Thinking-2507）指令遵循能力有提升、模型总结回复更加精简。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen3-next-80b-a3b-instruct', 'Qwen3 Next 80B A3B Instruct', 'chat', 131072, 32768, 0.001, 0.01, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "基于 Qwen3 的新一代非思考模式开源模型，相较上一版本（通义千问3-235B-A22B-Instruct-2507）中文文本理解能力更佳、逻辑推理能力有增强、文本生成类任务表现更好。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'deepseek-v3.1', 'DeepSeek V3.1', 'chat', 131072, 32768, 0.004, 0.012, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "DeepSeek V3.1 模型为混合推理架构模型，同时支持思考模式与非思考模式。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'baichuan-m2-32b', 'Baichuan M2 32B', 'chat', 64000, 8192, 0.0029, 0.0116, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 11.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Baichuan M2 32B 是百川智能推出的混合专家模型，具备强大的推理能力。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'glm-4.5v', 'GLM-4.5V', 'chat', 131072, 4096, 0.004, 0.012, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "GLM-4.5V 是智谱AI推出的多模态模型，支持视觉理解和推理。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'glm-4.5', 'GLM-4.5', 'chat', 131072, 4096, 0.002, 0.008, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["enableReasoning"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "GLM-4.5系列模型是智谱AI专为智能体设计的混合推理模型，提供思考与非思考两种模式。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'glm-4.5-air', 'GLM-4.5-Air', 'chat', 131072, 4096, 0.0006, 0.004, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "GLM-4.5-Air 是智谱AI推出的轻量级大语言模型，具备高效的推理能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'step3', 'Step3', 'chat', 131072, 4096, 0.0015, 0.004, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Step3 是阶跃星辰推出的多模态模型，具备强大的视觉理解能力。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen3-coder-480b-a35b-instruct', 'Qwen3 Coder 480B A35B', 'chat', 262144, 32768, 0.009, 0.036, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 36, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "通义千问代码模型开源版。最新的 qwen3-coder-480b-a35b-instruct 是基于 Qwen3 的代码生成模型，具有强大的Coding Agent能力，擅长工具调用和环境交互，能够实现自主编程、代码能力卓越的同时兼具通用能力。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen3-235b-a22b-instruct-2507', 'Qwen3 235B A22B Instruct 2507', 'chat', 131072, 8192, 0.002, 0.008, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "基于Qwen3的非思考模式开源模型，相较上一版本（通义千问3-235B-A22B）主观创作能力与模型安全性均有小幅度提升。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'kimi-k2-instruct', 'Kimi K2 Instruct', 'chat', 131072, 32768, 0.004, 0.016, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "Kimi K2 Instruct 是月之暗面推出的大语言模型，具有超长上下文处理能力。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'ernie-4.5-300b-a47b', 'ERNIE 4.5 300B A47B', 'chat', 32000, 8192, 0.0029, 0.0029, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "ERNIE 4.5 300B A47B 是百度文心推出的超大规模混合专家模型，具备卓越的推理能力。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'ernie-4.5-21b-a3b', 'ERNIE 4.5 21B A3B', 'chat', 120000, 8192, 0.001, 0.001, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 120000, "contextWindowTokens": 120000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "ERNIE 4.5 21B A3B 是百度文心推出的混合专家模型，具备强大的推理和多语言能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen3-8b', 'Qwen3 8B', 'chat', 131072, 8192, 0.001, 0.004, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Qwen3-8B 是 Qwen 系列第三代的大型语言模型，拥有 82 亿参数，专为高效推理和多语言任务设计。支持无缝切换思维模式（复杂推理）和非思维模式（通用对话），在数学、编码、常识推理及多语言指令执行中表现出色。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen3-14b', 'Qwen3 14B', 'chat', 131072, 8192, 0.002, 0.008, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Qwen3-14B 是 Qwen 系列第三代的大型语言模型，拥有 148 亿参数，专为高效推理和多语言任务设计。支持无缝切换思维模式（复杂推理）和非思维模式（通用对话），在数学、编码、常识推理及多语言指令执行中表现出色。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen3-32b', 'Qwen3 32B', 'chat', 131072, 8192, 0.0029, 0.0116, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 11.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Qwen3-32B 是 Qwen 系列第三代的大型语言模型，拥有 328 亿参数，专为高效推理和多语言任务设计。支持无缝切换思考模式（复杂推理）和非思考模式（通用对话），在数学、编码、常识推理及多语言指令执行中表现出色。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen3-30b-a3b', 'Qwen3 30B A3B', 'chat', 131072, 8192, 0.0022, 0.0087, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8.7, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Qwen3-30B-A3B 是 Qwen 系列第三代的大型语言模型，采用混合专家（MoE）架构，总计 305 亿参数，每 token 激活 33 亿参数。支持无缝切换思维模式（复杂推理）和非思维模式（通用对话），在数学、编码、常识推理及多语言指令执行中表现出色。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen3-235b-a22b', 'Qwen3 235B A22B', 'chat', 131072, 8192, 0.005, 0.02, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Qwen3-235B-A22B 是 Qwen 系列第三代的大型语言模型，采用混合专家（MoE）架构，总计 2350 亿参数，每 token 激活 220 亿参数。支持无缝切换思考模式（复杂推理）和非思维模式（通用对话），在数学、编码、常识推理及多语言指令执行中表现出色。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen2.5-vl-72b-instruct', 'Qwen2.5 VL 72B Instruct', 'chat', 125000, 4096, 0.01, 0.01, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 125000, "contextWindowTokens": 125000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Qwen2.5-VL 系列模型提升了模型的智能水平、实用性和适用性，使其在自然对话、内容创作、专业知识服务及代码开发等场景中表现更优。旗舰模型 Qwen2.5-VL-72B-Instruct 在涵盖多个领域和任务的基准测试中展现出强大的竞争力，包括大学水平的问题解答、数学、文档理解、通用问答、视频理解以及视觉代理任务等。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen2.5-vl-32b-instruct', 'Qwen2.5 VL 32B Instruct', 'chat', 125000, 4096, 0.0058, 0.0058, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5.8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 125000, "contextWindowTokens": 125000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Qwen2.5-VL 系列模型提升了模型的智能水平、实用性和适用性，使其在自然对话、内容创作、专业知识服务及代码开发等场景中表现更优。模型 Qwen2.5-VL-32B-Instruct 在涵盖多个领域和任务的基准测试中展现出强大的竞争力，包括大学水平的问题解答、数学、文档理解、通用问答、视频理解以及视觉代理任务等。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen2.5-vl-7b-instruct', 'Qwen2.5 VL 7B Instruct', 'chat', 125000, 4096, 0.002, 0.002, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 125000, "contextWindowTokens": 125000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Qwen2.5-VL 系列模型提升了模型的智能水平、实用性和适用性，使其在自然对话、内容创作、专业知识服务及代码开发等场景中表现更优。模型 Qwen2.5-VL-7B-Instruct 在涵盖多个领域和任务的基准测试中展现出强大的竞争力，包括大学水平的问题解答、数学、文档理解、通用问答、视频理解以及视觉代理任务等。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwq-32b', 'QwQ 32B', 'chat', 32000, 8192, 0.0029, 0.0029, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "QwQ 32B 是通义千问推出的推理专用模型，专注于推理任务。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'deepseek-v3', 'DeepSeek V3 0324', 'chat', 131072, 16384, 0.002, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "DeepSeek-V3-0324 是一个强大的专家混合（MoE）语言模型，总参数量为 671B，每个 Token 激活 37B 参数。该模型采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，实现了高效推理和经济训练，并在前代 DeepSeek-V3 的基础上显著提升了性能。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'deepseek-r1', 'DeepSeek R1', 'chat', 131072, 32768, 0.004, 0.016, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "DeepSeek-R1 是一个专注于推理能力的大语言模型，通过创新的训练流程实现了与 OpenAI-o1 相当的数学、代码和推理任务表现。该模型采用了冷启动数据和大规模强化学习相结合的方式进行训练。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'deepseek-r1-distill-qwen-32b', 'DeepSeek R1 Distill Qwen 32B', 'chat', 32000, 8192, 0.0029, 0.0029, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "DeepSeek R1 Distill Qwen 32B 是深度求索基于Qwen蒸馏的高效模型。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'megrez-3b-instruct', 'Megrez 3B Instruct', 'chat', 32000, 4096, 0, 0, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Megrez 3B Instruct 是无问芯穹推出的小参数量高效模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen2.5-32b-instruct', 'Qwen2.5 32B Instruct', 'chat', 32768, NULL, 0.0029, 0.0029, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5 是 Qwen 大型语言模型系列的最新成果。Qwen2.5 发布了从 0.5 到 720 亿参数不等的基础语言模型及指令调优语言模型。Qwen2.5 相比 Qwen2 带来了以下改进：\n显著增加知识量，在编程与数学领域的能力得到极大提升。\n在遵循指令、生成长文本、理解结构化数据 (例如，表格) 以及生成结构化输出特别是 JSON 方面有显著提升。对系统提示的多样性更具韧性，增强了聊天机器人中的角色扮演实现和条件设定。\n支持长上下文处理。\n支持超过 29 种语言的多语言功能，包括中文、英语、法语、西班牙语、葡萄牙语、德语、意大利语、俄语、日语、韩语、越南语、泰语、阿拉伯语等。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen2.5-72b-instruct', 'Qwen2.5 72B Instruct', 'chat', 32768, NULL, 0.005, 0.005, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5 是 Qwen 大型语言模型系列的最新成果。Qwen2.5 发布了从 0.5 到 720 亿参数不等的基础语言模型及指令调优语言模型。Qwen2.5 相比 Qwen2 带来了以下改进：\n显著增加知识量，在编程与数学领域的能力得到极大提升。\n在遵循指令、生成长文本、理解结构化数据 (例如，表格) 以及生成结构化输出特别是 JSON 方面有显著提升。对系统提示的多样性更具韧性，增强了聊天机器人中的角色扮演实现和条件设定。\n支持长上下文处理。\n支持超过 29 种语言的多语言功能，包括中文、英语、法语、西班牙语、葡萄牙语、德语、意大利语、俄语、日语、韩语、越南语、泰语、阿拉伯语等。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen2.5-14b-instruct', 'Qwen2.5 14B Instruct', 'chat', 32768, NULL, 0.002, 0.002, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5 是 Qwen 大型语言模型系列的最新成果。Qwen2.5 发布了从 0.5 到 720 亿参数不等的基础语言模型及指令调优语言模型。Qwen2.5 相比 Qwen2 带来了以下改进：\n显著增加知识量，在编程与数学领域的能力得到极大提升。\n在遵循指令、生成长文本、理解结构化数据 (例如，表格) 以及生成结构化输出特别是 JSON 方面有显著提升。对系统提示的多样性更具韧性，增强了聊天机器人中的角色扮演实现和条件设定。\n支持长上下文处理。\n支持超过 29 种语言的多语言功能，包括中文、英语、法语、西班牙语、葡萄牙语、德语、意大利语、俄语、日语、韩语、越南语、泰语、阿拉伯语等。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen2.5-7b-instruct', 'Qwen2.5 7B Instruct', 'chat', 32768, NULL, 0.001, 0.001, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5 是 Qwen 大型语言模型系列的最新成果。Qwen2.5 发布了从 0.5 到 720 亿参数不等的基础语言模型及指令调优语言模型。Qwen2.5 相比 Qwen2 带来了以下改进：\n显著增加知识量，在编程与数学领域的能力得到极大提升。\n在遵循指令、生成长文本、理解结构化数据 (例如，表格) 以及生成结构化输出特别是 JSON 方面有显著提升。对系统提示的多样性更具韧性，增强了聊天机器人中的角色扮演实现和条件设定。\n支持长上下文处理。\n支持超过 29 种语言的多语言功能，包括中文、英语、法语、西班牙语、葡萄牙语、德语、意大利语、俄语、日语、韩语、越南语、泰语、阿拉伯语等。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'qwen2.5-coder-32b-instruct', 'Qwen2.5 Coder 32B Instruct', 'chat', 32768, 4096, 0.0029, 0.0029, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Qwen2.5-Coder 是最新的代码专用 Qwen 大型语言模型系列。Qwen2.5-Coder 在 CodeQwen1.5 的基础上带来了以下改进：\n显著提升代码生成、代码推理和代码修复能力。\n支持真实世界应用，例如代码代理，增强编码能力和数学及一般能力。\n支持长上下文处理。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'gpt-oss-120b', 'GPT-OSS-120B', 'chat', 131072, 32768, 0.0008, 0.0032, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "该模型需要申请体验。GPT-OSS-120B 是 OpenAI 推出的开源大规模语言模型，具备强大的文本生成能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'gpt-oss-20b', 'GPT-OSS-20B', 'chat', 131072, 32768, 0.0004, 0.0016, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "该模型需要申请体验。GPT-OSS-20B 是 OpenAI 推出的开源中型语言模型，具备高效的文本生成能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'pro-deepseek-r1', 'DeepSeek R1 (Pro)', 'chat', 131072, 32768, 0.004, 0.016, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "企业专属服务专用模型，包并发服务。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'infiniai'), 'pro-deepseek-v3', 'DeepSeek V3 (Pro)', 'chat', 131072, 16384, 0.002, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "企业专属服务专用模型，包并发服务。"}', FALSE),
    -- internlm
    ((SELECT id FROM ai_providers WHERE code = 'internlm'), 'internlm3-latest', 'InternLM3', 'chat', 32768, NULL, 0, 0, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "我们最新的模型系列，有着卓越的推理性能，领跑同量级开源模型。默认指向我们最新发布的 InternLM3 系列模型，当前指向 internlm3-8b-instruct。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'internlm'), 'internlm2.5-latest', 'InternLM2.5', 'chat', 32768, NULL, 0, 0, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "我们仍在维护的老版本模型，经过多轮迭代有着极其优异且稳定的性能，包含 7B、20B 多种模型参数量可选，支持 1M 的上下文长度以及更强的指令跟随和工具调用能力。默认指向我们最新发布的 InternLM2.5 系列模型，当前指向 internlm2.5-20b-chat。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'internlm'), 'internvl3-latest', 'InternVL3', 'chat', 32768, NULL, 0, 0, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "我们最新发布多模态大模型，具备更强的图文理解能力、长时序图片理解能力，性能比肩顶尖闭源模型。默认指向我们最新发布的 InternVL 系列模型，当前指向 internvl3-78b。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'internlm'), 'internvl2.5-latest', 'InternVL2.5', 'chat', 32768, NULL, 0, 0, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "我们仍在维护的 InternVL2.5 版本，具备优异且稳定的性能。默认指向我们最新发布的 InternVL2.5 系列模型，当前指向 internvl2.5-78b。", "vision": true}', FALSE),
    -- jina
    ((SELECT id FROM ai_providers WHERE code = 'jina'), 'jina-deepsearch-v1', 'Jina DeepSearch v1', 'chat', 1000000, NULL, 0.00002, 0.00002, '{"abilities": {"reasoning": true, "search": true}, "settings": {"searchImpl": "internal"}, "pricing": {"units": [{"name": "textInput", "rate": 0.02, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.02, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000, "description": "深度搜索结合了网络搜索、阅读和推理，可进行全面调查。您可以将其视为一个代理，接受您的研究任务 - 它会进行广泛搜索并经过多次迭代，然后才能给出答案。这个过程涉及持续的研究、推理和从各个角度解决问题。这与直接从预训练数据生成答案的标准大模型以及依赖一次性表面搜索的传统 RAG 系统有着根本的不同。", "reasoning": true, "web_search": true}', TRUE),
    -- lmstudio
    ((SELECT id FROM ai_providers WHERE code = 'lmstudio'), 'llama3.1', 'Llama 3.1 8B', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Llama 3.1 是 Meta 推出的领先模型，支持高达 405B 参数，可应用于复杂对话、多语言翻译和数据分析领域。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'lmstudio'), 'qwen2.5-14b-instruct', 'Qwen2.5 14B', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Qwen2.5 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。"}', TRUE),
    -- minimax
    ((SELECT id FROM ai_providers WHERE code = 'minimax'), 'MiniMax-M2', 'MiniMax M2', 'chat', 204800, 131072, 0.0021, 0.0084, '{"abilities": {"functionCall": true, "reasoning": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-10-27", "source": "builtin", "maxToken": 204800, "contextWindowTokens": 204800, "maxOutputTokens": 131072, "maxOutput": 131072, "description": "专为高效编码与Agent工作流而生", "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'minimax'), 'MiniMax-M1', 'MiniMax M1', 'chat', 1000192, 40000, 0.0012, 0.016, '{"abilities": {"functionCall": true, "reasoning": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-16", "source": "builtin", "maxToken": 1000192, "contextWindowTokens": 1000192, "maxOutputTokens": 40000, "maxOutput": 40000, "description": "全新自研推理模型。全球领先：80K 思维链 x 1M 输入，效果比肩海外顶尖模型", "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'minimax'), 'MiniMax-Text-01', 'MiniMax Text 01', 'chat', 1000192, 40000, 0.001, 0.008, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-15", "source": "builtin", "maxToken": 1000192, "contextWindowTokens": 1000192, "maxOutputTokens": 40000, "maxOutput": 40000, "description": "在 MiniMax-01系列模型中，我们做了大胆创新：首次大规模实现线性注意力机制，传统 Transformer架构不再是唯一的选择。这个模型的参数量高达4560亿，其中单次激活459亿。模型综合性能比肩海外顶尖模型，同时能够高效处理全球最长400万token的上下文，是GPT-4o的32倍，Claude-3.5-Sonnet的20倍。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'minimax'), 'image-01', 'Image 01', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"aspectRatio": {"default": "1:1", "enum": ["1:1", "16:9", "4:3", "3:2", "2:3", "3:4", "9:16", "21:9"]}, "prompt": {"default": ""}, "seed": {"default": null}}, "released_at": "2025-02-28", "source": "builtin", "description": "全新图像生成模型，画面表现细腻，支持文生图、图生图"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'minimax'), 'image-01-live', 'Image 01 Live', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"aspectRatio": {"default": "1:1", "enum": ["1:1", "16:9", "4:3", "3:2", "2:3", "3:4", "9:16", "21:9"]}, "prompt": {"default": ""}, "seed": {"default": null}}, "released_at": "2025-02-28", "source": "builtin", "description": "图像生成模型，画面表现细腻，支持文生图并进行画风设置"}', TRUE),
    -- mistral
    ((SELECT id FROM ai_providers WHERE code = 'mistral'), 'mistral-medium-latest', 'Mistral Medium 3.1', 'chat', 128000, NULL, 0.0004, 0.002, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Mistral Medium 3 以 8 倍的成本提供最先进的性能，并从根本上简化了企业部署。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'mistral'), 'magistral-medium-latest', 'Magistral Medium 1.2', 'chat', 128000, NULL, 0.002, 0.005, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Magistral Medium 1.2 是Mistral AI于2025年9月发布的前沿级推理模型，具有视觉支持。", "vision": true, "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'mistral'), 'magistral-small-2509', 'Magistral Small 1.2', 'chat', 128000, NULL, 0.0005, 0.0015, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Magistral Small 1.2 是Mistral AI于2025年9月发布的开源小型推理模型，具有视觉支持。", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'mistral'), 'open-mistral-nemo', 'Mistral Nemo', 'chat', 128000, NULL, 0.00015, 0.00015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Mistral Nemo是一个与Nvidia合作开发的12B模型，提供出色的推理和编码性能，易于集成和替换。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'mistral'), 'mistral-small-latest', 'Mistral Small 3.2', 'chat', 128000, NULL, 0.0001, 0.0003, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Mistral Small是成本效益高、快速且可靠的选项，适用于翻译、摘要和情感分析等用例。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'mistral'), 'mistral-large-latest', 'Mistral Large 2.1', 'chat', 131072, NULL, 0.002, 0.006, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Mistral Large是旗舰大模型，擅长多语言任务、复杂推理和代码生成，是高端应用的理想选择。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'mistral'), 'codestral-latest', 'Codestral 2508', 'chat', 256000, NULL, 0.0003, 0.0009, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-30", "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "Codestral 是我们最先进的编码语言模型，第二个版本于2025年1月发布，专门从事低延迟、高频任务如中间填充（RST）、代码纠正和测试生成。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'mistral'), 'pixtral-large-latest', 'Pixtral Large', 'chat', 131072, NULL, 0.002, 0.006, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Pixtral Large 是一款拥有 1240 亿参数的开源多模态模型，基于 Mistral Large 2 构建。这是我们多模态家族中的第二款模型，展现了前沿水平的图像理解能力。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'mistral'), 'pixtral-12b-2409', 'Pixtral 12B', 'chat', 131072, NULL, 0.00015, 0.00015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Pixtral 模型在图表和图理解、文档问答、多模态推理和指令遵循等任务上表现出强大的能力，能够以自然分辨率和宽高比摄入图像，还能够在长达 128K 令牌的长上下文窗口中处理任意数量的图像。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'mistral'), 'ministral-3b-latest', 'Ministral 3B', 'chat', 131072, NULL, 0.00004, 0.00004, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.04, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.04, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Ministral 3B 是Mistral的世界顶级边缘模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'mistral'), 'ministral-8b-latest', 'Ministral 8B', 'chat', 131072, NULL, 0.0001, 0.0001, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Ministral 8B 是Mistral的性价比极高的边缘模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'mistral'), 'open-codestral-mamba', 'Codestral Mamba', 'chat', 256000, NULL, 0, 0, '{"pricing": {"units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "Codestral Mamba是专注于代码生成的Mamba 2语言模型，为先进的代码和推理任务提供强力支持。"}', FALSE),
    -- modelscope
    ((SELECT id FROM ai_providers WHERE code = 'modelscope'), 'Qwen/Qwen3-Next-80B-A3B-Thinking', 'Qwen3 Next 80B A3B Thinking', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'modelscope'), 'Qwen/Qwen3-Next-80B-A3B-Instruct', 'Qwen3 Next 80B A3B Instruct', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'modelscope'), 'deepseek-ai/DeepSeek-V3.2-Exp', 'DeepSeek V3.2 Exp', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek V3.2 Exp 模型为混合推理架构模型，同时支持思考模式与非思考模式。", "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'modelscope'), 'deepseek-ai/DeepSeek-V3.1', 'DeepSeek V3.1', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek V3.1 模型为混合推理架构模型，同时支持思考模式与非思考模式。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'modelscope'), 'deepseek-ai/DeepSeek-R1-0528', 'DeepSeek R1 0528', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek R1 通过利用增加的计算资源和在后训练过程中引入算法优化机制，显著提高了其推理和推断能力的深度。该模型在各种基准评估中表现出色，包括数学、编程和一般逻辑方面。其整体性能现已接近领先模型，如 O3 和 Gemini 2.5 Pro。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'modelscope'), 'Qwen/Qwen3-235B-A22B', 'Qwen3 235B A22B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Qwen3 235B A22B是通义千问3代超大规模模型，提供顶级的AI能力。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'modelscope'), 'Qwen/Qwen3-32B', 'Qwen3 32B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Qwen3 32B是通义千问3代模型，具有强大的推理和对话能力。", "function_calling": true}', FALSE),
    -- moonshot
    ((SELECT id FROM ai_providers WHERE code = 'moonshot'), 'kimi-k2-0905-preview', 'Kimi K2 0905', 'chat', 262144, NULL, 0.004, 0.016, '{"abilities": {"functionCall": true, "structuredOutput": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput_cacheRead", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-05", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "kimi-k2-0905-preview 模型上下文长度为 256k，具备更强的 Agentic Coding 能力、更突出的前端代码的美观度和实用性、以及更好的上下文理解能力。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'moonshot'), 'kimi-k2-0711-preview', 'Kimi K2 0711', 'chat', 131072, NULL, 0.004, 0.016, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput_cacheRead", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-11", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "kimi-k2 是一款具备超强代码和 Agent 能力的 MoE 架构基础模型，总参数 1T，激活参数 32B。在通用知识推理、编程、数学、Agent 等主要类别的基准性能测试中，K2 模型的性能超过其他主流开源模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'moonshot'), 'kimi-k2-turbo-preview', 'Kimi K2 0905 Turbo', 'chat', 262144, NULL, 0.016, 0.064, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput_cacheRead", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 64, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-05", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "kimi-k2 是一款具备超强代码和 Agent 能力的 MoE 架构基础模型，总参数 1T，激活参数 32B。在通用知识推理、编程、数学、Agent 等主要类别的基准性能测试中，K2 模型的性能超过其他主流开源模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'moonshot'), 'kimi-latest', 'Kimi Latest', 'chat', 131072, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput_cacheRead", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-17", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Kimi 智能助手产品使用最新的 Kimi 大模型，可能包含尚未稳定的特性。支持图片理解，同时会自动根据请求的上下文长度选择 8k/32k/128k 模型作为计费模型", "vision": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'moonshot'), 'kimi-thinking-preview', 'Kimi Thinking Preview', 'chat', 131072, NULL, 0.2, 0.2, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 200, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 200, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-05-06", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "kimi-thinking-preview 模型是月之暗面提供的具有多模态推理能力和通用推理能力的多模态思考模型，它擅长深度推理，帮助解决更多更难的事情", "vision": true, "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'moonshot'), 'moonshot-v1-auto', 'Moonshot V1 Auto', 'chat', 131072, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Moonshot V1 Auto 可以根据当前上下文占用的 Tokens 数量来选择合适的模型", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'moonshot'), 'moonshot-v1-8k', 'Moonshot V1 8K', 'chat', 8192, NULL, 0.002, 0.01, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Moonshot V1 8K 专为生成短文本任务设计，具有高效的处理性能，能够处理8,192个tokens，非常适合简短对话、速记和快速内容生成。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'moonshot'), 'moonshot-v1-32k', 'Moonshot V1 32K', 'chat', 32768, NULL, 0.005, 0.02, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Moonshot V1 32K 提供中等长度的上下文处理能力，能够处理32,768个tokens，特别适合生成各种长文档和复杂对话，应用于内容创作、报告生成和对话系统等领域。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'moonshot'), 'moonshot-v1-128k', 'Moonshot V1 128K', 'chat', 131072, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Moonshot V1 128K 是一款拥有超长上下文处理能力的模型，适用于生成超长文本，满足复杂的生成任务需求，能够处理多达128,000个tokens的内容，非常适合科研、学术和大型文档生成等应用场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'moonshot'), 'moonshot-v1-8k-vision-preview', 'Moonshot V1 8K Vision Preview', 'chat', 8192, NULL, 0.002, 0.01, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-14", "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Kimi 视觉模型（包括 moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview 等）能够理解图片内容，包括图片文字、图片颜色和物体形状等内容。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'moonshot'), 'moonshot-v1-32k-vision-preview', 'Moonshot V1 32K Vision Preview', 'chat', 32768, NULL, 0.005, 0.02, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-14", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Kimi 视觉模型（包括 moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview 等）能够理解图片内容，包括图片文字、图片颜色和物体形状等内容。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'moonshot'), 'moonshot-v1-128k-vision-preview', 'Moonshot V1 128K Vision Preview', 'chat', 131072, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-14", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Kimi 视觉模型（包括 moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview 等）能够理解图片内容，包括图片文字、图片颜色和物体形状等内容。", "vision": true, "function_calling": true}', FALSE),
    -- nebius
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'moonshotai/Kimi-K2-Instruct', 'Kimi-K2-Instruct', 'chat', 131072, NULL, 0.0005, 0.0024, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "moonshotai", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'Qwen/Qwen3-Coder-480B-A35B-Instruct', 'Qwen/Qwen3-Coder-480B-A35B-Instruct', 'chat', 262144, NULL, 0.0004, 0.0018, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'openai/gpt-oss-120b', 'gpt-oss-120b', 'chat', 131072, NULL, 0.00015, 0.0006, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "openai", "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'openai/gpt-oss-20b', 'gpt-oss-20b', 'chat', 131072, NULL, 0.00005, 0.0002, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "openai", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'zai-org/GLM-4.5', 'GLM-4.5', 'chat', 131072, NULL, 0.0006, 0.0022, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "zai-org", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'zai-org/GLM-4.5-Air', 'GLM-4.5-Air', 'chat', 131072, NULL, 0.0002, 0.0012, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "zai-org", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'deepseek-ai/DeepSeek-R1-0528', 'DeepSeek-R1-0528', 'chat', 163840, NULL, 0.0008, 0.0024, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "organization": "deepseek", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'deepseek-ai/DeepSeek-R1-0528-fast', 'DeepSeek-R1-0528 (fast)', 'chat', 32768, NULL, 0.002, 0.006, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "organization": "deepseek", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'Qwen/Qwen3-235B-A22B-Instruct-2507', 'Qwen3-235B-A22B-Instruct-2507', 'chat', 262144, NULL, 0.0002, 0.0006, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'Qwen/Qwen3-30B-A3B', 'Qwen3-30B-A3B', 'chat', 40960, NULL, 0.0001, 0.0003, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'Qwen/Qwen3-32B', 'Qwen3-32B', 'chat', 40960, NULL, 0.0001, 0.0003, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'Qwen/Qwen3-32B-fast', 'Qwen3-32B (fast)', 'chat', 40960, NULL, 0.0002, 0.0006, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'Qwen/Qwen3-14B', 'Qwen3-14B', 'chat', 40960, NULL, 0.00008, 0.00024, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.08, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.24, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'nvidia/Llama-3_1-Nemotron-Ultra-253B-v1', 'Llama-3_1-Nemotron-Ultra-253B-v1', 'chat', 131072, NULL, 0.0006, 0.0018, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "nvidia", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'deepseek-ai/DeepSeek-V3-0324', 'DeepSeek-V3-0324', 'chat', 163840, NULL, 0.0005, 0.0015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "organization": "deepseek", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'deepseek-ai/DeepSeek-V3-0324-fast', 'DeepSeek-V3-0324 (fast)', 'chat', 32768, NULL, 0.00075, 0.00225, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.25, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "organization": "deepseek", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'deepseek-ai/DeepSeek-V3', 'DeepSeek-V3', 'chat', 163840, NULL, 0.0005, 0.0015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "organization": "deepseek", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'meta-llama/Llama-3.3-70B-Instruct', 'Llama-3.3-70B-Instruct', 'chat', 131072, NULL, 0.00013, 0.0004, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.13, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "meta", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'meta-llama/Llama-3.3-70B-Instruct-fast', 'Llama-3.3-70B-Instruct (fast)', 'chat', 131072, NULL, 0.00025, 0.00075, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.75, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "meta", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'Meta-Llama-3.1-8B-Instruct', 'chat', 131072, NULL, 0.00002, 0.00006, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.02, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.06, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "meta", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'meta-llama/Meta-Llama-3.1-8B-Instruct-fast', 'Meta-Llama-3.1-8B-Instruct (fast)', 'chat', 131072, NULL, 0.00003, 0.00009, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.03, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.09, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "meta", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'meta-llama/Meta-Llama-3.1-405B-Instruct', 'Meta-Llama-3.1-405B-Instruct', 'chat', 131072, NULL, 0.001, 0.003, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "meta", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'Qwen/Qwen2.5-Coder-7B-fast', 'Qwen2.5-Coder-7B (fast)', 'chat', 32768, NULL, 0.00003, 0.00009, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.03, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.09, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'google/gemma-2-2b-it', 'Gemma-2-2b-it', 'chat', 8192, NULL, 0.00002, 0.00006, '{"pricing": {"units": [{"name": "textInput", "rate": 0.02, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.06, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "organization": "google"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'google/gemma-2-9b-it-fast', 'Gemma-2-9b-it (fast)', 'chat', 8192, NULL, 0.00003, 0.00009, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.03, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.09, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "organization": "google", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'Qwen/Qwen2.5-72B-Instruct', 'Qwen2.5-72B-Instruct', 'chat', 131072, NULL, 0.00013, 0.0004, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.13, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'Qwen/QwQ-32B', 'QwQ-32B', 'chat', 131072, NULL, 0.00015, 0.00045, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.45, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'Qwen/QwQ-32B-fast', 'QwQ-32B (fast)', 'chat', 131072, NULL, 0.0005, 0.0015, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'NousResearch/Hermes-3-Llama-405B', 'Hermes-3-Llama-3.1-405B', 'chat', 131072, NULL, 0.001, 0.003, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "NousResearch", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'NousResearch/Hermes-4-70B', 'Hermes-4-70B', 'chat', 131072, NULL, 0.00013, 0.0004, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.13, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "NousResearch", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'NousResearch/Hermes-4-405B', 'Hermes-4-405B', 'chat', 131072, NULL, 0.001, 0.003, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "NousResearch", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'mistralai/Devstral-Small-2505', 'Devstral-Small-2505', 'chat', 128000, NULL, 0.00008, 0.00024, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.08, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.24, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "organization": "mistralai", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'Qwen/Qwen3-30B-A3B-Thinking-2507', 'Qwen3-30B-A3B-Thinking-2507', 'chat', 262144, NULL, 0.0001, 0.0003, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'Qwen/Qwen3-30B-A3B-Instruct-2507', 'Qwen3-30B-A3B-Instruct-2507', 'chat', 262144, NULL, 0.0001, 0.0003, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'Qwen/Qwen3-Coder-30B-A3B-Instruct', 'Qwen3-Coder-30B-A3B-Instruct', 'chat', 262144, NULL, 0.0001, 0.0003, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'meta-llama/Llama-Guard-3-8B', 'Meta-Llama-Guard-3-8B', 'chat', 131072, NULL, 0.00002, 0.00006, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.02, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.06, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "organization": "meta", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'google/gemma-3-27b-it', 'Gemma-3-27b-it', 'chat', 110000, NULL, 0.0001, 0.0003, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 110000, "contextWindowTokens": 110000, "organization": "google", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'google/gemma-3-27b-it-fast', 'Gemma-3-27b-it (fast)', 'chat', 110000, NULL, 0.0002, 0.0006, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 110000, "contextWindowTokens": 110000, "organization": "google", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nebius'), 'Qwen/Qwen2.5-VL-72B-Instruct', 'Qwen2.5-VL-72B-Instruct', 'chat', 32000, NULL, 0.00025, 0.00075, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.75, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "organization": "Qwen", "vision": true, "function_calling": true}', FALSE),
    -- novita
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen3-vl-235b-a22b-instruct', 'Qwen3 VL 235B A22B Instruct', 'chat', 131072, 32768, 0.0003, 0.003, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen3-vl-235b-a22b-thinking', 'Qwen3 VL 235B A22B Thinking', 'chat', 131072, 32768, 0.00098, 0.00395, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.98, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3.95, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen3-next-80b-a3b-thinking', 'Qwen3 Next 80B A3B Thinking', 'chat', 131072, 32768, 0.00015, 0.0015, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen3-next-80b-a3b-instruct', 'Qwen3 Next 80B A3B Instruct', 'chat', 131072, 32768, 0.00015, 0.0015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen-mt-plus', 'Qwen MT Plus', 'chat', 4096, 2048, 0.00025, 0.00075, '{"pricing": {"units": [{"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.75, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "maxOutputTokens": 2048, "maxOutput": 2048}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'moonshotai/kimi-k2-0905', 'Kimi K2 0905', 'chat', 262144, NULL, 0.0006, 0.0025, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-05", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "kimi-k2-0905-preview 模型上下文长度为 256k，具备更强的 Agentic Coding 能力、更突出的前端代码的美观度和实用性、以及更好的上下文理解能力。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'deepseek/deepseek-v3.2-exp', 'Deepseek V3.2 Exp', 'chat', 163840, NULL, 0.00027, 0.00041, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.27, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.41, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'deepseek/deepseek-v3.1-terminus', 'DeepSeek V3.1 Terminus', 'chat', 131072, 65536, 0.00027, 0.001, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.27, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 65536, "maxOutput": 65536, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'deepseek/deepseek-v3.1', 'DeepSeek V3.1', 'chat', 131072, 32768, 0.00027, 0.001, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.27, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen3-coder-480b-a35b-instruct', 'Qwen3 Coder 480B A35B Instruct', 'chat', 65536, NULL, 0.00029, 0.0012, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.29, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'openai/gpt-oss-120b', 'OpenAI GPT OSS 120B', 'chat', 131072, NULL, 0.0001, 0.0005, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'openai/gpt-oss-20b', 'OpenAI: GPT OSS 20B', 'chat', 131072, NULL, 0.00004, 0.00015, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.04, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'zai-org/glm-4.5v', 'GLM-4.5V', 'chat', 65536, 16384, 0.0006, 0.0018, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "maxOutputTokens": 16384, "maxOutput": 16384, "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'zai-org/glm-4.5', 'GLM-4.5', 'chat', 131072, 98304, 0.0006, 0.0022, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 98304, "maxOutput": 98304, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen3-235b-a22b-instruct-2507', 'Qwen3 235B A22B Instruct 2507', 'chat', 131072, 16384, 0.00015, 0.0008, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16384, "maxOutput": 16384, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen3-235b-a22b-thinking-2507', 'Qwen3 235B A22b Thinking 2507', 'chat', 131072, 32768, 0.0003, 0.003, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'baichuan/baichuan-m2-32b', 'BaiChuan M2 32B', 'chat', 131072, NULL, 0.00007, 0.00007, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.07, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.07, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'moonshotai/kimi-k2-instruct', 'Kimi K2 0711', 'chat', 131072, NULL, 0.00057, 0.0023, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.57, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'thudm/glm-4.1v-9b-thinking', 'GLM 4.1V 9B Thinking', 'chat', 65536, NULL, 0.000035, 0.000138, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.035, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.138, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'baidu/ernie-4.5-21B-a3b', 'ERNIE 4.5 21B A3B', 'chat', 120000, NULL, 0.00007, 0.00028, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.07, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.28, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 120000, "contextWindowTokens": 120000, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'baidu/ernie-4.5-21B-a3b-thingking', 'ERNIE 4.5 21B A3B Thinking', 'chat', 131072, 65536, 0.00007, 0.00028, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.07, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.28, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 65536, "maxOutput": 65536, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'baidu/ernie-4.5-300b-a47b-paddle', 'ERNIE 4.5 300B A47B Paddle', 'chat', 123000, NULL, 0.00028, 0.0011, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.28, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 123000, "contextWindowTokens": 123000, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'baidu/ernie-4.5-vl-28b-a3b', 'ERNIE 4.5 VL 28B A3B', 'chat', 30000, NULL, 0.00014, 0.00056, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.14, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.56, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 30000, "contextWindowTokens": 30000, "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'baidu/ernie-4.5-vl-424b-a47b', 'ERNIE 4.5 VL 424B A47B', 'chat', 123000, NULL, 0.00042, 0.00125, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.42, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 123000, "contextWindowTokens": 123000, "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'minimaxai/minimax-m1-80k', 'MiniMax M1 80K', 'chat', 1000000, NULL, 0.00055, 0.0022, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen3-4b-fp8', 'Qwen3 4B FP8', 'chat', 128000, NULL, 0.00003, 0.00003, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.03, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.03, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen3-235b-a22b-fp8', 'Qwen3 235B A22B FP8', 'chat', 40960, NULL, 0.0002, 0.0008, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen3-30b-a3b-fp8', 'Qwen3 30B A3B FP8', 'chat', 32768, NULL, 0.00009, 0.00045, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.09, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.45, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen3-32b-fp8', 'Qwen3 32B FP8', 'chat', 40960, NULL, 0.0001, 0.00045, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.45, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'meta-llama/llama-3.3-70b-instruct', 'Llama 3.3 70B Instruct', 'chat', 131072, NULL, 0.00013, 0.00039, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.13, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.39, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen3-8b-fp8', 'Qwen3 8B FP8', 'chat', 128000, NULL, 0.000035, 0.000138, '{"pricing": {"units": [{"name": "textInput", "rate": 0.035, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.138, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'meta-llama/llama-4-scout-17b-16e-instruct', 'Llama 4 Scout 17B Instruct', 'chat', 131072, NULL, 0.0001, 0.0005, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'meta-llama/llama-4-maverick-17b-128e-instruct-fp8', 'Llama 4 Maverick 17B Instruct', 'chat', 1048576, 8192, 0.00017, 0.00085, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.17, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.85, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1048576, "contextWindowTokens": 1048576, "maxOutputTokens": 8192, "maxOutput": 8192, "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'meta-llama/llama-3.1-8b-instruct', 'Llama 3.1 8B Instruct', 'chat', 16384, NULL, 0.00002, 0.00005, '{"pricing": {"units": [{"name": "textInput", "rate": 0.02, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "Llama 3.1 8B Instruct  优化了高质量对话场景，表现优于许多领先的闭源模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'meta-llama/llama-3-8b-instruct', 'Llama 3 8B Instruct', 'chat', 8192, NULL, 0.00004, 0.00004, '{"pricing": {"units": [{"name": "textInput", "rate": 0.04, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.04, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Llama 3 8B Instruct 优化了高质量对话场景，性能优于许多闭源模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'meta-llama/llama-3-70b-instruct', 'Llama 3 70B Instruct', 'chat', 8192, NULL, 0.00051, 0.00074, '{"pricing": {"units": [{"name": "textInput", "rate": 0.51, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.74, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Llama 3 70B Instruct 优化用于高质量对话场景，在各类人类评估中表现优异。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'google/gemma-3-27b-it', 'Gemma 3 27B', 'chat', 32768, NULL, 0.000119, 0.0002, '{"pricing": {"units": [{"name": "textInput", "rate": 0.119, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Gemma 3 27B 是谷歌的一款开源语言模型，以其在效率和性能方面设立了新的标准。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'google/gemma-3-12b-it', 'Gemma 3 12B', 'chat', 131072, 8192, 0.00005, 0.0001, '{"pricing": {"units": [{"name": "textInput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemma 3 12B 是谷歌的一款开源语言模型，以其在效率和性能方面设立了新的标准。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'mistralai/mistral-nemo', 'Mistral Nemo', 'chat', 60288, NULL, 0.00004, 0.00017, '{"pricing": {"units": [{"name": "textInput", "rate": 0.04, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.17, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 60288, "contextWindowTokens": 60288, "description": "Mistral Nemo 是多语言支持和高性能编程的7.3B参数模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'microsoft/wizardlm-2-8x22b', 'WizardLM-2 8x22B', 'chat', 65535, NULL, 0.00062, 0.00062, '{"pricing": {"units": [{"name": "textInput", "rate": 0.62, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.62, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65535, "contextWindowTokens": 65535, "description": "WizardLM-2 8x22B 是微软AI最先进的Wizard模型，显示出极其竞争力的表现。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'nousresearch/hermes-2-pro-llama-3-8b', 'Hermes 2 Pro Llama 3 8B', 'chat', 8192, NULL, 0.00014, 0.00014, '{"pricing": {"units": [{"name": "textInput", "rate": 0.14, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.14, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Hermes 2 Pro Llama 3 8B 是 Nous Hermes 2的升级版本，包含最新的内部开发的数据集。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'gryphe/mythomax-l2-13b', 'MythoMax l2 13B', 'chat', 4096, NULL, 0.00009, 0.00009, '{"pricing": {"units": [{"name": "textInput", "rate": 0.09, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.09, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "MythoMax l2 13B 是一款合并了多个顶尖模型的创意与智能相结合的语言模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'deepseek/deepseek-prover-v2-671b', 'Deepseek Prover V2 671B', 'chat', 160000, NULL, 0.0007, 0.0025, '{"pricing": {"units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 160000, "contextWindowTokens": 160000}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'deepseek/deepseek-v3-turbo', 'Deepseek V3 Turbo', 'chat', 64000, NULL, 0.0004, 0.0013, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'deepseek/deepseek-v3-0324', 'Deepseek V3 0324', 'chat', 163840, NULL, 0.00028, 0.00114, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.28, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.14, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'deepseek/deepseek-r1-0528', 'Deepseek R1 0528', 'chat', 163840, 32768, 0.0007, 0.0025, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "maxOutputTokens": 32768, "maxOutput": 32768, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'deepseek/deepseek-r1-0528-qwen3-8b', 'DeepSeek R1 0528 Qwen3 8B', 'chat', 128000, NULL, 0.00006, 0.00009, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.06, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.09, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'deepseek/deepseek-r1-turbo', 'Deepseek R1 Turbo', 'chat', 64000, NULL, 0.0007, 0.0025, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'deepseek/deepseek-r1-distill-llama-70b', 'Deepseek R1 Distill Llama 70B', 'chat', 32000, NULL, 0.0008, 0.0008, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'deepseek/deepseek-r1-distill-qwen-14b', 'Deepseek R1 Distill Qwen 14B', 'chat', 32768, 16384, 0.00015, 0.00015, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 16384, "maxOutput": 16384, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'deepseek/deepseek-r1-distill-qwen-32b', 'Deepseek R1 Distill Qwen 32B', 'chat', 64000, NULL, 0.0003, 0.0003, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'Sao10K/L3-8B-Stheno-v3.2', 'L3 8B Stheno v3.2', 'chat', 8192, NULL, 0.00005, 0.00005, '{"pricing": {"units": [{"name": "textInput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen-2.5-72b-instruct', 'Qwen2.5 72B Instruct', 'chat', 32000, 8192, 0.00038, 0.0004, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.38, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 8192, "maxOutput": 8192, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'sao10k/l3-70b-euryale-v2.1', 'L3 70B Euryale v2.1', 'chat', 8192, NULL, 0.00148, 0.00148, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.48, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.48, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'sophosympatheia/midnight-rose-70b', 'Midnight Rose 70B', 'chat', 4096, NULL, 0.0008, 0.0008, '{"pricing": {"units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'sao10k/l3-8b-lunaris', 'L3 8B Lunaris', 'chat', 8192, NULL, 0.00005, 0.00005, '{"pricing": {"units": [{"name": "textInput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen2.5-vl-72b-instruct', 'Qwen2.5 VL 72B Instruct', 'chat', 32768, NULL, 0.0008, 0.0008, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'meta-llama/llama-3.2-3b-instruct', 'Llama 3.2 3B Instruct', 'chat', 32768, NULL, 0.00003, 0.00005, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.03, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'meta-llama/llama-3.1-8b-instruct-bf16', 'Llama 3.1 8B Instruct BF16', 'chat', 8192, NULL, 0.00006, 0.00006, '{"pricing": {"units": [{"name": "textInput", "rate": 0.06, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.06, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'sao10k/l31-70b-euryale-v2.2', 'L31 70B Euryale v2.2', 'chat', 8192, NULL, 0.00148, 0.00148, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.48, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.48, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'novita'), 'qwen/qwen2.5-7b-instruct', 'Qwen2.5 7B Instruct', 'chat', 32000, NULL, 0.00007, 0.00007, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.07, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.07, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "function_calling": true}', FALSE),
    -- nvidia
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'deepseek-ai/deepseek-v3.1-terminus', 'DeepSeek V3.1 Terminus', 'chat', 131072, 16384, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning"]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "DeepSeek V3.1：下一代推理模型，提升了复杂推理与链路思考能力，适合需要深入分析的任务。", "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'deepseek-ai/deepseek-v3.1', 'DeepSeek V3.1', 'chat', 131072, 16384, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning"]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "DeepSeek V3.1：下一代推理模型，提升了复杂推理与链路思考能力，适合需要深入分析的任务。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'meta/llama-3.3-70b-instruct', 'Llama 3.3 70B Instruct', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "先进的 LLM，擅长推理、数学、常识和函数调用。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'meta/llama-3.2-1b-instruct', 'Llama 3.2 1B Instruct', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "先进的最尖端小型语言模型，具备语言理解、卓越的推理能力和文本生成能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'meta/llama-3.2-3b-instruct', 'Llama 3.2 3B Instruct', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "先进的最尖端小型语言模型，具备语言理解、卓越的推理能力和文本生成能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'meta/llama-3.2-11b-vision-instruct', 'Llama 3.2 11B Vision Instruct', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "尖端的视觉-语言模型，擅长从图像中进行高质量推理。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'meta/llama-3.2-90b-vision-instruct', 'Llama 3.2 90B Vision Instruct', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "尖端的视觉-语言模型，擅长从图像中进行高质量推理。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'meta/llama-3.1-8b-instruct', 'Llama 3.1 8B Instruct', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "先进的最尖端模型，具备语言理解、卓越的推理能力和文本生成能力。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'meta/llama-3.1-70b-instruct', 'Llama 3.1 70B Instruct', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "赋能复杂对话，具备卓越的上下文理解、推理能力和文本生成能力。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'meta/llama-3.1-405b-instruct', 'Llama 3.1 405B Instruct', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "高级 LLM，支持合成数据生成、知识蒸馏和推理，适用于聊天机器人、编程和特定领域任务。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'nvidia/llama-3.1-nemotron-51b-instruct', 'Llama 3.1 Nemotron 51B Instruct', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "独特的语言模型，提供无与伦比的准确性和效率表现。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'nvidia/llama-3.1-nemotron-70b-instruct', 'Llama 3.1 Nemotron 70B Instruct', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Llama-3.1-Nemotron-70B-Instruct 是 NVIDIA 定制的大型语言模型，旨在提高 LLM 生成的响应的帮助性。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'google/gemma-2-2b-it', 'Gemma 2 2B Instruct', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "面向边缘应用的高级小型语言生成 AI 模型。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'google/gemma-2-9b-it', 'Gemma 2 9B Instruct', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "尖端文本生成模型，擅长文本理解、转换和代码生成。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'google/gemma-2-27b-it', 'Gemma 2 27B Instruct', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "尖端文本生成模型，擅长文本理解、转换和代码生成。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'deepseek-ai/deepseek-r1', 'DeepSeek R1', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "最先进的高效 LLM，擅长推理、数学和编程。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'qwen/qwen2.5-7b-instruct', 'Qwen2.5 7B Instruct', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "面向中文和英文的 LLM，针对语言、编程、数学、推理等领域。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'qwen/qwen2.5-coder-7b-instruct', 'Qwen2.5 Coder 7B Instruct', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "强大的中型代码模型，支持 32K 上下文长度，擅长多语言编程。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'nvidia'), 'qwen/qwen2.5-coder-32b-instruct', 'Qwen2.5 Coder 32B Instruct', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "高级 LLM，支持代码生成、推理和修复，涵盖主流编程语言。"}', FALSE),
    -- ollama
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'deepseek-v3.1:671b', 'DeepSeek V3.1', 'chat', 163840, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek V3.1：下一代推理模型，提升了复杂推理与链路思考能力，适合需要深入分析的任务。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'gpt-oss:20b', 'GPT-OSS 20B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "released_at": "2025-08-05", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "GPT-OSS 20B 是 OpenAI 发布的开源大语言模型，采用 MXFP4 量化技术，适合在高端消费级GPU或Apple Silicon Mac上运行。该模型在对话生成、代码编写和推理任务方面表现出色，支持函数调用和工具使用。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'gpt-oss:120b', 'GPT-OSS 120B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "released_at": "2025-08-05", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "GPT-OSS 120B 是 OpenAI 发布的大型开源语言模型，采用 MXFP4 量化技术，为旗舰级模型。需要多GPU或高性能工作站环境运行，在复杂推理、代码生成和多语言处理方面具备卓越性能，支持高级函数调用和工具集成。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'qwen3-coder:480b', 'Qwen3 Coder 480B', 'chat', 262144, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "阿里巴巴针对代理和编码任务的高性能长上下文模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'deepseek-r1', 'DeepSeek R1', 'chat', 65536, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "DeepSeek-R1 是一款强化学习（RL）驱动的推理模型，解决了模型中的重复性和可读性问题。在 RL 之前，DeepSeek-R1 引入了冷启动数据，进一步优化了推理性能。它在数学、代码和推理任务中与 OpenAI-o1 表现相当，并且通过精心设计的训练方法，提升了整体效果。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'deepseek-v3', 'DeepSeek V3 671B', 'chat', 65536, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "DeepSeek-V3 是一个强大的专家混合（MoE）语言模型，总参数量为 671B，每个 Token 激活 37B 参数。该模型采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，实现了高效推理和经济训练，并在前代 DeepSeek-V3 的基础上显著提升了性能。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'llama3.1', 'Llama 3.1 8B', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Llama 3.1 是 Meta 推出的领先模型，支持高达 405B 参数，可应用于复杂对话、多语言翻译和数据分析领域。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'llama3.1:70b', 'Llama 3.1 70B', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Llama 3.1 是 Meta 推出的领先模型，支持高达 405B 参数，可应用于复杂对话、多语言翻译和数据分析领域。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'llama3.1:405b', 'Llama 3.1 405B', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Llama 3.1 是 Meta 推出的领先模型，支持高达 405B 参数，可应用于复杂对话、多语言翻译和数据分析领域。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'codellama', 'Code Llama 7B', 'chat', 16384, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "Code Llama 是一款专注于代码生成和讨论的 LLM，结合广泛的编程语言支持，适用于开发者环境。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'codellama:13b', 'Code Llama 13B', 'chat', 16384, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "Code Llama 是一款专注于代码生成和讨论的 LLM，结合广泛的编程语言支持，适用于开发者环境。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'codellama:34b', 'Code Llama 34B', 'chat', 16384, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "Code Llama 是一款专注于代码生成和讨论的 LLM，结合广泛的编程语言支持，适用于开发者环境。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'codellama:70b', 'Code Llama 70B', 'chat', 16384, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "Code Llama 是一款专注于代码生成和讨论的 LLM，结合广泛的编程语言支持，适用于开发者环境。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'qwq', 'QwQ 32B', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "released_at": "2024-11-28", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "QwQ 是 Qwen 系列的推理模型。与传统的指令调优模型相比，QwQ 具备思考和推理的能力，能够在下游任务中，尤其是困难问题上，显著提升性能。QwQ-32B 是中型推理模型，能够在与最先进的推理模型（如 DeepSeek-R1、o1-mini）竞争时取得可观的表现。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'qwen3', 'Qwen3 7B', 'chat', 65536, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "Qwen3 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'qwen2.5:0.5b', 'Qwen2.5 0.5B', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Qwen2.5 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'qwen2.5:1.5b', 'Qwen2.5 1.5B', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Qwen2.5 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'qwen2.5', 'Qwen2.5 7B', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Qwen2.5 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'qwen2.5:72b', 'Qwen2.5 72B', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Qwen2.5 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'codeqwen', 'CodeQwen1.5 7B', 'chat', 65536, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "CodeQwen1.5 是基于大量代码数据训练的大型语言模型，专为解决复杂编程任务。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'qwen2:0.5b', 'Qwen2 0.5B', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Qwen2 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'qwen2:1.5b', 'Qwen2 1.5B', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Qwen2 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'qwen2', 'Qwen2 7B', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Qwen2 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'qwen2:72b', 'Qwen2 72B', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Qwen2 是阿里巴巴的新一代大规模语言模型，以优异的性能支持多元化的应用需求。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'gemma2:2b', 'Gemma 2 2B', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Gemma 2 是 Google 推出的高效模型，涵盖从小型应用到复杂数据处理的多种应用场景。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'gemma2', 'Gemma 2 9B', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Gemma 2 是 Google 推出的高效模型，涵盖从小型应用到复杂数据处理的多种应用场景。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'gemma2:27b', 'Gemma 2 27B', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Gemma 2 是 Google 推出的高效模型，涵盖从小型应用到复杂数据处理的多种应用场景。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'codegemma:2b', 'CodeGemma 2B', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "CodeGemma 专用于不同编程任务的轻量级语言模型，支持快速迭代和集成。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'codegemma', 'CodeGemma 7B', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "CodeGemma 专用于不同编程任务的轻量级语言模型，支持快速迭代和集成。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'phi3', 'Phi-3 3.8B', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Phi-3 是微软推出的轻量级开放模型，适用于高效集成和大规模知识推理。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'phi3:14b', 'Phi-3 14B', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Phi-3 是微软推出的轻量级开放模型，适用于高效集成和大规模知识推理。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'wizardlm2', 'WizardLM 2 7B', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "WizardLM 2 是微软AI提供的语言模型，在复杂对话、多语言、推理和智能助手领域表现尤为出色。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'wizardlm2:8x22b', 'WizardLM 2 8x22B', 'chat', 65536, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "WizardLM 2 是微软AI提供的语言模型，在复杂对话、多语言、推理和智能助手领域表现尤为出色。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'mathstral', 'MathΣtral 7B', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "MathΣtral 专为科学研究和数学推理设计，提供有效的计算能力和结果解释。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'mistral', 'Mistral 7B', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Mistral 是 Mistral AI 发布的 7B 模型，适合多变的语言处理需求。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'mixtral', 'Mixtral 8x7B', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Mixtral 是 Mistral AI 的专家模型，具有开源权重，并在代码生成和语言理解方面提供支持。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'mixtral:8x22b', 'Mixtral 8x22B', 'chat', 65536, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "Mixtral 是 Mistral AI 的专家模型，具有开源权重，并在代码生成和语言理解方面提供支持。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'mistral-large', 'Mixtral Large 123B', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Mixtral Large 是 Mistral 的旗舰模型，结合代码生成、数学和推理的能力，支持 128k 上下文窗口。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'mistral-nemo', 'Mixtral Nemo 12B', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Mistral Nemo 由 Mistral AI 和 NVIDIA 合作推出，是高效性能的 12B 模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'codestral', 'Codestral 22B', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Codestral 是 Mistral AI 的首款代码模型，为代码生成任务提供优异支持。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'aya', 'Aya 23 8B', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Aya 23 是 Cohere 推出的多语言模型，支持 23 种语言，为多元化语言应用提供便利。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'aya:35b', 'Aya 23 35B', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Aya 23 是 Cohere 推出的多语言模型，支持 23 种语言，为多元化语言应用提供便利。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'command-r', 'Command R 35B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Command R 是优化用于对话和长上下文任务的LLM，特别适合动态交互与知识管理。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'command-r-plus', 'Command R+ 104B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Command R+ 是一款高性能的大型语言模型，专为真实企业场景和复杂应用而设计。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'deepseek-v2', 'DeepSeek V2 16B', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "DeepSeek V2 是高效的 Mixture-of-Experts 语言模型，适用于经济高效的处理需求。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'deepseek-v2:236b', 'DeepSeek V2 236B', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "DeepSeek V2 236B 是 DeepSeek 的设计代码模型，提供强大的代码生成能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'deepseek-coder-v2', 'DeepSeek Coder V2 16B', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "DeepSeek Coder V2 是开源的混合专家代码模型，在代码任务方面表现优异，与 GPT4-Turbo 相媲美。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'deepseek-coder-v2:236b', 'DeepSeek Coder V2 236B', 'chat', 128000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "DeepSeek Coder V2 是开源的混合专家代码模型，在代码任务方面表现优异，与 GPT4-Turbo 相媲美。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'llava', 'LLaVA 7B', 'chat', 4096, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "LLaVA 是结合视觉编码器和 Vicuna 的多模态模型，用于强大的视觉和语言理解。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'llava:13b', 'LLaVA 13B', 'chat', 4096, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "LLaVA 是结合视觉编码器和 Vicuna 的多模态模型，用于强大的视觉和语言理解。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'llava:34b', 'LLaVA 34B', 'chat', 4096, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "LLaVA 是结合视觉编码器和 Vicuna 的多模态模型，用于强大的视觉和语言理解。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollama'), 'minicpm-v', 'MiniCPM-V 8B', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "MiniCPM-V 是 OpenBMB 推出的新一代多模态大模型，具备卓越的 OCR 识别和多模态理解能力，支持广泛的应用场景。", "vision": true}', FALSE),
    -- ollamacloud
    ((SELECT id FROM ai_providers WHERE code = 'ollamacloud'), 'glm-4.6', 'GLM-4.6', 'chat', 200000, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "智谱最新旗舰模型 GLM-4.6 (355B) 在高级编码、长文本处理、推理与智能体能力上全面超越前代，尤其在编程能力上对齐 Claude Sonnet 4，成为国内顶尖的 Coding 模型。", "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ollamacloud'), 'deepseek-v3.1:671b', 'DeepSeek V3.1', 'chat', 163840, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek V3.1：下一代推理模型，提升了复杂推理与链路思考能力，适合需要深入分析的任务。", "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ollamacloud'), 'gpt-oss:20b', 'GPT-OSS 20B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "released_at": "2025-08-05", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "GPT-OSS 20B 是 OpenAI 发布的开源大语言模型，采用 MXFP4 量化技术，适合在高端消费级GPU或Apple Silicon Mac上运行。该模型在对话生成、代码编写和推理任务方面表现出色，支持函数调用和工具使用。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollamacloud'), 'gpt-oss:120b', 'GPT-OSS 120B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "released_at": "2025-08-05", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "GPT-OSS 120B 是 OpenAI 发布的大型开源语言模型，采用 MXFP4 量化技术，为旗舰级模型。需要多GPU或高性能工作站环境运行，在复杂推理、代码生成和多语言处理方面具备卓越性能，支持高级函数调用和工具集成。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollamacloud'), 'kimi-k2:1t', 'Kimi K2', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Kimi K2 是由月之暗面 AI 开发的大规模混合专家 (MoE) 语言模型，具有 1 万亿总参数和每次前向传递 320 亿激活参数。它针对代理能力进行了优化，包括高级工具使用、推理和代码合成。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollamacloud'), 'qwen3-coder:480b', 'Qwen3 Coder 480B', 'chat', 262144, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "阿里巴巴针对代理和编码任务的高性能长上下文模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'ollamacloud'), 'qwen3-vl:235b', 'Qwen3 VL 235B', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    -- openai
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-5-pro', 'GPT-5 pro', 'chat', 400000, 272000, 0.015, 0.12, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["textVerbosity"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 120, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-10-06", "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 272000, "maxOutput": 272000, "description": "GPT-5 pro 使用更多计算来更深入地思考，并持续提供更好的答案。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-5-codex', 'GPT-5 Codex', 'chat', 400000, 128000, 0.00125, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["gpt5ReasoningEffort", "textVerbosity"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.125, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-15", "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 128000, "maxOutput": 128000, "description": "GPT-5 Codex 是一个针对 Codex 或类似环境中的代理编码任务优化的 GPT-5 版本。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-5', 'GPT-5', 'chat', 400000, 128000, 0.00125, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "structuredOutput": true, "vision": true}, "settings": {"extendParams": ["gpt5ReasoningEffort", "textVerbosity"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.125, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-07", "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 128000, "maxOutput": 128000, "description": "跨领域编码和代理任务的最佳模型。GPT-5 在准确性、速度、推理、上下文识别、结构化思维和问题解决方面实现了飞跃。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-5-mini', 'GPT-5 mini', 'chat', 400000, 128000, 0.00025, 0.002, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "structuredOutput": true, "vision": true}, "settings": {"extendParams": ["gpt5ReasoningEffort", "textVerbosity"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-07", "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 128000, "maxOutput": 128000, "description": "更快、更经济高效的 GPT-5 版本，适用于明确定义的任务。在保持高质量输出的同时，提供更快的响应速度。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-5-nano', 'GPT-5 nano', 'chat', 400000, 128000, 0.00005, 0.0004, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["gpt5ReasoningEffort", "textVerbosity"]}, "pricing": {"units": [{"name": "textInput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.005, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-07", "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 128000, "maxOutput": 128000, "description": "最快、最经济高效的 GPT-5 版本。非常适合需要快速响应且成本敏感的应用场景。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-5-chat-latest', 'GPT-5 Chat', 'chat', 400000, 128000, 0.00125, 0.01, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.125, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-07", "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "maxOutputTokens": 128000, "maxOutput": 128000, "description": "ChatGPT 中使用的 GPT-5 模型。结合了强大的语言理解与生成能力，适合对话式交互应用。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'o4-mini', 'o4-mini', 'chat', 200000, 100000, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.275, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o4-mini 是我们最新的小型 o 系列模型。 它专为快速有效的推理而优化，在编码和视觉任务中表现出极高的效率和性能。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'o4-mini-deep-research', 'o4-mini Deep Research', 'chat', 200000, 100000, 0.002, 0.008, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-26", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o4-mini-deep-research 是我们更快速、更实惠的深度研究模型——非常适合处理复杂的多步骤研究任务。它可以从互联网上搜索和综合信息，也可以通过 MCP 连接器访问并利用你的自有数据。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'o3-pro', 'o3-pro', 'chat', 200000, 100000, 0.02, 0.08, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 80, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-10", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3-pro 模型使用更多的计算来更深入地思考并始终提供更好的答案，仅支持 Responses API 下使用。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'o3', 'o3', 'chat', 200000, 100000, 0.002, 0.008, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-16", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3 是一款全能强大的模型，在多个领域表现出色。它为数学、科学、编程和视觉推理任务树立了新标杆。它也擅长技术写作和指令遵循。用户可利用它分析文本、代码和图像，解决多步骤的复杂问题。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'o3-deep-research', 'o3 Deep Research', 'chat', 200000, 100000, 0.01, 0.04, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 40, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-26", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3-deep-research 是我们最先进的深度研究模型，专为处理复杂的多步骤研究任务而设计。它可以从互联网上搜索和综合信息，也可以通过 MCP 连接器访问并利用你的自有数据。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'o3-mini', 'o3-mini', 'chat', 200000, 100000, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["reasoningEffort"]}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-31", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3-mini 是我们最新的小型推理模型，在与 o1-mini 相同的成本和延迟目标下提供高智能。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'o1-pro', 'o1-pro', 'chat', 200000, 100000, 0.15, 0.6, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"]}, "pricing": {"units": [{"name": "textInput", "rate": 150, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 600, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-19", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o1 系列模型经过强化学习训练，能够在回答前进行思考，并执行复杂的推理任务。o1-pro 模型使用了更多计算资源，以进行更深入的思考，从而持续提供更优质的回答。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'o1-mini', 'o1-mini', 'chat', 128000, 65536, 0.0011, 0.0044, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["reasoningEffort"]}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-12", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "o1-mini是一款针对编程、数学和科学应用场景而设计的快速、经济高效的推理模型。该模型具有128K上下文和2023年10月的知识截止日期。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'o1', 'o1', 'chat', 200000, 100000, 0.015, 0.06, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"]}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 7.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-12-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o1是OpenAI新的推理模型，支持图文输入并输出文本，适用于需要广泛通用知识的复杂任务。该模型具有200K上下文和2023年10月的知识截止日期。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4.1', 'GPT-4.1', 'chat', 1047576, 32768, 0.002, 0.008, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 是我们用于复杂任务的旗舰模型。它非常适合跨领域解决问题。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4.1-mini', 'GPT-4.1 mini', 'chat', 1047576, 32768, 0.0004, 0.0016, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 mini 提供了智能、速度和成本之间的平衡，使其成为许多用例中有吸引力的模型。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4.1-nano', 'GPT-4.1 nano', 'chat', 1047576, 32768, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 nano 是最快，最具成本效益的GPT-4.1模型。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o-mini', 'GPT-4o mini', 'chat', 128000, 16384, 0.00015, 0.0006, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-07-18", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "GPT-4o mini是OpenAI在GPT-4 Omni之后推出的最新模型，支持图文输入并输出文本。作为他们最先进的小型模型，它比其他近期的前沿模型便宜很多，并且比GPT-3.5 Turbo便宜超过60%。它保持了最先进的智能，同时具有显著的性价比。GPT-4o mini在MMLU测试中获得了 82% 的得分，目前在聊天偏好上排名高于 GPT-4。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o-mini-search-preview', 'GPT-4o mini Search Preview', 'chat', 128000, 16384, 0.00015, 0.0006, '{"abilities": {"search": true}, "settings": {"searchImpl": "internal"}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-11", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "GPT-4o mini 搜索预览版是一个专门训练用于理解和执行网页搜索查询的模型，使用的是 Chat Completions API。除了令牌费用之外，网页搜索查询还会按每次工具调用收取费用。", "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o', 'GPT-4o', 'chat', 128000, NULL, 0.0025, 0.01, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-05-13", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o-search-preview', 'GPT-4o Search Preview', 'chat', 128000, 16384, 0.0025, 0.01, '{"abilities": {"search": true}, "settings": {"searchImpl": "internal"}, "pricing": {"units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-11", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "GPT-4o 搜索预览版是一个专门训练用于理解和执行网页搜索查询的模型，使用的是 Chat Completions API。除了令牌费用之外，网页搜索查询还会按每次工具调用收取费用。", "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o-2024-11-20', 'GPT-4o 1120', 'chat', 128000, NULL, 0.0025, 0.01, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-11-20", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o-2024-05-13', 'GPT-4o 0513', 'chat', 128000, NULL, 0.005, 0.015, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-05-13", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-audio', 'GPT Audio', 'chat', 128000, 16384, 0.0025, 0.01, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioInput", "rate": 40, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioOutput", "rate": 80, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-28", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "GPT Audio 是面向音频输入输出的通用聊天模型，支持在 Chat Completions API 中使用音频 I/O。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o-audio-preview', 'GPT-4o Audio Preview', 'chat', 128000, 16384, 0.0025, 0.01, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-12-17", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "GPT-4o Audio Preview 模型，支持音频输入输出", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o-mini-audio-preview', 'GPT-4o mini Audio', 'chat', 128000, 16384, 0.00015, 0.0006, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-12-17", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "GPT-4o mini Audio 模型，支持音频输入输出", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'chatgpt-4o-latest', 'ChatGPT-4o', 'chat', 128000, NULL, 0.005, 0.015, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-08-14", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4-turbo', 'GPT-4 Turbo', 'chat', 128000, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4-turbo-2024-04-09', 'GPT-4 Turbo Vision 0409', 'chat', 128000, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-04-09", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4-turbo-preview', 'GPT-4 Turbo Preview', 'chat', 128000, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4-0125-preview', 'GPT-4 Turbo Preview 0125', 'chat', 128000, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-01-25", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4-1106-preview', 'GPT-4 Turbo Preview 1106', 'chat', 128000, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2023-11-06", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4', 'GPT-4', 'chat', 8192, NULL, 0.03, 0.06, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4-0613', 'GPT-4 0613', 'chat', 8192, NULL, 0.03, 0.06, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2023-06-13", "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "GPT-4 提供了一个更大的上下文窗口，能够处理更长的文本输入，适用于需要广泛信息整合和数据分析的场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-3.5-turbo', 'GPT-3.5 Turbo', 'chat', 16384, NULL, 0.0005, 0.0015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-3.5-turbo-0125', 'GPT-3.5 Turbo 0125', 'chat', 16384, NULL, 0.0005, 0.0015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-01-25", "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-3.5-turbo-1106', 'GPT-3.5 Turbo 1106', 'chat', 16384, NULL, 0.001, 0.002, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2023-11-06", "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，Currently points to gpt-3.5-turbo-0125", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-3.5-turbo-instruct', 'GPT-3.5 Turbo Instruct', 'chat', 4096, NULL, 0.0015, 0.002, '{"pricing": {"units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "GPT 3.5 Turbo，适用于各种文本生成和理解任务，对指令遵循的优化"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'codex-mini-latest', 'Codex mini', 'chat', 200000, 100000, 0.0015, 0.006, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"]}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.375, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-01", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "codex-mini-latest 是 o4-mini 的微调版本，专门用于 Codex CLI。对于直接通过 API 使用，我们推荐从 gpt-4.1 开始。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'computer-use-preview', 'Computer Use Preview', 'chat', 8192, 1024, 0.003, 0.012, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"]}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-11", "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 1024, "maxOutput": 1024, "description": "computer-use-preview 模型是专为“计算机使用工具”设计的专用模型，经过训练以理解并执行计算机相关任务。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'text-embedding-3-large', 'Text Embedding 3 Large', 'embedding', 8192, NULL, 0.00013, NULL, '{"pricing": {"currency": "USD", "units": [{"name": "textInput", "rate": 0.13, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-01-25", "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "最强大的向量化模型，适用于英文和非英文任务", "maxDimension": 3072}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'text-embedding-3-small', 'Text Embedding 3 Small', 'embedding', 8192, NULL, 0.00002, NULL, '{"pricing": {"currency": "USD", "units": [{"name": "textInput", "rate": 0.02, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-01-25", "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "高效且经济的新一代 Embedding 模型，适用于知识检索、RAG 应用等场景", "maxDimension": 1536}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'tts-1', 'TTS-1', 'tts', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionCharacters"}]}, "source": "builtin", "description": "最新的文本转语音模型，针对实时场景优化速度"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'tts-1-hd', 'TTS-1 HD', 'tts', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 30, "strategy": "fixed", "unit": "millionCharacters"}]}, "source": "builtin", "description": "最新的文本转语音模型，针对质量进行优化"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o-mini-tts', 'GPT-4o Mini TTS', 'tts', NULL, NULL, 0.0006, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "description": "GPT-4o mini TTS 是一个基于 GPT-4o mini 构建的文本转语音模型，这是一种快速且强大的语言模型。使用它可以将文本转换为自然听起来的语音文本。最大输入标记数为 2000。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'whisper-1', 'Whisper', 'stt', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "audioInput", "rate": 0.0001, "strategy": "fixed", "unit": "second"}]}, "source": "builtin", "description": "通用语音识别模型，支持多语言语音识别、语音翻译和语言识别。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o-transcribe', 'GPT-4o Transcribe', 'stt', 16000, 2000, 0.0025, 0.01, '{"pricing": {"units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioInput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "maxOutputTokens": 2000, "maxOutput": 2000, "description": "GPT-4o Transcribe 是一种使用 GPT-4o 转录音频的语音转文本模型。与原始 Whisper 模型相比，它提高了单词错误率，并提高了语言识别和准确性。使用它来获得更准确的转录。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o-mini-transcribe', 'GPT-4o Mini Transcribe', 'stt', 16000, 2000, 0.00125, 0.005, '{"pricing": {"units": [{"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "maxOutputTokens": 2000, "maxOutput": 2000, "description": "GPT-4o Mini Transcribe 是一种使用 GPT-4o 转录音频的语音转文本模型。与原始 Whisper 模型相比，它提高了单词错误率，并提高了语言识别和准确性。使用它来获得更准确的转录。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-image-1', 'GPT Image 1', 'image', NULL, NULL, 0.005, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageInput_cacheRead", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageOutput", "rate": 40, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"high_1024x1024": 0.167, "high_1024x1536": 0.25, "high_1536x1024": 0.25, "low_1024x1024": 0.011, "low_1024x1536": 0.016, "low_1536x1024": 0.016, "medium_1024x1024": 0.042, "medium_1024x1536": 0.063, "medium_1536x1024": 0.063}, "pricingParams": ["quality", "size"]}, "name": "imageGeneration", "strategy": "lookup", "unit": "image"}]}, "parameters": {"imageUrls": {"default": []}, "prompt": {"default": ""}, "size": {"default": "auto", "enum": ["auto", "1024x1024", "1536x1024", "1024x1536"]}}, "source": "builtin", "description": "ChatGPT 原生多模态图片生成模型", "resolutions": ["1024x1024", "1024x1536", "1536x1024"]}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-image-1-mini', 'GPT Image 1 Mini', 'image', NULL, NULL, 0.002, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageInput_cacheRead", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"low_1024x1024": 0.005, "low_1024x1536": 0.006, "low_1536x1024": 0.006, "medium_1024x1024": 0.011, "medium_1024x1536": 0.015, "medium_1536x1024": 0.015}, "pricingParams": ["quality", "size"]}, "name": "imageGeneration", "strategy": "lookup", "unit": "image"}]}, "parameters": {"imageUrls": {"default": []}, "prompt": {"default": ""}, "size": {"default": "auto", "enum": ["auto", "1024x1024", "1536x1024", "1024x1536"]}}, "released_at": "2025-10-06", "source": "builtin", "description": "成本更低的 GPT Image 1 版本，原生支持文本与图像输入并生成图像输出。", "resolutions": ["1024x1024", "1024x1536", "1536x1024"]}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'dall-e-3', 'DALL·E 3', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"lookup": {"prices": {"hd_1024x1024": 0.08, "hd_1024x1792": 0.12, "hd_1792x1024": 0.12, "standard_1024x1024": 0.04, "standard_1024x1792": 0.08, "standard_1792x1024": 0.08}, "pricingParams": ["quality", "size"]}, "name": "imageGeneration", "strategy": "lookup", "unit": "image"}]}, "parameters": {"prompt": {"default": ""}, "quality": {"default": "standard", "enum": ["standard", "hd"]}, "size": {"default": "1024x1024", "enum": ["1024x1024", "1792x1024", "1024x1792"]}}, "source": "builtin", "description": "最新的 DALL·E 模型，于2023年11月发布。支持更真实、准确的图像生成，具有更强的细节表现力", "resolutions": ["1024x1024", "1024x1792", "1792x1024"]}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'dall-e-2', 'DALL·E 2', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"lookup": {"prices": {"1024x1024": 0.02, "256x256": 0.016, "512x512": 0.018}, "pricingParams": ["size"]}, "name": "imageGeneration", "strategy": "lookup", "unit": "image"}]}, "parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["256x256", "512x512", "1024x1024"]}}, "source": "builtin", "description": "第二代 DALL·E 模型，支持更真实、准确的图像生成，分辨率是第一代的4倍", "resolutions": ["256x256", "512x512", "1024x1024"]}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-realtime', 'GPT Realtime', 'realtime', 32000, 4096, 0.004, 0.016, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "audioInput", "rate": 32, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioOutput", "rate": 64, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioInput_cacheRead", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageInput_cacheRead", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-28", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "通用实时模型，支持文本与音频的实时输入输出，并支持图像输入。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o-realtime-preview', 'GPT-4o Realtime 241217', 'realtime', 16000, 4096, 0.005, 0.02, '{"pricing": {"units": [{"name": "audioInput", "rate": 40, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioOutput", "rate": 80, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioInput_cacheRead", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-12-17", "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "GPT-4o 实时版本，支持音频和文本实时输入输出"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o-realtime-preview-2025-06-03', 'GPT-4o Realtime 250603', 'realtime', 32000, 4096, 0.005, 0.02, '{"pricing": {"units": [{"name": "audioInput", "rate": 40, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioOutput", "rate": 80, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioInput_cacheRead", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-03", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "GPT-4o 实时版本，支持音频和文本实时输入输出"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o-realtime-preview-2024-10-01', 'GPT-4o Realtime 241001', 'realtime', 16000, 4096, 0.005, 0.02, '{"pricing": {"units": [{"name": "audioInput", "rate": 100, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioOutput", "rate": 200, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioInput_cacheRead", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-10-01", "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "GPT-4o 实时版本，支持音频和文本实时输入输出"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openai'), 'gpt-4o-mini-realtime-preview', 'GPT-4o Mini Realtime', 'realtime', 128000, 4096, 0.0006, 0.0024, '{"pricing": {"units": [{"name": "audioInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "audioInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-12-17", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "GPT-4o-mini 实时版本，支持音频和文本实时输入输出"}', FALSE),
    -- openrouter
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'openrouter/auto', 'Auto (best for prompt)', 'chat', 2000000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 2000000, "contextWindowTokens": 2000000, "description": "根据上下文长度、主题和复杂性，你的请求将发送到 Llama 3 70B Instruct、Claude 3.5 Sonnet（自我调节）或 GPT-4o。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'deepseek/deepseek-chat-v3.1', 'DeepSeek V3.1', 'chat', 163840, NULL, 0.0002, 0.0008, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-21", "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek-V3.1是一款支持128K长上下文和高效模式切换的大型混合推理模型，它在工具调用、代码生成和复杂推理任务上实现了卓越的性能与速度。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'google/gemini-2.5-flash-image-preview', 'Nano Banana', 'chat', 40960, 8192, 0.0003, 0.0025, '{"abilities": {"imageOutput": true, "vision": true}, "pricing": {"units": [{"name": "imageOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-26", "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 2.5 Flash 实验模型，支持图像生成", "vision": true, "image_generation": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'qwen/qwen3-30b-a3b:free', 'Qwen3 30B A3B (Free)', 'chat', 40960, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "description": "Qwen3 是 Qwen 大型语言模型系列的最新一代，具有密集和专家混合 (MoE) 架构，在推理、多语言支持和高级代理任务方面表现出色。其在复杂推理的思考模式和高效对话的非思考模式之间无缝切换的独特能力确保了多功能、高质量的性能。\n\nQwen3 显著优于 QwQ 和 Qwen2.5 等先前模型，提供卓越的数学、编码、常识推理、创意写作和交互式对话能力。Qwen3-30B-A3B 变体包含 305 亿个参数（33 亿个激活参数）、48 层、128 个专家（每个任务激活 8 个），并支持高达 131K 令牌上下文（使用 YaRN），为开源模型树立了新标准。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'qwen/qwen3-30b-a3b', 'Qwen3 30B A3B', 'chat', 40960, 40960, 0.0001, 0.0003, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "maxOutputTokens": 40960, "maxOutput": 40960, "description": "Qwen3 是 Qwen 大型语言模型系列的最新一代，具有密集和专家混合 (MoE) 架构，在推理、多语言支持和高级代理任务方面表现出色。其在复杂推理的思考模式和高效对话的非思考模式之间无缝切换的独特能力确保了多功能、高质量的性能。\n\nQwen3 显著优于 QwQ 和 Qwen2.5 等先前模型，提供卓越的数学、编码、常识推理、创意写作和交互式对话能力。Qwen3-30B-A3B 变体包含 305 亿个参数（33 亿个激活参数）、48 层、128 个专家（每个任务激活 8 个），并支持高达 131K 令牌上下文（使用 YaRN），为开源模型树立了新标准。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'qwen/qwen3-8b:free', 'Qwen3 8B (Free)', 'chat', 40960, 40960, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "maxOutputTokens": 40960, "maxOutput": 40960, "description": "Qwen3-8B 是 Qwen3 系列中一个密集的 82 亿参数因果语言模型，专为推理密集型任务和高效对话而设计。它支持在用于数学、编码和逻辑推理的“思考”模式与用于一般对话的“非思考”模式之间无缝切换。该模型经过微调，可用于指令遵循、代理集成、创意写作以及跨 100 多种语言和方言的多语言使用。它原生支持 32K 令牌上下文窗口，并可通过 YaRN 扩展到 131K 令牌。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'qwen/qwen3-14b:free', 'Qwen3 14B (Free)', 'chat', 40960, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "description": "Qwen3-14B 是 Qwen3 系列中一个密集的 148 亿参数因果语言模型，专为复杂推理和高效对话而设计。它支持在用于数学、编程和逻辑推理等任务的“思考”模式与用于通用对话的“非思考”模式之间无缝切换。该模型经过微调，可用于指令遵循、代理工具使用、创意写作以及跨 100 多种语言和方言的多语言任务。它原生处理 32K 令牌上下文，并可使用基于 YaRN 的扩展扩展到 131K 令牌。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'qwen/qwen3-14b', 'Qwen3 14B', 'chat', 40960, 40960, 0.00008, 0.00024, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.08, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.24, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "maxOutputTokens": 40960, "maxOutput": 40960, "description": "Qwen3-14B 是 Qwen3 系列中一个密集的 148 亿参数因果语言模型，专为复杂推理和高效对话而设计。它支持在用于数学、编程和逻辑推理等任务的“思考”模式与用于通用对话的“非思考”模式之间无缝切换。该模型经过微调，可用于指令遵循、代理工具使用、创意写作以及跨 100 多种语言和方言的多语言任务。它原生处理 32K 令牌上下文，并可使用基于 YaRN 的扩展扩展到 131K 令牌。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'qwen/qwen3-32b:free', 'Qwen3 32B (Free)', 'chat', 40960, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "description": "Qwen3-32B 是 Qwen3 系列中一个密集的 328 亿参数因果语言模型，针对复杂推理和高效对话进行了优化。它支持在用于数学、编码和逻辑推理等任务的“思考”模式与用于更快、通用对话的“非思考”模式之间无缝切换。该模型在指令遵循、代理工具使用、创意写作以及跨 100 多种语言和方言的多语言任务中表现出强大的性能。它原生处理 32K 令牌上下文，并可使用基于 YaRN 的扩展扩展到 131K 令牌。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'qwen/qwen3-32b', 'Qwen3 32B', 'chat', 40960, NULL, 0.0001, 0.0003, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "description": "Qwen3-32B 是 Qwen3 系列中一个密集的 328 亿参数因果语言模型，针对复杂推理和高效对话进行了优化。它支持在用于数学、编码和逻辑推理等任务的“思考”模式与用于更快、通用对话的“非思考”模式之间无缝切换。该模型在指令遵循、代理工具使用、创意写作以及跨 100 多种语言和方言的多语言任务中表现出强大的性能。它原生处理 32K 令牌上下文，并可使用基于 YaRN 的扩展扩展到 131K 令牌。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'qwen/qwen3-235b-a22b:free', 'Qwen3 235B A22B (Free)', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Qwen3-235B-A22B 是由 Qwen 开发的 235B 参数专家混合 (MoE) 模型，每次前向传递激活 22B 参数。它支持在用于复杂推理、数学和代码任务的“思考”模式与用于一般对话效率的“非思考”模式之间无缝切换。该模型展示了强大的推理能力、多语言支持（100 多种语言和方言）、高级指令遵循和代理工具调用能力。它原生处理 32K 令牌上下文窗口，并使用基于 YaRN 的扩展扩展到 131K 令牌。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'qwen/qwen3-235b-a22b', 'Qwen3 235B A22B', 'chat', 40960, 40960, 0.0002, 0.0006, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "maxOutputTokens": 40960, "maxOutput": 40960, "description": "Qwen3-235B-A22B 是由 Qwen 开发的 235B 参数专家混合 (MoE) 模型，每次前向传递激活 22B 参数。它支持在用于复杂推理、数学和代码任务的“思考”模式与用于一般对话效率的“非思考”模式之间无缝切换。该模型展示了强大的推理能力、多语言支持（100 多种语言和方言）、高级指令遵循和代理工具调用能力。它原生处理 32K 令牌上下文窗口，并使用基于 YaRN 的扩展扩展到 131K 令牌。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'tngtech/deepseek-r1t-chimera:free', 'DeepSeek R1T Chimera (Free)', 'chat', 163840, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek-R1T-Chimera 通过合并 DeepSeek-R1 和 DeepSeek-V3 (0324) 创建，结合了 R1 的推理能力和 V3 的令牌效率改进。它基于 DeepSeek-MoE Transformer 架构，并针对通用文本生成任务进行了优化。\n\n该模型合并了两个源模型的预训练权重，以平衡推理、效率和指令遵循任务的性能。它根据 MIT 许可证发布，旨在用于研究和商业用途。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'thudm/glm-z1-rumination-32b', 'GLM Z1 Rumination 32B', 'chat', 32000, NULL, 0.00024, 0.00024, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.24, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.24, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "GLM Z1 Rumination 32B 是 GLM-4-Z1 系列中的 32B 参数深度推理模型，针对需要长时间思考的复杂、开放式任务进行了优化。它建立在 glm-4-32b-0414 的基础上，增加了额外的强化学习阶段和多阶段对齐策略，引入了旨在模拟扩展认知处理的“反思”能力。这包括迭代推理、多跳分析和工具增强的工作流程，例如搜索、检索和引文感知合成。\n\n该模型在研究式写作、比较分析和复杂问答方面表现出色。它支持用于搜索和导航原语（`search`、`click`、`open`、`finish`）的函数调用，从而可以在代理式管道中使用。反思行为由具有基于规则的奖励塑造和延迟决策机制的多轮循环控制，并以 OpenAI 内部对齐堆栈等深度研究框架为基准。此变体适用于需要深度而非速度的场景。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'thudm/glm-z1-32b', 'GLM Z1 32B', 'chat', 32768, NULL, 0.00024, 0.00024, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.24, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.24, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "GLM-Z1-32B-0414 是 GLM-4-32B 的增强推理变体，专为深度数学、逻辑和面向代码的问题解决而构建。它应用扩展强化学习（任务特定和基于通用成对偏好）来提高复杂多步骤任务的性能。与基础 GLM-4-32B 模型相比，Z1 显著提升了结构化推理和形式化领域的能力。\n\n该模型支持通过提示工程强制执行“思考”步骤，并为长格式输出提供改进的连贯性。它针对代理工作流进行了优化，并支持长上下文（通过 YaRN）、JSON 工具调用和用于稳定推理的细粒度采样配置。非常适合需要深思熟虑、多步骤推理或形式化推导的用例。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'thudm/glm-4-32b:free', 'GLM 4 32B (Free)', 'chat', 32000, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "GLM-4-32B-0414 是一个 32B 双语（中英）开放权重语言模型，针对代码生成、函数调用和代理式任务进行了优化。它在 15T 高质量和重推理数据上进行了预训练，并使用人类偏好对齐、拒绝采样和强化学习进一步完善。该模型在复杂推理、工件生成和结构化输出任务方面表现出色，在多个基准测试中达到了与 GPT-4o 和 DeepSeek-V3-0324 相当的性能。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'thudm/glm-4-32b', 'GLM 4 32B', 'chat', 32000, NULL, 0.00024, 0.00024, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.24, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.24, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "GLM-4-32B-0414 是一个 32B 双语（中英）开放权重语言模型，针对代码生成、函数调用和代理式任务进行了优化。它在 15T 高质量和重推理数据上进行了预训练，并使用人类偏好对齐、拒绝采样和强化学习进一步完善。该模型在复杂推理、工件生成和结构化输出任务方面表现出色，在多个基准测试中达到了与 GPT-4o 和 DeepSeek-V3-0324 相当的性能。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'google/gemini-2.5-pro', 'Gemini 2.5 Pro', 'chat', 1048576, 65536, 0.00125, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1048576, "contextWindowTokens": 1048576, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Pro 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'google/gemini-2.5-pro-preview', 'Gemini 2.5 Pro Preview', 'chat', 1048576, 65536, 0.00125, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1048576, "contextWindowTokens": 1048576, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Pro Preview 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'google/gemini-2.5-flash', 'Gemini 2.5 Flash', 'chat', 1048576, 65535, 0.00015, 0.0006, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1048576, "contextWindowTokens": 1048576, "maxOutputTokens": 65535, "maxOutput": 65535, "description": "Gemini 2.5 Flash 是 Google 最先进的主力模型，专为高级推理、编码、数学和科学任务而设计。它包含内置的“思考”能力，使其能够提供具有更高准确性和细致上下文处理的响应。\n\n注意：此模型有两个变体：思考和非思考。输出定价根据思考能力是否激活而有显著差异。如果您选择标准变体（不带“:thinking”后缀），模型将明确避免生成思考令牌。\n\n要利用思考能力并接收思考令牌，您必须选择“:thinking”变体，这将产生更高的思考输出定价。\n\n此外，Gemini 2.5 Flash 可通过“推理最大令牌数”参数进行配置，如文档中所述 (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'google/gemini-2.5-flash-preview', 'Gemini 2.5 Flash Preview', 'chat', 1048576, 65535, 0.00015, 0.0006, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1048576, "contextWindowTokens": 1048576, "maxOutputTokens": 65535, "maxOutput": 65535, "description": "Gemini 2.5 Flash 是 Google 最先进的主力模型，专为高级推理、编码、数学和科学任务而设计。它包含内置的“思考”能力，使其能够提供具有更高准确性和细致上下文处理的响应。\n\n注意：此模型有两个变体：思考和非思考。输出定价根据思考能力是否激活而有显著差异。如果您选择标准变体（不带“:thinking”后缀），模型将明确避免生成思考令牌。\n\n要利用思考能力并接收思考令牌，您必须选择“:thinking”变体，这将产生更高的思考输出定价。\n\n此外，Gemini 2.5 Flash 可通过“推理最大令牌数”参数进行配置，如文档中所述 (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'google/gemini-2.5-flash-preview:thinking', 'Gemini 2.5 Flash Preview (thinking)', 'chat', 1048576, 65535, 0.00015, 0.0035, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1048576, "contextWindowTokens": 1048576, "maxOutputTokens": 65535, "maxOutput": 65535, "description": "Gemini 2.5 Flash 是 Google 最先进的主力模型，专为高级推理、编码、数学和科学任务而设计。它包含内置的“思考”能力，使其能够提供具有更高准确性和细致上下文处理的响应。\n\n注意：此模型有两个变体：思考和非思考。输出定价根据思考能力是否激活而有显著差异。如果您选择标准变体（不带“:thinking”后缀），模型将明确避免生成思考令牌。\n\n要利用思考能力并接收思考令牌，您必须选择“:thinking”变体，这将产生更高的思考输出定价。\n\n此外，Gemini 2.5 Flash 可通过“推理最大令牌数”参数进行配置，如文档中所述 (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'openai/o3', 'o3', 'chat', 200000, 100000, 0.002, 0.008, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3 是一款全能强大的模型，在多个领域表现出色。它为数学、科学、编程和视觉推理任务树立了新标杆。它也擅长技术写作和指令遵循。用户可利用它分析文本、代码和图像，解决多步骤的复杂问题。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'openai/o4-mini-high', 'o4-mini (high)', 'chat', 200000, 100000, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.275, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o4-mini 高推理等级版，专为快速有效的推理而优化，在编码和视觉任务中表现出极高的效率和性能。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'openai/o4-mini', 'o4-mini', 'chat', 200000, 100000, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.275, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-17", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o4-mini 专为快速有效的推理而优化，在编码和视觉任务中表现出极高的效率和性能。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'openai/gpt-4.1', 'GPT-4.1', 'chat', 1047576, 32768, 0.002, 0.008, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 是我们用于复杂任务的旗舰模型。它非常适合跨领域解决问题。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'openai/gpt-4.1-mini', 'GPT-4.1 mini', 'chat', 1047576, 32768, 0.0004, 0.0016, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 mini 提供了智能、速度和成本之间的平衡，使其成为许多用例中有吸引力的模型。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'openai/gpt-4.1-nano', 'GPT-4.1 nano', 'chat', 1047576, 32768, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GPT-4.1 nano 是最快，最具成本效益的GPT-4.1模型。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'openai/o3-mini-high', 'o3-mini (high)', 'chat', 200000, 100000, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-31", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3-mini 高推理等级版，在与 o1-mini 相同的成本和延迟目标下提供高智能。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'openai/o3-mini', 'o3-mini', 'chat', 200000, 100000, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-31", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 100000, "maxOutput": 100000, "description": "o3-mini 在与 o1-mini 相同的成本和延迟目标下提供高智能。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'openai/o1-mini', 'o1-mini', 'chat', 128000, 65536, 0.003, 0.012, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-12", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "o1-mini是一款针对编程、数学和科学应用场景而设计的快速、经济高效的推理模型。该模型具有128K上下文和2023年10月的知识截止日期。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'openai/o1-preview', 'o1-preview', 'chat', 128000, 32768, 0.015, 0.06, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-12", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "o1是OpenAI新的推理模型，适用于需要广泛通用知识的复杂任务。该模型具有128K上下文和2023年10月的知识截止日期。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'openai/gpt-4o-mini', 'GPT-4o mini', 'chat', 128000, 16385, 0.00015, 0.0006, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16385, "maxOutput": 16385, "description": "GPT-4o mini是OpenAI在GPT-4 Omni之后推出的最新模型，支持图文输入并输出文本。作为他们最先进的小型模型，它比其他近期的前沿模型便宜很多，并且比GPT-3.5 Turbo便宜超过60%。它保持了最先进的智能，同时具有显著的性价比。GPT-4o mini在MMLU测试中获得了 82% 的得分，目前在聊天偏好上排名高于 GPT-4。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'openai/gpt-4o', 'GPT-4o', 'chat', 128000, NULL, 0.0025, 0.01, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'deepseek/deepseek-r1-0528', 'DeepSeek R1 0528', 'chat', 163840, NULL, 0.0005, 0.00218, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.18, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-05-28", "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek-R1 在仅有极少标注数据的情况下，极大提升了模型推理能力。在输出最终回答之前，模型会先输出一段思维链内容，以提升最终答案的准确性。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'deepseek/deepseek-r1-0528:free', 'DeepSeek R1 0528 (Free)', 'chat', 163840, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "released_at": "2025-05-28", "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek-R1 在仅有极少标注数据的情况下，极大提升了模型推理能力。在输出最终回答之前，模型会先输出一段思维链内容，以提升最终答案的准确性。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'deepseek/deepseek-r1', 'DeepSeek R1', 'chat', 163840, NULL, 0.003, 0.008, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-20", "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek-R1 在仅有极少标注数据的情况下，极大提升了模型推理能力。在输出最终回答之前，模型会先输出一段思维链内容，以提升最终答案的准确性。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'deepseek/deepseek-r1:free', 'DeepSeek R1 (Free)', 'chat', 163840, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "released_at": "2025-01-20", "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek-R1 在仅有极少标注数据的情况下，极大提升了模型推理能力。在输出最终回答之前，模型会先输出一段思维链内容，以提升最终答案的准确性。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'deepseek/deepseek-chat-v3-0324', 'DeepSeek V3 0324', 'chat', 163840, NULL, 0.00027, 0.0011, '{"pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.07, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.27, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek V3 是一个 685B 参数的专家混合模型，是 DeepSeek 团队旗舰聊天模型系列的最新迭代。\n\n它继承了 [DeepSeek V3](/deepseek/deepseek-chat-v3) 模型，并在各种任务上表现出色。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'deepseek/deepseek-chat-v3-0324:free', 'DeepSeek V3 0324 (Free)', 'chat', 163840, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek V3 是一个 685B 参数的专家混合模型，是 DeepSeek 团队旗舰聊天模型系列的最新迭代。\n\n它继承了 [DeepSeek V3](/deepseek/deepseek-chat-v3) 模型，并在各种任务上表现出色。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'anthropic/claude-sonnet-4.5', 'Claude Sonnet 4.5', 'chat', 200000, 64000, 0.003, 0.015, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["disableContextCaching", "enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheWrite", "rate": 3.75, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-30", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Claude Sonnet 4.5 是 Anthropic 迄今为止最智能的模型。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'anthropic/claude-3-haiku', 'Claude 3 Haiku', 'chat', 200000, 4096, 0.00025, 0.00125, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"5m": 0.3125}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2024-03-07", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Claude 3 Haiku 是 Anthropic 的最快且最紧凑的模型，旨在实现近乎即时的响应。它具有快速且准确的定向性能。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'anthropic/claude-3.5-haiku', 'Claude 3.5 Haiku', 'chat', 200000, 8192, 0.001, 0.005, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"5m": 1.25}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2024-11-05", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Claude 3.5 Haiku 是 Anthropic 最快的下一代模型。与 Claude 3 Haiku 相比，Claude 3.5 Haiku 在各项技能上都有所提升，并在许多智力基准测试中超越了上一代最大的模型 Claude 3 Opus。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'anthropic/claude-3.5-sonnet', 'Claude 3.5 Sonnet', 'chat', 200000, 8192, 0.003, 0.015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"5m": 3.75}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2024-06-20", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Claude 3.5 Sonnet 提供了超越 Opus 的能力和比 Sonnet 更快的速度，同时保持与 Sonnet 相同的价格。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'anthropic/claude-3.7-sonnet', 'Claude 3.7 Sonnet', 'chat', 200000, 8192, 0.003, 0.015, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"5m": 3.75}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-02-24", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Claude 3.7 Sonnet 是 Anthropic 迄今为止最智能的模型，也是市场上首个混合推理模型。Claude 3.7 Sonnet 可以产生近乎即时的响应或延长的逐步思考，用户可以清晰地看到这些过程。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'anthropic/claude-sonnet-4', 'Claude Sonnet 4', 'chat', 200000, 64000, 0.003, 0.015, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-05-23", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Claude Sonnet 4 可以产生近乎即时的响应或延长的逐步思考，用户可以清晰地看到这些过程。API 用户还可以对模型思考的时间进行细致的控制", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'anthropic/claude-opus-4', 'Claude Opus 4', 'chat', 200000, 32000, 0.015, 0.075, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 75, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-05-23", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "Claude Opus 4 是 Anthropic 用于处理高度复杂任务的最强大模型。它在性能、智能、流畅性和理解力方面表现卓越。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'anthropic/claude-3-opus', 'Claude 3 Opus', 'chat', 200000, 4096, 0.015, 0.075, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 75, "strategy": "fixed", "unit": "millionTokens"}, {"lookup": {"prices": {"5m": 18.75}, "pricingParams": ["ttl"]}, "name": "textInput_cacheWrite", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2024-02-29", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Claude 3 Opus 是 Anthropic 用于处理高度复杂任务的最强大模型。它在性能、智能、流畅性和理解力方面表现卓越。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'google/gemini-flash-1.5', 'Gemini 1.5 Flash', 'chat', 1008192, 8192, 0.000075, 0.0003, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1008192, "contextWindowTokens": 1008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Flash 提供了优化后的多模态处理能力，适用多种复杂任务场景。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'google/gemini-2.0-flash-001', 'Gemini 2.0 Flash', 'chat', 1056768, 8192, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-05", "source": "builtin", "maxToken": 1056768, "contextWindowTokens": 1056768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 2.0 Flash 提供下一代功能和改进，包括卓越的速度、原生工具使用、多模态生成和1M令牌上下文窗口。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'google/gemini-pro-1.5', 'Gemini 1.5 Pro', 'chat', 2008192, 8192, 0.0035, 0.0105, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 2008192, "contextWindowTokens": 2008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Pro 结合最新优化技术，带来更高效的多模态数据处理能力。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'meta-llama/llama-3.2-11b-vision-instruct', 'Llama 3.2 11B Vision', 'chat', 131072, NULL, 0.000162, 0.000162, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.162, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.162, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "LLaMA 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'meta-llama/llama-3.2-90b-vision-instruct', 'Llama 3.2 90B Vision', 'chat', 131072, NULL, 0.0004, 0.0004, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "LLaMA 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'meta-llama/llama-3.3-70b-instruct', 'Llama 3.3 70B Instruct', 'chat', 131072, NULL, 0.00012, 0.0003, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.12, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Llama 3.3 是 Llama 系列最先进的多语言开源大型语言模型，以极低成本体验媲美 405B 模型的性能。基于 Transformer 结构，并通过监督微调（SFT）和人类反馈强化学习（RLHF）提升有用性和安全性。其指令调优版本专为多语言对话优化，在多项行业基准上表现优于众多开源和封闭聊天模型。知识截止日期为 2023 年 12 月", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'meta-llama/llama-3.3-70b-instruct:free', 'Llama 3.3 70B Instruct (Free)', 'chat', 65536, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "Llama 3.3 是 Llama 系列最先进的多语言开源大型语言模型，以极低成本体验媲美 405B 模型的性能。基于 Transformer 结构，并通过监督微调（SFT）和人类反馈强化学习（RLHF）提升有用性和安全性。其指令调优版本专为多语言对话优化，在多项行业基准上表现优于众多开源和封闭聊天模型。知识截止日期为 2023 年 12 月", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'qwen/qwen-2-7b-instruct:free', 'Qwen2 7B (Free)', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2 是全新的大型语言模型系列，具有更强的理解和生成能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'meta-llama/llama-3.1-8b-instruct:free', 'Llama 3.1 8B (Free)', 'chat', 131072, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "LLaMA 3.1 提供多语言支持，是业界领先的生成模型之一。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'google/gemma-2-9b-it:free', 'Gemma 2 9B (Free)', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Gemma 2 是Google轻量化的开源文本模型系列。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'openrouter'), 'google/gemini-2.0-flash-exp:free', 'Gemini 2.0 Flash Experimental (Free)', 'chat', 1056768, 8192, NULL, NULL, '{"abilities": {"functionCall": true, "vision": true}, "released_at": "2024-12-11", "source": "builtin", "maxToken": 1056768, "contextWindowTokens": 1056768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 2.0 Flash Experimental 是 Google 最新的实验性多模态AI模型，与历史版本相比有一定的质量提升，特别是对于世界知识、代码和长上下文。", "vision": true, "function_calling": true}', FALSE),
    -- perplexity
    ((SELECT id FROM ai_providers WHERE code = 'perplexity'), 'sonar-deep-research', 'Sonar Deep Research', 'chat', 127072, 8192, 0.002, 0.008, '{"abilities": {"reasoning": true, "search": true}, "settings": {"extendParams": ["reasoningEffort"], "searchImpl": "internal"}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-14", "source": "builtin", "maxToken": 127072, "contextWindowTokens": 127072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Deep Research 进行全面的专家级研究，并将其综合成可访问、可作的报告。", "reasoning": true, "web_search": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'perplexity'), 'sonar-reasoning-pro', 'Sonar Reasoning Pro', 'chat', 127072, 8192, 0.002, 0.008, '{"abilities": {"reasoning": true, "search": true, "vision": true}, "settings": {"searchImpl": "internal"}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-21", "source": "builtin", "maxToken": 127072, "contextWindowTokens": 127072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "支持搜索上下文的高级搜索产品，支持高级查询和跟进。", "vision": true, "reasoning": true, "web_search": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'perplexity'), 'sonar-reasoning', 'Sonar Reasoning', 'chat', 127072, 8192, 0.001, 0.005, '{"abilities": {"reasoning": true, "search": true, "vision": true}, "settings": {"searchImpl": "internal"}, "pricing": {"units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-21", "source": "builtin", "maxToken": 127072, "contextWindowTokens": 127072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "支持搜索上下文的高级搜索产品，支持高级查询和跟进。", "vision": true, "reasoning": true, "web_search": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'perplexity'), 'sonar-pro', 'Sonar Pro', 'chat', 200000, NULL, 0.003, 0.015, '{"abilities": {"search": true, "vision": true}, "settings": {"searchImpl": "internal"}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-21", "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "支持搜索上下文的高级搜索产品，支持高级查询和跟进。", "vision": true, "web_search": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'perplexity'), 'sonar', 'Sonar', 'chat', 127072, NULL, 0.001, 0.001, '{"abilities": {"search": true, "vision": true}, "settings": {"searchImpl": "internal"}, "pricing": {"units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-21", "source": "builtin", "maxToken": 127072, "contextWindowTokens": 127072, "description": "基于搜索上下文的轻量级搜索产品，比 Sonar Pro 更快、更便宜。", "vision": true, "web_search": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'perplexity'), 'r1-1776', 'R1 1776', 'chat', 127072, NULL, 0.002, 0.008, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-18", "source": "builtin", "maxToken": 127072, "contextWindowTokens": 127072, "description": "R1-1776 是 DeepSeek R1 模型的一个版本，经过后训练，可提供未经审查、无偏见的事实信息。", "vision": true, "reasoning": true}', FALSE),
    -- ppio
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'deepseek/deepseek-r1/community', 'DeepSeek: DeepSeek R1 (Community)', 'chat', 64000, NULL, 0.004, 0.016, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "description": "DeepSeek R1是DeepSeek团队发布的最新开源模型，具备非常强悍的推理性能，尤其在数学、编程和推理任务上达到了与OpenAI的o1模型相当的水平。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'deepseek/deepseek-v3/community', 'DeepSeek: DeepSeek V3 (Community)', 'chat', 64000, NULL, 0.001, 0.002, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "description": "DeepSeek-V3在推理速度方面实现了比之前模型的重大突破。在开源模型中排名第一，并可与全球最先进的闭源模型相媲美。DeepSeek-V3 采用了多头潜在注意力 （MLA） 和 DeepSeekMoE 架构，这些架构在 DeepSeek-V2 中得到了全面验证。此外，DeepSeek-V3 开创了一种用于负载均衡的辅助无损策略，并设定了多标记预测训练目标以获得更强的性能。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'deepseek/deepseek-r1', 'DeepSeek R1', 'chat', 64000, NULL, 0.004, 0.016, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "description": "DeepSeek R1是DeepSeek团队发布的最新开源模型，具备非常强悍的推理性能，尤其在数学、编程和推理任务上达到了与OpenAI的o1模型相当的水平。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'deepseek/deepseek-v3', 'DeepSeek V3', 'chat', 64000, NULL, 0.001, 0.002, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "description": "DeepSeek-V3在推理速度方面实现了比之前模型的重大突破。在开源模型中排名第一，并可与全球最先进的闭源模型相媲美。DeepSeek-V3 采用了多头潜在注意力 （MLA） 和 DeepSeekMoE 架构，这些架构在 DeepSeek-V2 中得到了全面验证。此外，DeepSeek-V3 开创了一种用于负载均衡的辅助无损策略，并设定了多标记预测训练目标以获得更强的性能。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'deepseek/deepseek-r1-distill-llama-70b', 'DeepSeek R1 Distill Llama 70B', 'chat', 32000, NULL, 0.0058, 0.0058, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5.8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "DeepSeek R1 Distill Llama 70B是基于Llama3.3  70B的大型语言模型，该模型利用DeepSeek R1输出的微调，实现了与大型前沿模型相当的竞争性能。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'deepseek/deepseek-r1-distill-qwen-32b', 'DeepSeek: DeepSeek R1 Distill Qwen 32B', 'chat', 64000, NULL, 0.00218, 0.00218, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.18, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.18, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "description": "DeepSeek R1 Distill Qwen 32B 是一种基于 Qwen 2.5 32B 的蒸馏大语言模型，通过使用 DeepSeek R1 的输出进行训练而得。该模型在多个基准测试中超越了 OpenAI 的 o1-mini，取得了密集模型（dense models）的最新技术领先成果（state-of-the-art）。以下是一些基准测试的结果：\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nCodeForces Rating: 1691\n该模型通过从 DeepSeek R1 的输出中进行微调，展现了与更大规模的前沿模型相当的竞争性能。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'deepseek/deepseek-r1-distill-qwen-14b', 'DeepSeek: DeepSeek R1 Distill Qwen 14B', 'chat', 64000, NULL, 0.001, 0.001, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "description": "DeepSeek R1 Distill Qwen 14B 是一种基于 Qwen 2.5 14B 的蒸馏大语言模型，通过使用 DeepSeek R1 的输出进行训练而得。该模型在多个基准测试中超越了 OpenAI 的 o1-mini，取得了密集模型（dense models）的最新技术领先成果（state-of-the-art）。以下是一些基准测试的结果：\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nCodeForces Rating: 1481\n该模型通过从 DeepSeek R1 的输出中进行微调，展现了与更大规模的前沿模型相当的竞争性能。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'deepseek/deepseek-r1-distill-llama-8b', 'DeepSeek: DeepSeek R1 Distill Llama 8B', 'chat', 32000, NULL, 0.0003, 0.0003, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "DeepSeek R1 Distill Llama 8B 是一种基于 Llama-3.1-8B-Instruct 的蒸馏大语言模型，通过使用 DeepSeek R1 的输出进行训练而得。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'qwen/qwen-2.5-72b-instruct', 'qwen/qwen-2.5-72b-instruct', 'chat', 32768, NULL, 0.00275, 0.00288, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.88, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'qwen/qwen-2-vl-72b-instruct', 'qwen/qwen-2-vl-72b-instruct', 'chat', 32768, NULL, 0.0045, 0.0045, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2-VL 是 Qwen-VL 模型的最新迭代版本，在视觉理解基准测试中达到了最先进的性能，包括 MathVista、DocVQA、RealWorldQA 和 MTVQA 等。Qwen2-VL 能够理解超过 20 分钟的视频，用于高质量的基于视频的问答、对话和内容创作。它还具备复杂推理和决策能力，可以与移动设备、机器人等集成，基于视觉环境和文本指令进行自动操作。除了英语和中文，Qwen2-VL 现在还支持理解图像中不同语言的文本，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语等", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'meta-llama/llama-3.2-3b-instruct', 'meta-llama/llama-3.2-3b-instruct', 'chat', 32768, NULL, 0.000216, 0.00036, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.216, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.36, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "meta-llama/llama-3.2-3b-instruct"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'qwen/qwen2.5-32b-instruct', 'qwen/qwen2.5-32b-instruct', 'chat', 32000, NULL, 0.00126, 0.00126, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.26, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.26, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "Qwen2.5-32B-Instruct 是阿里云发布的最新大语言模型系列之一。该 32B 模型在编码和数学等领域具有显著改进的能力。该模型提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'baichuan/baichuan2-13b-chat', 'baichuan/baichuan2-13b-chat', 'chat', 14336, NULL, 0.00175, 0.00175, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.75, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 14336, "contextWindowTokens": 14336, "description": "Baichuan-13B 百川智能开发的包含 130 亿参数的开源可商用的大规模语言模型，在权威的中文和英文 benchmark 上均取得同尺寸最好的效果"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'meta-llama/llama-3.1-70b-instruct', 'meta-llama/llama-3.1-70b-instruct', 'chat', 32768, NULL, 0.00245, 0.00282, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.45, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.82, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Meta最新一代的Llama 3.1模型系列，70B（700亿参数）的指令微调版本针对高质量对话场景进行了优化。在业界评估中，与领先的闭源模型相比，它展现出了强劲的性能。(仅针对企业实名认证通过主体开放）"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'meta-llama/llama-3.1-8b-instruct', 'meta-llama/llama-3.1-8b-instruct', 'chat', 32768, NULL, 0.0004, 0.0004, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Meta最新一代的Llama 3.1模型系列，8B（80亿参数）的指令微调版本特别快速高效。在业界评估中，表现出强劲的性能，超越了很多领先的闭源模型。(仅针对企业实名认证通过主体开放）"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), '01-ai/yi-1.5-34b-chat', '01-ai/yi-1.5-34b-chat', 'chat', 16384, NULL, 0.0011, 0.0011, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "零一万物，最新开源微调模型，340亿参数，微调支持多种对话场景，高质量训练数据，对齐人类偏好。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), '01-ai/yi-1.5-9b-chat', '01-ai/yi-1.5-9b-chat', 'chat', 16384, NULL, 0.0004, 0.0004, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "零一万物，最新开源微调模型，90亿参数，微调支持多种对话场景，高质量训练数据，对齐人类偏好。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'thudm/glm-4-9b-chat', 'thudm/glm-4-9b-chat', 'chat', 32768, NULL, 0.0005, 0.0005, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "智谱AI发布的GLM-4系列最新一代预训练模型的开源版本。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'ppio'), 'qwen/qwen-2-7b-instruct', 'qwen/qwen-2-7b-instruct', 'chat', 32768, NULL, 0.00032, 0.00032, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.32, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.32, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2是全新的Qwen大型语言模型系列。Qwen2 7B是一个基于transformer的模型，在语言理解、多语言能力、编程、数学和推理方面表现出色。"}', TRUE),
    -- qiniu
    ((SELECT id FROM ai_providers WHERE code = 'qiniu'), 'deepseek-v3', 'DeepSeek V3', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "推理速度大幅提升，位居开源模型之首，媲美顶尖闭源模型。采用负载均衡辅助策略和多标记预测训练，性能显著增强。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'qiniu'), 'deepseek-r1', 'DeepSeek R1', 'chat', 65536, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "DeepSeek R1 是 DeepSeek 团队发布的最新开源模型，具备非常强悍的推理性能，尤其在数学、编程和推理任务上达到了与 OpenAI 的 o1 模型相当的水平。", "reasoning": true}', TRUE),
    -- qwen
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-vl-plus', 'Qwen3 VL Plus', 'chat', 262144, 32768, NULL, NULL, '{"abilities": {"reasoning": true, "vision": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "config": {"deploymentName": "qwen3-vl-plus"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 1, "[0.032, 0.128]": 1.5, "[0.128, infinity]": 3}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 10, "[0.032, 0.128]": 15, "[0.128, infinity]": 30}, "pricingParams": ["textInputRange"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-09-23", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "通义千问VL是具有视觉（图像）理解能力的文本生成模型，不仅能进行OCR（图片文字识别），还能进一步总结和推理，例如从商品照片中提取属性，根据习题图进行解题等。", "organization": "Qwen", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-vl-flash', 'Qwen3 VL Flash', 'chat', 262144, 32768, NULL, NULL, '{"abilities": {"reasoning": true, "vision": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "config": {"deploymentName": "qwen3-vl-flash-2025-10-15"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 0.15, "[0.032, 0.128]": 0.3, "[0.128, 0.256]": 0.6}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 1.5, "[0.032, 0.128]": 3, "[0.128, 0.256]": 6}, "pricingParams": ["textInputRange"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-10-15", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "Qwen3 VL Flash：轻量化高速推理版本，适合对延迟敏感或大批量请求场景。", "organization": "Qwen", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'deepseek-v3.2-exp', 'DeepSeek V3.2 Exp', 'chat', 131072, 65536, 0.002, 0.003, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "deepseek-v3.2-exp 引入稀疏注意力机制，旨在提升处理长文本时的训练与推理效率，价格低于 deepseek-v3.1。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'deepseek-v3.1', 'DeepSeek V3.1', 'chat', 131072, 65536, 0.004, 0.012, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "DeepSeek V3.1 模型为混合推理架构模型，同时支持思考模式与非思考模式。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'Moonshot-Kimi-K2-Instruct', 'Kimi K2 Instruct', 'chat', 131072, 8192, 0.004, 0.016, '{"abilities": {"search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-17", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "总参数 1T，激活参数 32B。 非思维模型中，在前沿知识、数学和编码方面达到了顶尖水平，更擅长通用 Agent 任务。 针对代理任务进行了精心优化，不仅能回答问题，还能采取行动。 最适用于即兴、通用聊天和代理体验，是一款无需长时间思考的反射级模型。", "organization": "Qwen", "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'glm-4.5', 'GLM-4.5', 'chat', 131072, 16384, NULL, NULL, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 3, "[0.032, infinity]": 4}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 14, "[0.032, infinity]": 16}, "pricingParams": ["textInputRange"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "GLM-4.5系列模型是智谱AI专为智能体设计的混合推理模型，提供思考与非思考两种模式。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'glm-4.5-air', 'GLM-4.5-Air', 'chat', 131072, 16384, NULL, NULL, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 0.8, "[0.032, infinity]": 1.2}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 6, "[0.032, infinity]": 8}, "pricingParams": ["textInputRange"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "GLM-4.5系列模型是智谱AI专为智能体设计的混合推理模型，提供思考与非思考两种模式。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-coder-plus', 'Qwen3 Coder Plus', 'chat', 1000000, 65536, NULL, NULL, '{"abilities": {"functionCall": true}, "config": {"deploymentName": "qwen3-coder-plus"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 0.8, "[0.032, 0.128]": 1.2000000000000002, "[0.128, 0.256]": 2, "[0.256, infinity]": 4}, "pricingParams": ["textInputRange"]}, "name": "textInput_cacheRead", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 4, "[0.032, 0.128]": 6, "[0.128, 0.256]": 10, "[0.256, infinity]": 20}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 16, "[0.032, 0.128]": 24, "[0.128, 0.256]": 40, "[0.256, infinity]": 200}, "pricingParams": ["textInputRange"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "通义千问代码模型。最新的 Qwen3-Coder 系列模型是基于 Qwen3 的代码生成模型，具有强大的Coding Agent能力，擅长工具调用和环境交互，能够实现自主编程，代码能力卓越的同时兼具通用能力。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-coder-flash', 'Qwen3 Coder Flash', 'chat', 1000000, 65536, NULL, NULL, '{"abilities": {"functionCall": true}, "config": {"deploymentName": "qwen3-coder-flash"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 0.2, "[0.032, 0.128]": 0.3, "[0.128, 0.256]": 0.5, "[0.256, 1]": 1}, "pricingParams": ["textInputRange"]}, "name": "textInput_cacheRead", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 1, "[0.032, 0.128]": 1.5, "[0.128, 0.256]": 2.5, "[0.256, 1]": 5}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 4, "[0.032, 0.128]": 6, "[0.128, 0.256]": 10, "[0.256, 1]": 25}, "pricingParams": ["textInputRange"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "通义千问代码模型。最新的 Qwen3-Coder 系列模型是基于 Qwen3 的代码生成模型，具有强大的Coding Agent能力，擅长工具调用和环境交互，能够实现自主编程，代码能力卓越的同时兼具通用能力。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-coder-480b-a35b-instruct', 'Qwen3 Coder 480B A35B', 'chat', 262144, 65536, NULL, NULL, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 6, "[0.032, 0.128]": 9, "[0.128, 0.2]": 15}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 24, "[0.032, 0.128]": 36, "[0.128, 0.2]": 60}, "pricingParams": ["textInputRange"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "通义千问代码模型开源版。最新的 qwen3-coder-480b-a35b-instruct 是基于 Qwen3 的代码生成模型，具有强大的Coding Agent能力，擅长工具调用和环境交互，能够实现自主编程、代码能力卓越的同时兼具通用能力。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-coder-30b-a3b-instruct', 'Qwen3 Coder 30B A3B', 'chat', 262144, 65536, NULL, NULL, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 1.5, "[0.032, 0.128]": 2.25, "[0.128, 0.2]": 3.75}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 6, "[0.032, 0.128]": 9, "[0.128, 0.2]": 15}, "pricingParams": ["textInputRange"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "通义千问代码模型开源版。最新的 qwen3-coder-30b-a3b-instruct 是基于 Qwen3 的代码生成模型，具有强大的Coding Agent能力，擅长工具调用和环境交互，能够实现自主编程、代码能力卓越的同时兼具通用能力。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-235b-a22b-thinking-2507', 'Qwen3 235B A22B Thinking 2507', 'chat', 131072, 32768, 0.002, 0.02, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-25", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "基于Qwen3的思考模式开源模型，相较上一版本（通义千问3-235B-A22B）逻辑能力、通用能力、知识增强及创作能力均有大幅提升，适用于高难度强推理场景。", "organization": "Qwen", "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-235b-a22b-instruct-2507', 'Qwen3 235B A22B Instruct 2507', 'chat', 131072, 32768, 0.002, 0.008, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-22", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "基于Qwen3的非思考模式开源模型，相较上一版本（通义千问3-235B-A22B）主观创作能力与模型安全性均有小幅度提升。", "organization": "Qwen", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-30b-a3b-thinking-2507', 'Qwen3 30B A3B Thinking 2507', 'chat', 131072, 32768, 0.00075, 0.0075, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 7.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-30", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "基于Qwen3的思考模式开源模型，相较上一版本（通义千问3-30B-A3B）逻辑能力、通用能力、知识增强及创作能力均有大幅提升，适用于高难度强推理场景。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-30b-a3b-instruct-2507', 'Qwen3 30B A3B Instruct 2507', 'chat', 131072, 32768, 0.00075, 0.003, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-29", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "相较上一版本（Qwen3-30B-A3B）中英文和多语言整体通用能力有大幅提升。主观开放类任务专项优化，显著更加符合用户偏好，能够提供更有帮助性的回复。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-next-80b-a3b-thinking', 'Qwen3 Next 80B A3B Thinking', 'chat', 131072, 32768, 0.001, 0.01, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-12", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "基于 Qwen3 的新一代思考模式开源模型，相较上一版本（通义千问3-235B-A22B-Thinking-2507）指令遵循能力有提升、模型总结回复更加精简。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-next-80b-a3b-instruct', 'Qwen3 Next 80B A3B Instruct', 'chat', 131072, 32768, 0.001, 0.004, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-12", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "基于 Qwen3 的新一代非思考模式开源模型，相较上一版本（通义千问3-235B-A22B-Instruct-2507）中文文本理解能力更佳、逻辑推理能力有增强、文本生成类任务表现更好。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-235b-a22b', 'Qwen3 235B A22B', 'chat', 131072, 8192, 0.002, 0.02, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-28", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-32b', 'Qwen3 32B', 'chat', 131072, 8192, 0.002, 0.02, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-28", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-30b-a3b', 'Qwen3 30B A3B', 'chat', 131072, 8192, 0.00075, 0.0075, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 7.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-28", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-14b', 'Qwen3 14B', 'chat', 131072, 8192, 0.001, 0.01, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-28", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-8b', 'Qwen3 8B', 'chat', 131072, 8192, 0.0005, 0.005, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-28", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-4b', 'Qwen3 4B', 'chat', 131072, 8192, 0.0003, 0.003, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-28", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-1.7b', 'Qwen3 1.7B', 'chat', 32768, 8192, 0.0003, 0.003, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-28", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-0.6b', 'Qwen3 0.6B', 'chat', 32768, 8192, 0.0003, 0.003, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-28", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwq-plus', 'QwQ Plus', 'chat', 131072, 8192, 0.0016, 0.004, '{"abilities": {"functionCall": true, "reasoning": true, "search": true}, "settings": {"searchImpl": "params"}, "config": {"deploymentName": "qwq-plus-2025-03-05"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-05", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "基于 Qwen2.5 模型训练的 QwQ 推理模型，通过强化学习大幅度提升了模型推理能力。模型数学代码等核心指标（AIME 24/25、LiveCodeBench）以及部分通用指标（IFEval、LiveBench等）达到DeepSeek-R1 满血版水平。", "organization": "Qwen", "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-flash', 'Qwen Flash', 'chat', 1000000, 32768, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "search": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "config": {"deploymentName": "qwen-flash"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "strategy": "tiered", "tiers": [{"rate": 0.15, "upTo": 0.128}, {"rate": 0.6, "upTo": 0.256}, {"rate": 1.2, "upTo": "infinity"}], "unit": "millionTokens"}, {"name": "textOutput", "strategy": "tiered", "tiers": [{"rate": 1.5, "upTo": 0.128}, {"rate": 6, "upTo": 0.256}, {"rate": 12, "upTo": "infinity"}], "unit": "millionTokens"}, {"name": "textInput_cacheRead", "strategy": "tiered", "tiers": [{"rate": 0.03, "upTo": 0.128}, {"rate": 0.12, "upTo": 0.256}, {"rate": 0.24, "upTo": "infinity"}], "unit": "millionTokens"}]}, "released_at": "2025-07-28", "source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "通义千问系列速度最快、成本极低的模型，适合简单任务。", "organization": "Qwen", "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-turbo', 'Qwen Turbo', 'chat', 1000000, 16384, 0.0003, 0.003, '{"abilities": {"functionCall": true, "reasoning": true, "search": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "config": {"deploymentName": "qwen-turbo-2025-07-15"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput_cacheRead", "rate": 0.06, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-15", "source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "通义千问 Turbo 后续不再更新，建议替换为通义千问 Flash 。通义千问超大规模语言模型，支持中文、英文等不同语言输入。", "organization": "Qwen", "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-plus', 'Qwen Plus', 'chat', 1000000, 32768, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "search": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"], "searchImpl": "params"}, "config": {"deploymentName": "qwen-plus-2025-09-11"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.128]": 0.16000000000000003, "[0.128, 0.256]": 0.48, "[0.256, infinity]": 0.96}, "pricingParams": ["textInputRange"]}, "name": "textInput_cacheRead", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.128]": 0.8, "[0.128, 0.256]": 2.4, "[0.256, infinity]": 4.8}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.128]_[false]": 2, "[0, 0.128]_[true]": 8, "[0.128, 0.256]_[false]": 20, "[0.128, 0.256]_[true]": 24, "[0.256, infinity]_[false]": 48, "[0.256, infinity]_[true]": 64}, "pricingParams": ["textInputRange", "thinkingMode"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "通义千问超大规模语言模型增强版，支持中文、英文等不同语言输入。", "organization": "Qwen", "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-max', 'Qwen3 Max', 'chat', 262144, 65536, NULL, NULL, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "config": {"deploymentName": "qwen3-max"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 1.2000000000000002, "[0.032, 0.128]": 2, "[0.128, infinity]": 3}, "pricingParams": ["textInputRange"]}, "name": "textInput_cacheRead", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 6, "[0.032, 0.128]": 10, "[0.128, infinity]": 15}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 24, "[0.032, 0.128]": 40, "[0.128, infinity]": 60}, "pricingParams": ["textInputRange"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "released_at": "2025-09-23", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "通义千问3系列Max模型，相较2.5系列整体通用能力有大幅度提升，中英文通用文本理解能力、复杂指令遵循能力、主观开放任务能力、多语言能力、工具调用能力均显著增强；模型知识幻觉更少。最新的qwen3-max模型：相较qwen3-max-preview版本，在智能体编程与工具调用方向进行了专项升级。本次发布的正式版模型达到领域SOTA水平，适配场景更加复杂的智能体需求。", "organization": "Qwen", "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-max', 'Qwen Max', 'chat', 131072, 8192, 0.0024, 0.0096, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "config": {"deploymentName": "qwen-max-2025-01-25"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput_cacheRead", "rate": 0.48, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 2.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问千亿级别超大规模语言模型，支持中文、英文等不同语言输入，当前通义千问2.5产品版本背后的API模型。", "organization": "Qwen", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-long', 'Qwen Long', 'chat', 10000000, 8192, 0.0005, 0.002, '{"abilities": {"functionCall": true}, "config": {"deploymentName": "qwen-long-latest"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 10000000, "contextWindowTokens": 10000000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问超大规模语言模型，支持长文本上下文，以及基于长文档、多文档等多个场景的对话功能。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-omni-flash', 'Qwen Omni Turbo', 'chat', 65536, 16384, 0.0018, 0.0069, '{"abilities": {"vision": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "config": {"deploymentName": "qwen3-omni-flash-2025-09-15"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6.9, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-15", "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "Qwen-Omni 模型能够接收文本、图片、音频、视频等多种模态的组合输入，并生成文本或语音形式的回复， 提供多种拟人音色，支持多语言和方言的语音输出，可应用于文本创作、视觉识别、语音助手等场景。", "organization": "Qwen", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-omni-turbo', 'Qwen Omni Turbo', 'chat', 32768, 2048, 0.0015, 0.0045, '{"abilities": {"vision": true}, "config": {"deploymentName": "qwen-omni-turbo-2025-03-26"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 2048, "maxOutput": 2048, "description": "Qwen-Omni 系列模型支持输入多种模态的数据，包括视频、音频、图片、文本，并输出音频与文本。", "organization": "Qwen", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen2.5-omni-7b', 'Qwen2.5 Omni 7B', 'chat', 32768, 2048, 0.002, 0.006, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 2048, "maxOutput": 2048, "description": "Qwen-Omni 系列模型支持输入多种模态的数据，包括视频、音频、图片、文本，并输出音频与文本。", "organization": "Qwen", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-vl-plus', 'Qwen VL Plus', 'chat', 131072, 8192, 0.0008, 0.002, '{"abilities": {"vision": true}, "config": {"deploymentName": "qwen-vl-plus-2025-08-15"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput_cacheRead", "rate": 0.16000000000000003, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问大规模视觉语言模型增强版。大幅提升细节识别能力和文字识别能力，支持超百万像素分辨率和任意长宽比规格的图像。", "organization": "Qwen", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-vl-max', 'Qwen VL Max', 'chat', 131072, 8192, 0.0016, 0.004, '{"abilities": {"vision": true}, "config": {"deploymentName": "qwen-vl-max-2025-08-13"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput_cacheRead", "rate": 0.32000000000000006, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问超大规模视觉语言模型。相比增强版，再次提升视觉推理能力和指令遵循能力，提供更高的视觉感知和认知水平。", "organization": "Qwen", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-vl-ocr', 'Qwen VL OCR', 'chat', 34096, 4096, 0.005, 0.005, '{"abilities": {"vision": true}, "config": {"deploymentName": "qwen-vl-ocr-2025-04-13"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 34096, "contextWindowTokens": 34096, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "通义千问OCR是文字提取专有模型，专注于文档、表格、试题、手写体文字等类型图像的文字提取能力。它能够识别多种文字，目前支持的语言有：汉语、英语、法语、日语、韩语、德语、俄语、意大利语、越南语、阿拉伯语。", "organization": "Qwen", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-vl-30b-a3b-thinking', 'Qwen3 VL 30B A3B Thinking', 'chat', 131072, 32768, 0.00075, 0.0075, '{"abilities": {"vision": true, "reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 7.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "Qwen-VL（开源版）提供视觉理解与文本生成能力，支持智能体交互、视觉编码、空间感知、长视频理解与深度思考，并在复杂场景下具备更强的文字识别与多语言支持。", "organization": "Qwen", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-vl-30b-a3b-instruct', 'Qwen3 VL 30B A3B Instruct', 'chat', 131072, 32768, 0.00075, 0.003, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "Qwen3 VL 30B 非思考模式（Instruct），面向普通指令跟随场景，保持较高的多模态理解与生成能力。", "organization": "Qwen", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-vl-8b-thinking', 'Qwen3 VL 8B Thinking', 'chat', 131072, 32768, 0.0005, 0.005, '{"abilities": {"vision": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "Qwen3 VL 8B 思考模式，面向轻量级多模态推理与交互场景，保留长上下文理解能力。", "organization": "Qwen", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-vl-8b-instruct', 'Qwen3 VL 8B Instruct', 'chat', 131072, 32768, 0.0005, 0.002, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "Qwen3 VL 8B 非思考模式（Instruct），适合常规多模态生成与识别任务。", "organization": "Qwen", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-vl-235b-a22b-thinking', 'Qwen3 VL 235B A22B Thinking', 'chat', 131072, 32768, 0.002, 0.02, '{"abilities": {"vision": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "Qwen3 VL 235B A22B 思考模式（开源版），针对高难度强推理与长视频理解场景，提供顶尖的视觉+文本推理能力。", "organization": "Qwen", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen3-vl-235b-a22b-instruct', 'Qwen3 VL 235B A22B Instruct', 'chat', 131072, 32768, 0.002, 0.008, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "Qwen3 VL 235B A22B 非思考模式（Instruct），适用于非思考指令场景，保持强大的视觉理解能力。", "organization": "Qwen", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-math-turbo', 'Qwen Math Turbo', 'chat', 4096, 3072, 0.002, 0.006, '{"config": {"deploymentName": "qwen-math-turbo-latest"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "maxOutputTokens": 3072, "maxOutput": 3072, "description": "通义千问数学模型是专门用于数学解题的语言模型。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-math-plus', 'Qwen Math Plus', 'chat', 4096, 3072, 0.004, 0.012, '{"config": {"deploymentName": "qwen-math-plus-latest"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "maxOutputTokens": 3072, "maxOutput": 3072, "description": "通义千问数学模型是专门用于数学解题的语言模型。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-coder-turbo', 'Qwen Coder Turbo', 'chat', 131072, 8192, 0.002, 0.006, '{"config": {"deploymentName": "qwen-coder-turbo-latest"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问代码模型。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-coder-plus', 'Qwen Coder Plus', 'chat', 131072, 8192, 0.0035, 0.007, '{"config": {"deploymentName": "qwen-coder-plus-latest"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 7, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问代码模型。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwq-32b', 'QwQ 32B', 'chat', 131072, 8192, 0.002, 0.006, '{"abilities": {"reasoning": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-06", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "基于 Qwen2.5-32B 模型训练的 QwQ 推理模型，通过强化学习大幅度提升了模型推理能力。模型数学代码等核心指标（AIME 24/25、LiveCodeBench）以及部分通用指标（IFEval、LiveBench等）达到DeepSeek-R1 满血版水平，各指标均显著超过同样基于 Qwen2.5-32B 的 DeepSeek-R1-Distill-Qwen-32B。", "organization": "Qwen", "reasoning": true, "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwq-32b-preview', 'QwQ 32B Preview', 'chat', 32768, 16384, 0.002, 0.006, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-11-28", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "QwQ模型是由 Qwen 团队开发的实验性研究模型，专注于增强 AI 推理能力。", "organization": "Qwen", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qvq-max', 'QVQ Max', 'chat', 131072, 8192, 0.008, 0.032, '{"abilities": {"reasoning": true, "vision": true}, "config": {"deploymentName": "qvq-max-2025-05-15"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 32, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-05-15", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问QVQ视觉推理模型，支持视觉输入及思维链输出，在数学、编程、视觉分析、创作以及通用任务上都表现了更强的能力。", "organization": "Qwen", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qvq-plus', 'QVQ Plus', 'chat', 131072, 8192, 0.002, 0.005, '{"abilities": {"reasoning": true, "vision": true}, "config": {"deploymentName": "qvq-plus-2025-05-15"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-05-15", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "视觉推理模型。支持视觉输入及思维链输出，继qvq-max模型后推出的plus版本，相较于qvq-max模型，qvq-plus系列模型推理速度更快，效果和成本更均衡。", "organization": "Qwen", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qvq-72b-preview', 'QVQ 72B Preview', 'chat', 32768, 16384, 0.012, 0.036, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 36, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-12-25", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "QVQ模型是由 Qwen 团队开发的实验性研究模型，专注于提升视觉推理能力，尤其在数学推理领域。", "organization": "Qwen", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen2.5-7b-instruct', 'Qwen2.5 7B', 'chat', 131072, 8192, 0.0005, 0.001, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问2.5对外开源的7B规模的模型。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen2.5-14b-instruct', 'Qwen2.5 14B', 'chat', 131072, 8192, 0.001, 0.003, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问2.5对外开源的14B规模的模型。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen2.5-32b-instruct', 'Qwen2.5 32B', 'chat', 131072, 8192, 0.002, 0.006, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问2.5对外开源的32B规模的模型。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen2.5-72b-instruct', 'Qwen2.5 72B', 'chat', 131072, 8192, 0.004, 0.012, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问2.5对外开源的72B规模的模型。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen2.5-14b-instruct-1m', 'Qwen2.5 14B 1M', 'chat', 1000000, 8192, 0.001, 0.003, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-27", "source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问2.5对外开源的72B规模的模型。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen2.5-math-7b-instruct', 'Qwen2.5 Math 7B', 'chat', 4096, 3072, 0.001, 0.002, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "maxOutputTokens": 3072, "maxOutput": 3072, "description": "Qwen-Math 模型具有强大的数学解题能力。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen2.5-math-72b-instruct', 'Qwen2.5 Math 72B', 'chat', 4096, 3072, 0.004, 0.012, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-23", "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "maxOutputTokens": 3072, "maxOutput": 3072, "description": "Qwen-Math 模型具有强大的数学解题能力。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen2.5-coder-7b-instruct', 'Qwen2.5 Coder 7B', 'chat', 131072, 8192, 0.001, 0.002, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问代码模型开源版。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen2.5-coder-14b-instruct', 'Qwen2.5 Coder 14B', 'chat', 131072, 8192, 0.002, 0.006, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问代码模型开源版。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen2.5-coder-32b-instruct', 'Qwen2.5 Coder 32B', 'chat', 131072, 8192, 0.002, 0.006, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "通义千问代码模型开源版。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen2.5-vl-72b-instruct', 'Qwen2.5 VL 72B', 'chat', 131072, 8192, 0.016, 0.048, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 48, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-27", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "指令跟随、数学、解题、代码整体提升，万物识别能力提升，支持多样格式直接精准定位视觉元素，支持对长视频文件（最长10分钟）进行理解和秒级别的事件时刻定位，能理解时间先后和快慢，基于解析和定位能力支持操控OS或Mobile的Agent，关键信息抽取能力和Json格式输出能力强，此版本为72B版本，本系列能力最强的版本。", "organization": "Qwen", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen2.5-vl-32b-instruct', 'Qwen2.5 VL 32B', 'chat', 131072, 8192, 0.008, 0.024, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 24, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-24", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Qwen2.5VL系列模型，在math和学科问题解答达到了接近Qwen2.5VL-72B的水平，回复风格面向人类偏好进行大幅调整，尤其是数学、逻辑推理、知识问答等客观类query，模型回复详实程度和格式清晰度明显改善。此版本为32B版本。", "organization": "Qwen", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen2.5-vl-7b-instruct', 'Qwen2.5 VL 7B', 'chat', 131072, 8192, 0.002, 0.005, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-27", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "指令跟随、数学、解题、代码整体提升，万物识别能力提升，支持多样格式直接精准定位视觉元素，支持对长视频文件（最长10分钟）进行理解和秒级别的事件时刻定位，能理解时间先后和快慢，基于解析和定位能力支持操控OS或Mobile的Agent，关键信息抽取能力和Json格式输出能力强，此版本为72B版本，本系列能力最强的版本。", "organization": "Qwen", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'deepseek-r1-0528', 'DeepSeek R1 0528', 'chat', 131072, 16384, 0.004, 0.016, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-05-28", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "685B 满血版模型，2025年5月28日发布。DeepSeek-R1 在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能较高，能力较强。", "organization": "DeepSeek", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'deepseek-v3', 'DeepSeek V3', 'chat', 65536, 8192, 0.002, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-27", "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "DeepSeek-V3 为自研 MoE 模型，671B 参数，激活 37B，在 14.8T token 上进行了预训练，在长文本、代码、数学、百科、中文能力上表现优秀。", "organization": "DeepSeek"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'deepseek-r1-distill-qwen-1.5b', 'DeepSeek R1 Distill Qwen 1.5B', 'chat', 32768, 16384, 0, 0, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "DeepSeek-R1-Distill-Qwen-1.5B 是一个基于 Qwen2.5-Math-1.5B 的蒸馏大型语言模型，使用了 DeepSeek R1 的输出。", "organization": "DeepSeek", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'deepseek-r1-distill-qwen-7b', 'DeepSeek R1 Distill Qwen 7B', 'chat', 32768, 16384, 0.0005, 0.001, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "DeepSeek-R1-Distill-Qwen-7B 是一个基于 Qwen2.5-Math-7B 的蒸馏大型语言模型，使用了 DeepSeek R1 的输出。", "organization": "DeepSeek", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'deepseek-r1-distill-qwen-14b', 'DeepSeek R1 Distill Qwen 14B', 'chat', 32768, 16384, 0.001, 0.003, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "DeepSeek-R1-Distill-Qwen-14B 是一个基于 Qwen2.5-14B 的蒸馏大型语言模型，使用了 DeepSeek R1 的输出。", "organization": "DeepSeek", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'deepseek-r1-distill-qwen-32b', 'DeepSeek R1 Distill Qwen 32B', 'chat', 32768, 16384, 0.002, 0.006, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "DeepSeek-R1-Distill-Qwen-32B 是一个基于 Qwen2.5-32B 的蒸馏大型语言模型，使用了 DeepSeek R1 的输出。", "organization": "DeepSeek", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'deepseek-r1-distill-llama-8b', 'DeepSeek R1 Distill Llama 8B', 'chat', 32768, 16384, 0, 0, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "DeepSeek-R1-Distill-Llama-8B 是一个基于 Llama-3.1-8B 的蒸馏大型语言模型，使用了 DeepSeek R1 的输出。", "organization": "DeepSeek", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'deepseek-r1-distill-llama-70b', 'DeepSeek R1 Distill Llama 70B', 'chat', 32768, 16384, 0, 0, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "DeepSeek-R1-Distill-Llama-70B 是一个基于 Llama-3.3-70B-Instruct 的蒸馏大型语言模型，使用了 DeepSeek R1 的输出。", "organization": "DeepSeek", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-image-edit', 'Qwen Image Edit', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0.3, "strategy": "fixed", "unit": "image"}]}, "parameters": {"imageUrl": {"default": ""}, "prompt": {"default": ""}, "seed": {"default": null}}, "released_at": "2025-09-18", "source": "builtin", "description": "Qwen Image Edit 是一款图生图模型，支持基于输入图像和文本提示进行图像编辑和修改，能够根据用户需求对原图进行精准调整和创意改造。", "organization": "Qwen"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'qwen-image', 'Qwen Image', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0.25, "strategy": "fixed", "unit": "image"}]}, "parameters": {"prompt": {"default": ""}, "seed": {"default": null}, "size": {"default": "1328x1328", "enum": ["1664x928", "1472x1140", "1328x1328", "1140x1472", "928x1664"]}}, "released_at": "2025-08-13", "source": "builtin", "description": "Qwen-Image 是一款通用图像生成模型，支持多种艺术风格，尤其擅长复杂文本渲染，特别是中英文文本渲染。模型支持多行布局、段落级文本生成以及细粒度细节刻画，可实现复杂的图文混合布局设计。", "organization": "Qwen"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'wan2.2-t2i-flash', 'Wanxiang2.2 T2I Flash', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0.14, "strategy": "fixed", "unit": "image"}]}, "parameters": {"height": {"default": 1024, "max": 1440, "min": 512, "step": 1}, "prompt": {"default": ""}, "seed": {"default": null}, "width": {"default": 1024, "max": 1440, "min": 512, "step": 1}}, "released_at": "2025-07-28", "source": "builtin", "description": "万相2.2极速版，当前最新模型。在创意性、稳定性、写实质感上全面升级，生成速度快，性价比高。", "organization": "Qwen"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'wan2.2-t2i-plus', 'Wanxiang2.2 T2I Plus', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0.2, "strategy": "fixed", "unit": "image"}]}, "parameters": {"height": {"default": 1024, "max": 1440, "min": 512, "step": 1}, "prompt": {"default": ""}, "seed": {"default": null}, "width": {"default": 1024, "max": 1440, "min": 512, "step": 1}}, "released_at": "2025-07-28", "source": "builtin", "description": "万相2.2专业版，当前最新模型。在创意性、稳定性、写实质感上全面升级，生成细节丰富。", "organization": "Qwen"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'wanx2.1-t2i-turbo', 'Wanxiang2.1 T2I Turbo', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0.14, "strategy": "fixed", "unit": "image"}]}, "parameters": {"height": {"default": 1024, "max": 1440, "min": 512, "step": 1}, "prompt": {"default": ""}, "seed": {"default": null}, "width": {"default": 1024, "max": 1440, "min": 512, "step": 1}}, "released_at": "2025-01-08", "source": "builtin", "description": "全面升级版本。生成速度快、效果全面、综合性价比高。对应通义万相官网2.1极速模型。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'wanx2.1-t2i-plus', 'Wanxiang2.1 T2I Plus', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0.2, "strategy": "fixed", "unit": "image"}]}, "parameters": {"height": {"default": 1024, "max": 1440, "min": 512, "step": 1}, "prompt": {"default": ""}, "seed": {"default": null}, "width": {"default": 1024, "max": 1440, "min": 512, "step": 1}}, "released_at": "2025-01-08", "source": "builtin", "description": "全面升级版本。生成图像细节更丰富，速度稍慢。对应通义万相官网2.1专业模型。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'wanx2.0-t2i-turbo', 'Wanxiang2.0 T2I Turbo', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0.04, "strategy": "fixed", "unit": "image"}]}, "parameters": {"height": {"default": 1024, "max": 1440, "min": 512, "step": 1}, "prompt": {"default": ""}, "seed": {"default": null}, "width": {"default": 1024, "max": 1440, "min": 512, "step": 1}}, "released_at": "2025-01-17", "source": "builtin", "description": "擅长质感人像，速度中等、成本较低。对应通义万相官网2.0极速模型。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'wanx-v1', 'Wanxiang v1', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0.16, "strategy": "fixed", "unit": "image"}]}, "parameters": {"height": {"default": 1024, "max": 1440, "min": 512, "step": 1}, "prompt": {"default": ""}, "seed": {"default": null}, "width": {"default": 1024, "max": 1440, "min": 512, "step": 1}}, "released_at": "2024-05-22", "source": "builtin", "description": "基础文生图模型。对应通义万相官网1.0通用模型。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'flux-schnell', 'FLUX.1 [schnell]', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0, "strategy": "fixed", "unit": "image"}]}, "parameters": {"prompt": {"default": ""}, "seed": {"default": null}, "size": {"default": "1024x1024", "enum": ["512x1024", "768x512", "768x1024", "1024x576", "576x1024", "1024x1024"]}, "steps": {"default": 4, "max": 12, "min": 1}}, "released_at": "2024-08-07", "source": "builtin", "description": "FLUX.1 [schnell] 作为目前开源最先进的少步模型，不仅超越了同类竞争者，甚至还优于诸如 Midjourney v6.0 和 DALL·E 3 (HD) 等强大的非精馏模型。该模型经过专门微调，以保留预训练阶段的全部输出多样性，相较于当前市场上的最先进模型，FLUX.1 [schnell] 显著提升了在视觉质量、指令遵从、尺寸/比例变化、字体处理及输出多样性等方面的可能，为用户带来更为丰富多样的创意图像生成体验。", "organization": "Qwen"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'flux-dev', 'FLUX.1 [dev]', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0, "strategy": "fixed", "unit": "image"}]}, "parameters": {"prompt": {"default": ""}, "seed": {"default": null}, "size": {"default": "1024x1024", "enum": ["512x1024", "768x512", "768x1024", "1024x576", "576x1024", "1024x1024"]}, "steps": {"default": 50, "max": 50, "min": 1}}, "released_at": "2024-08-07", "source": "builtin", "description": "FLUX.1 [dev] 是一款面向非商业应用的开源权重、精炼模型。FLUX.1 [dev] 在保持了与FLUX专业版相近的图像质量和指令遵循能力的同时，具备更高的运行效率。相较于同尺寸的标准模型，它在资源利用上更为高效。", "organization": "Qwen"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'flux-merged', 'FLUX.1-merged', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0, "strategy": "fixed", "unit": "image"}]}, "parameters": {"prompt": {"default": ""}, "seed": {"default": null}, "size": {"default": "1024x1024", "enum": ["512x1024", "768x512", "768x1024", "1024x576", "576x1024", "1024x1024"]}, "steps": {"default": 30, "max": 30, "min": 1}}, "released_at": "2024-08-22", "source": "builtin", "description": "FLUX.1-merged 模型结合了 \"DEV\" 在开发阶段探索的深度特性和 \"Schnell\" 所代表的高速执行优势。通过这一举措，FLUX.1-merged 不仅提升了模型的性能界限，还拓宽了其应用范围。", "organization": "Qwen"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'stable-diffusion-3.5-large', 'StableDiffusion 3.5 Large', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0, "strategy": "fixed", "unit": "image"}]}, "parameters": {"height": {"default": 1024, "max": 1024, "min": 512, "step": 128}, "prompt": {"default": ""}, "steps": {"default": 40, "max": 500, "min": 1}, "width": {"default": 1024, "max": 1024, "min": 512, "step": 128}}, "released_at": "2024-10-25", "source": "builtin", "description": "stable-diffusion-3.5-large 是一个具有8亿参数的多模态扩散变压器（MMDiT）文本到图像生成模型，具备卓越的图像质量和提示词匹配度，支持生成 100 万像素的高分辨率图像，且能够在普通消费级硬件上高效运行。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'stable-diffusion-3.5-large-turbo', 'StableDiffusion 3.5 Large Turbo', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0, "strategy": "fixed", "unit": "image"}]}, "parameters": {"height": {"default": 1024, "max": 1024, "min": 512, "step": 128}, "prompt": {"default": ""}, "steps": {"default": 40, "max": 500, "min": 1}, "width": {"default": 1024, "max": 1024, "min": 512, "step": 128}}, "released_at": "2024-10-25", "source": "builtin", "description": "stable-diffusion-3.5-large-turbo 是在 stable-diffusion-3.5-large 的基础上采用对抗性扩散蒸馏（ADD）技术的模型，具备更快的速度。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'stable-diffusion-xl', 'StableDiffusion xl', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0, "strategy": "fixed", "unit": "image"}]}, "parameters": {"height": {"default": 1024, "max": 1024, "min": 512, "step": 128}, "prompt": {"default": ""}, "steps": {"default": 50, "max": 500, "min": 1}, "width": {"default": 1024, "max": 1024, "min": 512, "step": 128}}, "released_at": "2024-04-09", "source": "builtin", "description": "stable-diffusion-xl 相比于 v1.5 做了重大的改进，并且与当前开源的文生图 SOTA 模型 midjourney 效果相当。具体改进之处包括： 更大的 unet backbone，是之前的 3 倍； 增加了 refinement 模块用于改善生成图片的质量；更高效的训练技巧等。", "organization": "Qwen"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'qwen'), 'stable-diffusion-v1.5', 'StableDiffusion v1.5', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0, "strategy": "fixed", "unit": "image"}]}, "parameters": {"height": {"default": 512, "max": 1024, "min": 512, "step": 128}, "prompt": {"default": ""}, "steps": {"default": 50, "max": 500, "min": 1}, "width": {"default": 512, "max": 1024, "min": 512, "step": 128}}, "released_at": "2024-04-09", "source": "builtin", "description": "stable-diffusion-v1.5 是以 stable-diffusion-v1.2 检查点的权重进行初始化，并在 \"laion-aesthetics v2 5+\" 上以 512x512 的分辨率进行了595k步的微调，减少了 10% 的文本条件化，以提高无分类器的引导采样。", "organization": "Qwen"}', FALSE),
    -- sambanova
    ((SELECT id FROM ai_providers WHERE code = 'sambanova'), 'Meta-Llama-3.3-70B-Instruct', 'Meta Llama 3.3 70B Instruct', 'chat', 16000, NULL, 0.0006, 0.0012, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "description": "Llama 3.3 是 Llama 系列最先进的多语言开源大型语言模型，以极低成本体验媲美 405B 模型的性能。基于 Transformer 结构，并通过监督微调（SFT）和人类反馈强化学习（RLHF）提升有用性和安全性。其指令调优版本专为多语言对话优化，在多项行业基准上表现优于众多开源和封闭聊天模型。知识截止日期为 2023 年 12 月", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'sambanova'), 'Meta-Llama-3.2-1B-Instruct', 'Meta Llama 3.2 1B Instruct', 'chat', 16000, NULL, 0.00004, 0.00008, '{"pricing": {"units": [{"name": "textInput", "rate": 0.04, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.08, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "description": "先进的最尖端小型语言模型，具备语言理解、卓越的推理能力和文本生成能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sambanova'), 'Meta-Llama-3.2-3B-Instruct', 'Meta Llama 3.2 3B Instruct', 'chat', 8000, NULL, 0.00008, 0.00016, '{"pricing": {"units": [{"name": "textInput", "rate": 0.08, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "先进的最尖端小型语言模型，具备语言理解、卓越的推理能力和文本生成能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sambanova'), 'Llama-3.2-11B-Vision-Instruct', 'Meta Llama 3.2 11B Vision Instruct', 'chat', 4000, NULL, 0.00015, 0.0003, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4000, "contextWindowTokens": 4000, "description": "在高分辨率图像上表现出色的图像推理能力，适用于视觉理解应用。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'sambanova'), 'Llama-3.2-90B-Vision-Instruct	', 'Meta Llama 3.2 90B Vision Instruct', 'chat', 4000, NULL, 0.0008, 0.0016, '{"abilities": {"vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4000, "contextWindowTokens": 4000, "description": "适用于视觉理解代理应用的高级图像推理能力。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'sambanova'), 'Meta-Llama-3.1-8B-Instruct', 'Meta Llama 3.1 8B Instruct', 'chat', 16000, NULL, 0.0001, 0.0002, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "description": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sambanova'), 'Meta-Llama-3.1-70B-Instruct', 'Meta Llama 3.1 70B Instruct', 'chat', 128000, NULL, 0.0006, 0.0012, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sambanova'), 'Meta-Llama-3.1-405B-Instruct', 'Meta Llama 3.1 405B Instruct', 'chat', 16000, NULL, 0.005, 0.01, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "description": "Llama 3.1指令调优的文本模型，针对多语言对话用例进行了优化，在许多可用的开源和封闭聊天模型中，在常见行业基准上表现优异。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sambanova'), 'Llama-3.1-Tulu-3-405B', 'Llama 3.1 Tulu 3 405B', 'chat', 16000, NULL, 0.0007, 0.0014, '{"pricing": {"units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sambanova'), 'DeepSeek-R1', 'DeepSeek R1', 'chat', 4000, NULL, 0.005, 0.007, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 7, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4000, "contextWindowTokens": 4000, "description": "最先进的高效 LLM，擅长推理、数学和编程。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sambanova'), 'DeepSeek-R1-Distill-Llama-70B', 'DeepSeek R1 Distill Llama 70B', 'chat', 32000, NULL, 0.0007, 0.0014, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "DeepSeek R1——DeepSeek 套件中更大更智能的模型——被蒸馏到 Llama 70B 架构中。基于基准测试和人工评估，该模型比原始 Llama 70B 更智能，尤其在需要数学和事实精确性的任务上表现出色。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'sambanova'), 'QwQ-32B-Preview', 'QwQ 32B Preview', 'chat', 16000, NULL, 0.0015, 0.003, '{"abilities": {"reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "description": "Qwen QwQ 是由 Qwen 团队开发的实验研究模型，专注于提升AI推理能力。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'sambanova'), 'Qwen2.5-72B-Instruct', 'Qwen2.5 72B Instruct', 'chat', 16000, NULL, 0.002, 0.004, '{"pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "description": "面向中文和英文的 LLM，针对语言、编程、数学、推理等领域。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'sambanova'), 'Qwen2.5-Coder-32B-Instruct', 'Qwen2.5 Coder 32B Instruct', 'chat', 16000, NULL, 0.0015, 0.003, '{"pricing": {"units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "description": "高级 LLM，支持代码生成、推理和修复，涵盖主流编程语言。"}', TRUE),
    -- search1api
    ((SELECT id FROM ai_providers WHERE code = 'search1api'), 'deepseek-r1-70b-online', 'DeepSeek R1 70B', 'chat', 131072, 16384, NULL, NULL, '{"abilities": {"reasoning": true, "search": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "DeepSeek R1 70B 标准版，支持实时联网搜索，适合需要最新信息的对话和文本处理任务。", "reasoning": true, "web_search": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'search1api'), 'deepseek-r1-online', 'DeepSeek R1', 'chat', 65536, 8192, NULL, NULL, '{"abilities": {"reasoning": true, "search": true}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "DeepSeek R1 满血版，拥有 671B 参数，支持实时联网搜索，具有更强大的理解和生成能力。", "reasoning": true, "web_search": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'search1api'), 'deepseek-r1-70b-fast-online', 'DeepSeek R1 70B Fast', 'chat', 131072, 16384, NULL, NULL, '{"abilities": {"reasoning": true, "search": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "DeepSeek R1 70B 快速版，支持实时联网搜索，在保持模型性能的同时提供更快的响应速度。", "reasoning": true, "web_search": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'search1api'), 'deepseek-r1-fast-online', 'DeepSeek R1 Fast', 'chat', 163840, 16384, NULL, NULL, '{"abilities": {"reasoning": true, "search": true}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "DeepSeek R1 满血快速版，支持实时联网搜索，结合了 671B 参数的强大能力和更快的响应速度。", "reasoning": true, "web_search": true}', TRUE),
    -- sensenova
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseNova-V6-5-Pro', 'SenseNova V6.5 Pro', 'chat', 131072, NULL, 0.003, 0.009, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-23", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "通过对多模态、语言及推理数据的全面更新与训练策略的优化，新模型在多模态推理和泛化指令跟随能力上实现了显著提升，支持高达128k的上下文窗口，并在OCR与文旅IP识别等专项任务中表现卓越。", "vision": true, "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseNova-V6-5-Turbo', 'SenseNova V6.5 Turbo', 'chat', 131072, NULL, 0.0015, 0.0045, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-23", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "通过对多模态、语言及推理数据的全面更新与训练策略的优化，新模型在多模态推理和泛化指令跟随能力上实现了显著提升，支持高达128k的上下文窗口，并在OCR与文旅IP识别等专项任务中表现卓越。", "vision": true, "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'Qwen3-235B', 'Qwen3 235B A22B', 'chat', 32768, NULL, 0, 0, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["enableReasoning"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-05-27", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen3-235B-A22B，MoE（混合专家模型）模型,引入了“混合推理模式”，支持用户在“思考模式”和“非思考模式”之间无缝切换，支持119种语言和方言理解与推理，并具备强大的工具调用能力，在综合能力、代码与数学、多语言能力、知识与推理等多项基准测试中，都能与DeepSeek R1、OpenAI o1、o3-mini、Grok 3和谷歌Gemini 2.5 Pro等目前市场上的主流大模型竞争。", "organization": "Qwen", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'Qwen3-32B', 'Qwen3 32B', 'chat', 32768, NULL, 0, 0, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["enableReasoning"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-05-27", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen3-32B，稠密模型（Dense Model）,引入了“混合推理模式”，支持用户在“思考模式”和“非思考模式”之间无缝切换，由于模型架构改进、训练数据增加以及更有效的训练方法，整体性能与Qwen2.5-72B表现相当。", "organization": "Qwen", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseNova-V6-Reasoner', 'SenseNova V6 Reasoner', 'chat', 32768, NULL, 0.004, 0.016, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "兼顾视觉、语言深度推理，实现慢思考和深度推理，呈现完整的思维链过程。", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseNova-V6-Turbo', 'SenseNova V6 Turbo', 'chat', 32768, NULL, 0.0015, 0.0045, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "实现图片、文本、视频能力的原生统一，突破传统多模态分立局限，在多模基础能力、语言基础能力等核心维度全面领先，文理兼修，在多项测评中多次位列国内外第一梯队水平。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseNova-V6-Pro', 'SenseNova V6 Pro', 'chat', 32768, NULL, 0.003, 0.009, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "实现图片、文本、视频能力的原生统一，突破传统多模态分立局限，在OpenCompass和SuperCLUE评测中斩获双冠军。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseChat-5-beta', 'SenseChat 5.5 Beta', 'chat', 32768, NULL, 0.008, 0.02, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "部分性能优于 SenseCat-5-1202"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseChat-5-1202', 'SenseChat 5.5 1202', 'chat', 32768, NULL, 0.008, 0.02, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-12-30", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "是基于V5.5的最新版本，较上版本在中英文基础能力，聊天，理科知识， 文科知识，写作，数理逻辑，字数控制 等几个维度的表现有显著提升。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseChat-Turbo-1202', 'SenseChat Turbo 1202', 'chat', 32768, NULL, 0.0003, 0.0006, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-12-30", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "是最新的轻量版本模型，达到全量模型90%以上能力，显著降低推理成本。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseChat-5', 'SenseChat 5.5', 'chat', 131072, 131072, 0.008, 0.02, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 131072, "maxOutput": 131072, "description": "最新版本模型 (V5.5)，128K上下文长度，在数学推理、英文对话、指令跟随以及长文本理解等领域能力显著提升，比肩GPT-4o。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseChat-Vision', 'SenseChat 5.5 Vision', 'chat', 16384, 16384, 0.01, 0.06, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-12", "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "最新版本模型 (V5.5)，支持多图的输入，全面实现模型基础能力优化，在对象属性识别、空间关系、动作事件识别、场景理解、情感识别、逻辑常识推理和文本理解生成上都实现了较大提升。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseChat-Turbo', 'SenseChat 5.0 Turbo', 'chat', 32768, 32768, 0.0003, 0.0006, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "适用于快速问答、模型微调场景", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseChat-128K', 'SenseChat 4.0 128K', 'chat', 131072, 131072, 0.06, 0.06, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 131072, "maxOutput": 131072, "description": "基础版本模型 (V4)，128K上下文长度，在长文本理解及生成等任务中表现出色"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseChat-32K', 'SenseChat 4.0 32K', 'chat', 32768, 32768, 0.036, 0.036, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 36, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 36, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "基础版本模型 (V4)，32K上下文长度，灵活应用于各类场景"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseChat', 'SenseChat 4.0 4K', 'chat', 4096, 4096, 0.012, 0.012, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "基础版本模型 (V4)，4K上下文长度，通用能力强大"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseChat-5-Cantonese', 'SenseChat 5.0 Cantonese', 'chat', 32768, 32768, 0.027, 0.027, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 27, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 27, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "专门为适应香港地区的对话习惯、俚语及本地知识而设计，在粤语的对话理解上超越了GPT-4，在知识、推理、数学及代码编写等多个领域均能与GPT-4 Turbo相媲美。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseChat-Character', 'SenseChat Character', 'chat', 8192, 1024, 0.012, 0.012, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 1024, "maxOutput": 1024, "description": "拟人对话标准版模型，8K上下文长度，高响应速度"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'SenseChat-Character-Pro', 'SenseChat Character Pro', 'chat', 32768, 4096, 0.015, 0.015, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "拟人对话高级版模型，32K上下文长度，能力全面提升，支持中/英文对话"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'DeepSeek-V3', 'DeepSeek V3', 'chat', 32768, NULL, 0.002, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "DeepSeek-V3 是一款由深度求索公司自研的MoE模型。DeepSeek-V3 多项评测成绩超越了 Qwen2.5-72B 和 Llama-3.1-405B 等其他开源模型，并在性能上和世界顶尖的闭源模型 GPT-4o 以及 Claude-3.5-Sonnet 不分伯仲。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'DeepSeek-R1', 'DeepSeek R1', 'chat', 32768, NULL, 0.004, 0.016, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "DeepSeek-R1 在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能比肩 OpenAI o1 正式版。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'DeepSeek-R1-Distill-Qwen-14B', 'DeepSeek R1 Distill Qwen 14B', 'chat', 32768, NULL, 0, 0, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "DeepSeek-R1-Distill 模型是在开源模型的基础上通过微调训练得到的，训练过程中使用了由 DeepSeek-R1 生成的样本数据。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'sensenova'), 'DeepSeek-R1-Distill-Qwen-32B', 'DeepSeek R1 Distill Qwen 32B', 'chat', 8192, NULL, 0, 0, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "DeepSeek-R1-Distill 模型是在开源模型的基础上通过微调训练得到的，训练过程中使用了由 DeepSeek-R1 生成的样本数据。", "reasoning": true}', FALSE),
    -- siliconcloud
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-VL-32B-Instruct', 'Qwen3 VL 32B Instruct', 'chat', 262144, NULL, 0.001, 0.004, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-10-21", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "Qwen3-VL-32B-Instruct 是阿里巴巴通义千问团队推出的视觉语言模型，在多个视觉语言基准测试中取得了领先的 SOTA 性能。该模型支持百万像素级别的高分辨率图像输入，并具备强大的通用视觉理解、多语言 OCR、细粒度视觉定位和视觉对话能力。作为 Qwen3 系列中的视觉语言模型，它能够处理复杂的多模态任务，支持工具调用和前缀续写等高级功能。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-VL-32B-Thinking', 'Qwen3 VL 32B Thinking', 'chat', 262144, NULL, 0.001, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-10-21", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "Qwen3-VL-32B-Thinking 是阿里巴巴通义千问团队推出的视觉语言模型中一个为复杂视觉推理任务特别优化的版本。该模型内置了\"思考模式\"，使其在回答问题前能够生成详细的中间推理步骤，从而显著增强其在需要多步逻辑、规划和复杂推理的任务上的表现。该模型支持百万像素级别的高分辨率图像输入，具备强大的通用视觉理解、多语言 OCR、细粒度视觉定位和视觉对话能力，并支持工具调用和前缀续写等功能。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'deepseek-ai/DeepSeek-OCR', 'DeepSeek OCR', 'chat', 8192, NULL, 0, 0, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-10-20", "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "DeepSeek-OCR 是由深度求索（DeepSeek AI）推出的一个视觉语言模型，专注于光学字符识别（OCR）与\"上下文光学压缩\"。该模型旨在探索从图像中压缩上下文信息的边界，能够高效处理文档并将其转换为如 Markdown 等结构化文本格式。它能够准确识别图像中的文字内容，特别适用于文档数字化、文字提取和结构化处理等应用场景。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-Omni-30B-A3B-Instruct', 'Qwen3 Omni 30B A3B Instruct', 'chat', 65536, NULL, 0.0007, 0.0028, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-22", "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "Qwen3-Omni-30B-A3B-Instruct 是阿里巴巴通义千问团队最新 Qwen3 系列中的一员。它是一个拥有 300 亿总参数和 30 亿激活参数的混合专家（MoE）模型，在保持强大性能的同时有效降低了推理成本。该模型在高质量、多来源、多语言的数据上进行训练，具备强大的通用能力，支持全模态输入处理，包括文本、图像、音频和视频，能够理解和生成跨模态的内容。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-Omni-30B-A3B-Thinking', 'Qwen3 Omni 30B A3B Thinking', 'chat', 65536, NULL, 0.0007, 0.0028, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-22", "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "Qwen3-Omni-30B-A3B-Thinking 是 Qwen3-Omni 全模态模型中的核心\"思考者\"（Thinker）组件。它专门负责处理包括文本、音频、图像和视频在内的多模态输入，并执行复杂的思维链推理。作为推理的大脑，该模型将所有输入统一到通用的表征空间中，实现跨模态的深度理解和复杂推理能力。该模型基于混合专家（MoE）架构，拥有 300 亿总参数和 30 亿激活参数，能够在保持强大推理能力的同时优化计算效率。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-Omni-30B-A3B-Captioner', 'Qwen3 Omni 30B A3B Captioner', 'chat', 65536, NULL, 0.0007, 0.0028, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-22", "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "Qwen3-Omni-30B-A3B-Captioner 是阿里巴巴通义千问团队 Qwen3 系列中的一款视觉语言模型（VLM）。它专门用于生成高质量、详细且准确的图像描述。该模型基于 300 亿总参数的混合专家（MoE）架构，能够深入理解图像内容并将其转化为自然流畅的文字描述。它在图像细节捕捉、场景理解、物体识别和关系推理等方面表现卓越，特别适合需要精确图像理解和描述生成的应用场景。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'tencent/Hunyuan-MT-7B', 'Hunyuan MT 7B', 'chat', 32768, NULL, 0, 0, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-01", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "混元翻译模型（Hunyuan Translation Model）由一个翻译模型 Hunyuan-MT-7B 和一个集成模型 Hunyuan-MT-Chimera 组成。Hunyuan-MT-7B 是一个拥有 70 亿参数的轻量级翻译模型，用于将源文本翻译成目标语言。该模型支持 33 种语言以及 5 种中国少数民族语言的互译。在 WMT25 国际机器翻译竞赛中，Hunyuan-MT-7B 在其参与的 31 个语言类别中获得了 30 个第一名，展现了其卓越的翻译能力。针对翻译场景，腾讯混元提出了一个从预训练到监督微调、再到翻译强化和集成强化的完整训练范式，使其在同等规模的模型中达到了业界领先的性能。该模型计算效率高、易于部署，适合多种应用场景。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'inclusionAI/Ling-1T', 'Ling 1T', 'chat', 131072, NULL, 0.004, 0.016, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-10-09", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Ling-1T 是 \"灵 2.0\" 系列的首款旗舰级 non-thinking 模型，拥有 1 万亿总参数和每 token 约 500 亿个活动参数。基于灵 2.0 架构构建，Ling-1T 旨在突破高效推理和可扩展认知的极限。Ling-1T-base 在超过 20 万亿个高质量、推理密集的 token 上进行训练，针对大型知识密集型任务与长文档理解进行了优化，具备出色的工具调用和上下文记忆能力。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'inclusionAI/Ring-1T', 'Ring-1T', 'chat', 131072, NULL, 0.004, 0.016, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-10-14", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Ring-1T 是一款由百灵（Bailing）团队发布的万亿参数规模的开源思想模型。它基于 Ling 2.0 架构和 Ling-1T-base 基础模型训练，总参数量达 1 万亿，激活参数量为 500 亿，并支持高达 128K 的上下文窗口。该模型通过大规模可验证奖励强化学习进行优化。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'inclusionAI/Ling-1T', 'Ling-1T', 'chat', 131072, NULL, 0.004, 0.016, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-10-09", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Ling-1T 是\"灵 2.0\"系列的首款旗舰级 non-thinking 模型，拥有 1 万亿总参数和每 token 约 500 亿个活动参数。基于灵 2.0 架构构建，Ling-1T 旨在突破高效推理和可扩展认知的极限。Ling-1T-base 在超过 20 万亿个高质量、推理密集的 token 上进行训练。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'zai-org/GLM-4.6', 'GLM-4.6', 'chat', 198000, NULL, 0.0035, 0.014, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 14, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-30", "source": "builtin", "maxToken": 198000, "contextWindowTokens": 198000, "description": "与 GLM-4.5 相比，GLM-4.6 带来了多项关键改进。其上下文窗口从 128K 扩展到 200K tokens，使模型能够处理更复杂的智能体任务。模型在代码基准测试中取得了更高的分数，并在 Claude Code、Cline、Roo Code 和 Kilo Code 等应用中展现了更强的真实世界性能，包括在生成视觉效果精致的前端页面方面有所改进。GLM-4.6 在推理性能上表现出明显提升，并支持在推理过程中使用工具，从而带来了更强的综合能力。它在工具使用和基于搜索的智能体方面表现更强，并且能更有效地集成到智能体框架中。在写作方面，该模型在风格和可读性上更符合人类偏好，并在角色扮演场景中表现得更自然。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-Next-80B-A3B-Thinking', 'Qwen3 Next 80B A3B Thinking', 'chat', 256000, NULL, 0.001, 0.004, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-10", "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "Qwen3-Next-80B-A3B-Thinking 是由阿里巴巴通义千问团队发布的、专为复杂推理任务设计的下一代基础模型。它基于创新的 Qwen3-Next 架构，该架构融合了混合注意力机制（Gated DeltaNet 与 Gated Attention）和高稀疏度混合专家（MoE）结构，旨在实现极致的训练与推理效率。作为一个总参数达 800 亿的稀疏模型，它在推理时仅激活约 30 亿参数，大幅降低了计算成本，在处理超过 32K tokens 的长上下文任务时，吞吐量比 Qwen3-32B 模型高出 10 倍以上。此“Thinking”版本专为执行数学证明、代码综合、逻辑分析和规划等高难度多步任务而优化，并默认以结构化的“思维链”形式输出推理过程。在性能上，它不仅超越了 Qwen3-32B-Thinking 等成本更高的模型，还在多个基准测试中优于 Gemini-2.5-Flash-Thinking。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-Next-80B-A3B-Instruct', 'Qwen3 Next 80B A3B Instruct', 'chat', 131072, NULL, 0.001, 0.004, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-10", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Qwen3-Next-80B-A3B-Instruct 是由阿里巴巴通义千问团队发布的下一代基础模型。它基于全新的 Qwen3-Next 架构，旨在实现极致的训练和推理效率。该模型采用了创新的混合注意力机制（Gated DeltaNet 和 Gated Attention）、高稀疏度混合专家（MoE）结构以及多项训练稳定性优化。作为一个拥有 800 亿总参数的稀疏模型，它在推理时仅需激活约 30 亿参数，从而大幅降低了计算成本，并在处理超过 32K tokens 的长上下文任务时，推理吞吐量比 Qwen3-32B 模型高出 10 倍以上。此模型为指令微调版本，专为通用任务设计，不支持思维链（Thinking）模式。在性能上，它与通义千问的旗舰模型 Qwen3-235B 在部分基准测试中表现相当，尤其在超长上下文任务中展现出明显优势。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-VL-30B-A3B-Instruct', 'Qwen3 VL 30B A3B Instruct', 'chat', 256000, NULL, 0.0007, 0.0028, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "Qwen3-VL-30B-A3B-Instruct 是 Qwen3-VL 系列的指令微调版本，具有强大的视觉-语言理解与生成能力，原生支持 256K 上下文长度，适合多模态对话与图像条件生成任务。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-VL-30B-A3B-Thinking', 'Qwen3 VL 30B A3B Thinking', 'chat', 256000, NULL, 0.0007, 0.0028, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "Qwen3-VL-30B-A3B-Thinking 是 Qwen3-VL 的推理增强版本（Thinking），在多模态推理、图像到代码和复杂视觉理解任务上进行了优化，支持 256K 上下文并具备更强的链式思考能力。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-VL-235B-A22B-Instruct', 'Qwen3 VL 235B A22B Instruct', 'chat', 256000, NULL, 0.0025, 0.01, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "Qwen3-VL-235B-A22B-Instruct 是 Qwen3-VL 系列的大型指令微调模型，基于混合专家（MoE）架构，拥有卓越的多模态理解与生成能力，原生支持 256K 上下文，适用于高并发生产级多模态服务。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-VL-235B-A22B-Thinking', 'Qwen3 VL 235B A22B Thinking', 'chat', 256000, NULL, 0.0025, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "Qwen3-VL-235B-A22B-Thinking 是 Qwen3-VL 系列中的旗舰思考版本，针对复杂多模态推理、长上下文推理与智能体交互进行了专项优化，适合需要深度思考与视觉推理的企业级场景。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'deepseek-ai/DeepSeek-V3.2-Exp', 'DeepSeek V3.2 Exp', 'chat', 163840, NULL, 0.002, 0.003, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-29", "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek-V3.2-Exp 是 DeepSeek 发布的实验性 V3.2 版本，作为迈向下一代架构的中间探索。它在 V3.1-Terminus 的基础上引入了 DeepSeek 稀疏注意力（DeepSeek Sparse Attention，DSA）机制以提升长上下文训练与推理效率，针对工具调用、长文档理解与多步推理进行了专项优化。V3.2-Exp 为研究与产品化之间的桥梁，适合希望在高上下文预算场景中探索更高推理效率的用户。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Pro/deepseek-ai/DeepSeek-V3.2-Exp', 'DeepSeek V3.2 Exp (Pro)', 'chat', 163840, NULL, 0.002, 0.003, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-29", "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek-V3.2-Exp 是 DeepSeek 发布的实验性 V3.2 版本，作为迈向下一代架构的中间探索。它在 V3.1-Terminus 的基础上引入了 DeepSeek 稀疏注意力（DeepSeek Sparse Attention，DSA）机制以提升长上下文训练与推理效率，针对工具调用、长文档理解与多步推理进行了专项优化。V3.2-Exp 为研究与产品化之间的桥梁，适合希望在高上下文预算场景中探索更高推理效率的用户。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'deepseek-ai/DeepSeek-V3.1-Terminus', 'DeepSeek V3.1 Terminus', 'chat', 163840, NULL, 0.004, 0.012, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek-V3.1-Terminus 是由深度求索（DeepSeek）发布的 V3.1 模型的更新版本，定位为混合智能体大语言模型。此次更新在保持模型原有能力的基础上，专注于修复用户反馈的问题并提升稳定性。它显著改善了语言一致性，减少了中英文混用和异常字符的出现。模型集成了“思考模式”（Thinking Mode）和“非思考模式”（Non-thinking Mode），用户可通过聊天模板灵活切换以适应不同任务。作为一个重要的优化，V3.1-Terminus 增强了代码智能体（Code Agent）和搜索智能体（Search Agent）的性能，使其在工具调用和执行多步复杂任务方面更加可靠。", "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Pro/deepseek-ai/DeepSeek-V3.1-Terminus', 'DeepSeek V3.1 Terminus (Pro)', 'chat', 163840, NULL, 0.004, 0.012, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek-V3.1-Terminus 是由深度求索（DeepSeek）发布的 V3.1 模型的更新版本，定位为混合智能体大语言模型。此次更新在保持模型原有能力的基础上，专注于修复用户反馈的问题并提升稳定性。它显著改善了语言一致性，减少了中英文混用和异常字符的出现。模型集成了“思考模式”（Thinking Mode）和“非思考模式”（Non-thinking Mode），用户可通过聊天模板灵活切换以适应不同任务。作为一个重要的优化，V3.1-Terminus 增强了代码智能体（Code Agent）和搜索智能体（Search Agent）的性能，使其在工具调用和执行多步复杂任务方面更加可靠。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-VL-8B-Instruct', 'Qwen3 VL 8B Instruct', 'chat', 256000, NULL, 0.0005, 0.002, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-10-15", "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "Qwen3-VL-8B-Instruct 是 Qwen3 系列的视觉语言模型，基于 Qwen3-8B-Instruct 开发并在大量图文数据上训练，擅长通用视觉理解、以视觉为中心的对话以及图像中的多语言文本识别。适用于视觉问答、图像描述、多模态指令跟随与工具调用场景。", "organization": "Qwen", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-VL-8B-Thinking', 'Qwen3 VL 8B Thinking', 'chat', 256000, NULL, 0.0005, 0.005, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-10-15", "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "Qwen3-VL-8B-Thinking 是 Qwen3 系列的视觉思考版本，针对复杂多步推理任务优化，默认在回答前生成逐步思考（thinking chain）以提高推理准确性。适合需要深度推理的视觉问答、审阅图像内容并给出详细分析的场景。", "organization": "Qwen", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'inclusionAI/Ring-flash-2.0', 'Ring Flash 2.0', 'chat', 131072, NULL, 0.001, 0.004, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-19", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Ring-flash-2.0 是一个基于 Ling-flash-2.0-base 深度优化的高性能思考模型。它采用混合专家（MoE）架构，总参数量为 100B，但在每次推理中仅激活 6.1B 参数。该模型通过独创的 icepop 算法，解决了 MoE 大模型在强化学习（RL）训练中的不稳定性难题，使其复杂推理能力在长周期训练中得以持续提升。Ring-flash-2.0 在数学竞赛、代码生成和逻辑推理等多个高难度基准测试中取得了显著突破，其性能不仅超越了 40B 参数规模以下的顶尖稠密模型，还能媲美更大规模的开源 MoE 模型及闭源的高性能思考模型。尽管该模型专注于复杂推理，它在创意写作等任务上也表现出色。此外，得益于其高效的架构设计，Ring-flash-2.0 在提供强大性能的同时，也实现了高速推理，显著降低了思考模型在高并发场景下的部署成本。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'inclusionAI/Ling-flash-2.0', 'Ling Flash 2.0', 'chat', 131072, NULL, 0.001, 0.004, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-17", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Ling-flash-2.0 是由蚂蚁集团百灵团队发布的 Ling 2.0 架构系列的第三款模型。它是一款混合专家（MoE）模型，总参数规模达到 1000 亿，但每个 token 仅激活 61 亿参数（非词向量激活 48 亿）。 作为一个轻量级配置的模型，Ling-flash-2.0 在多个权威评测中展现出媲美甚至超越 400 亿级别稠密（Dense）模型及更大规模 MoE 模型的性能。该模型旨在通过极致的架构设计与训练策略，在“大模型等于大参数”的共识下探索高效能的路径。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'inclusionAI/Ling-mini-2.0', 'Ling Mini 2.0', 'chat', 131072, NULL, 0.0005, 0.002, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-09", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Ling-mini-2.0 是一款基于 MoE 架构的小尺寸高性能大语言模型。它拥有 16B 总参数，但每个 token 仅激活 1.4B（non-embedding 789M），从而实现了极高的生成速度。得益于高效的 MoE 设计与大规模高质量训练数据，尽管激活参数仅为 1.4B，Ling-mini-2.0 依然在下游任务中展现出可媲美 10B 以下 dense LLM 及更大规模 MoE 模型的顶尖性能。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'ByteDance-Seed/Seed-OSS-36B-Instruct', 'Seed OSS 36B Instruct', 'chat', 256000, NULL, 0.0015, 0.004, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-20", "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "Seed-OSS 是由字节跳动 Seed 团队开发的一系列开源大型语言模型，专为强大的长上下文处理、推理、智能体（agent）和通用能力而设计。该系列中的 Seed-OSS-36B-Instruct 是一个拥有 360 亿参数的指令微调模型，它原生支持超长上下文长度，使其能够一次性处理海量文档或复杂的代码库。该模型在推理、代码生成和智能体任务（如工具使用）方面进行了特别优化，同时保持了平衡且出色的通用能力。此模型的一大特色是“思考预算”（Thinking Budget）功能，允许用户根据需要灵活调整推理长度，从而在实际应用中有效提升推理效率。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'stepfun-ai/step3', 'Step 3', 'chat', 65536, NULL, 0.004, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-31", "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "Step3 是由阶跃星辰（StepFun）发布的前沿多模态推理模型，它基于拥有 321B 总参数和 38B 激活参数的专家混合（MoE）架构构建。该模型采用端到端设计，旨在最小化解码成本，同时在视觉语言推理方面提供顶级性能。通过多矩阵分解注意力（MFA）和注意力-FFN 解耦（AFD）的协同设计，Step3 在旗舰级和低端加速器上都能保持卓越的效率。在预训练阶段，Step3 处理了超过 20T 的文本 token 和 4T 的图文混合 token，覆盖十多种语言。该模型在数学、代码及多模态等多个基准测试中均达到了开源模型的领先水平。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-Coder-480B-A35B-Instruct', 'Qwen3 Coder 480B A35B Instruct', 'chat', 262144, NULL, 0.008, 0.016, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-23", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "Qwen3-Coder-480B-A35B-Instruct 是由阿里巴巴发布的、迄今为止最具代理（Agentic）能力的代码模型。它是一个拥有 4800 亿总参数和 350 亿激活参数的混合专家（MoE）模型，在效率和性能之间取得了平衡。该模型原生支持 256K（约 26 万） tokens 的上下文长度，并可通过 YaRN 等外推方法扩展至 100 万 tokens，使其能够处理大规模代码库和复杂的编程任务。Qwen3-Coder 专为代理式编码工作流设计，不仅能生成代码，还能与开发工具和环境自主交互，以解决复杂的编程问题。在多个编码和代理任务的基准测试中，该模型在开源模型中取得了顶尖水平，其性能可与 Claude Sonnet 4 等领先模型相媲美。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-Coder-30B-A3B-Instruct', 'Qwen3 Coder 30B A3B Instruct', 'chat', 262144, NULL, 0.0007, 0.0028, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-31", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "Qwen3-Coder-30B-A3B-Instruct 是由阿里巴巴通义千问团队开发的 Qwen3 系列中的代码模型。作为一个经过精简优化的模型，它在保持高性能和高效率的同时，专注于提升代码处理能力。该模型在代理式编程（Agentic Coding）、自动化浏览器操作和工具调用等复杂任务上，于开源模型中表现出显著的性能优势。它原生支持 256K tokens 的长上下文，并可扩展至 1M tokens，从而能够更好地进行代码库级别的理解和处理。此外，该模型为 Qwen Code、CLINE 等平台提供了强大的代理编码支持，并设计了专门的函数调用格式。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'zai-org/GLM-4.5V', 'GLM-4.5V', 'chat', 65536, NULL, 0.001, 0.006, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-11", "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "GLM-4.5V 是由智谱 AI（Zhipu AI）发布的最新一代视觉语言模型（VLM）该模型基于拥有 106B 总参数和 12B 激活参数的旗舰文本模型 GLM-4.5-Air 构建，采用了混合专家（MoE）架构，旨在以更低的推理成本实现卓越性能 GLM-4.5V 在技术上延续了 GLM-4.1V-Thinking 的路线，并引入了三维旋转位置编码（3D-RoPE）等创新，显著增强了对三维空间关系的感知与推理能力。通过在预训练、监督微调和强化学习阶段的优化，该模型具备了处理图像、视频、长文档等多种视觉内容的能力，在 41 个公开的多模态基准测试中达到了同级别开源模型的顶尖水平此外，模型还新增了“思考模式”开关，允许用户在快速响应和深度推理之间灵活选择，以平衡效率与效果。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'zai-org/GLM-4.5', 'GLM-4.5', 'chat', 131072, NULL, 0.0035, 0.014, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 14, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-28", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "GLM-4.5 是一款专为智能体应用打造的基础模型，使用了混合专家（Mixture-of-Experts）架构。在工具调用、网页浏览、软件工程、前端编程领域进行了深度优化，支持无缝接入 Claude Code、Roo Code 等代码智能体中使用。GLM-4.5 采用混合推理模式，可以适应复杂推理和日常使用等多种应用场景。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'zai-org/GLM-4.5-Air', 'GLM-4.5-Air', 'chat', 131072, NULL, 0.001, 0.006, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-28", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "GLM-4.5-Air 是一款专为智能体应用打造的基础模型，使用了混合专家（Mixture-of-Experts）架构。在工具调用、网页浏览、软件工程、前端编程领域进行了深度优化，支持无缝接入 Claude Code、Roo Code 等代码智能体中使用。GLM-4.5 采用混合推理模式，可以适应复杂推理和日常使用等多种应用场景。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'ascend-tribe/pangu-pro-moe', 'Pangu Pro MoE 72B A16B', 'chat', 131072, NULL, 0.001, 0.004, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-17", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Pangu-Pro-MoE 72B-A16B 是一款 720 亿参数、激活 160 亿参的稀疏大语言模型，它基于分组混合专家（MoGE）架构，它在专家选择阶段对专家进行分组，并约束 token 在每个组内激活等量专家，从而实现专家负载均衡，显著提升模型在昇腾平台的部署效率。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'baidu/ERNIE-4.5-300B-A47B', 'ERNIE 4.5 300B A47B', 'chat', 131072, NULL, 0.002, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-30", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "ERNIE-4.5-300B-A47B 是由百度公司开发的一款基于混合专家（MoE）架构的大语言模型。该模型总参数量为 3000 亿，但在推理时每个 token 仅激活 470 亿参数，从而在保证强大性能的同时兼顾了计算效率。作为 ERNIE 4.5 系列的核心模型之一，在文本理解、生成、推理和编程等任务上展现出卓越的能力。该模型采用了一种创新的多模态异构 MoE 预训练方法，通过文本与视觉模态的联合训练，有效提升了模型的综合能力，尤其在指令遵循和世界知识记忆方面效果突出。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'moonshotai/Kimi-K2-Instruct-0905', 'Kimi K2 0905', 'chat', 262144, NULL, 0.004, 0.016, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-05", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "Kimi K2-Instruct-0905 是 Kimi K2 最新、最强大的版本。它是一款顶尖的混合专家（MoE）语言模型，拥有 1 万亿的总参数和 320 亿的激活参数。该模型的主要特性包括：增强的智能体编码智能，在公开基准测试和真实世界的编码智能体任务中表现出显著的性能提升；改进的前端编码体验，在前端编程的美观性和实用性方面均有进步。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Pro/moonshotai/Kimi-K2-Instruct-0905', 'Kimi K2 0905 (Pro)', 'chat', 262144, NULL, 0.004, 0.016, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-09-05", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "Kimi K2-Instruct-0905 是 Kimi K2 最新、最强大的版本。它是一款顶尖的混合专家（MoE）语言模型，拥有 1 万亿的总参数和 320 亿的激活参数。该模型的主要特性包括：增强的智能体编码智能，在公开基准测试和真实世界的编码智能体任务中表现出显著的性能提升；改进的前端编码体验，在前端编程的美观性和实用性方面均有进步。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'moonshotai/Kimi-Dev-72B', 'Kimi Dev 72B', 'chat', 131072, NULL, 0.002, 0.008, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-17", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Kimi-Dev-72B 是一款开源代码大模型，经过大规模强化学习优化，能输出稳健、可直接投产的补丁。该模型在 SWE-bench Verified 上取得 60.4 % 的新高分，刷新了开源模型在缺陷修复、代码评审等自动化软件工程任务上的纪录。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'tencent/Hunyuan-A13B-Instruct', 'Hunyuan A13B Instruct', 'chat', 131072, NULL, 0.001, 0.004, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-27", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Hunyuan-A13B-Instruct 参数量800 亿，激活 130 亿参数即可对标更大模型，支持“快思考/慢思考”混合推理；长文理解稳定；经 BFCL-v3 与 τ-Bench 验证，Agent 能力领先；结合 GQA 与多量化格式，实现高效推理。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'MiniMaxAI/MiniMax-M1-80k', 'MiniMax M1 80K', 'chat', 131072, NULL, 0.004, 0.016, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-16", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "MiniMax-M1 是开源权重的大规模混合注意力推理模型，拥有 4560 亿参数，每个 Token 可激活约 459 亿参数。模型原生支持 100 万 Token 的超长上下文，并通过闪电注意力机制，在 10 万 Token 的生成任务中相比 DeepSeek R1 节省 75% 的浮点运算量。同时，MiniMax-M1 采用 MoE（混合专家）架构，结合 CISPO 算法与混合注意力设计的高效强化学习训练，在长输入推理与真实软件工程场景中实现了业界领先的性能。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Tongyi-Zhiwen/QwenLong-L1-32B', 'QwenLong L1 32B', 'chat', 131072, NULL, 0.001, 0.004, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-05-26", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "QwenLong-L1-32B 是首个使用强化学习训练的长上下文大型推理模型（LRM），专门针对长文本推理任务进行优化。该模型通过渐进式上下文扩展的强化学习框架，实现了从短上下文到长上下文的稳定迁移。在七个长上下文文档问答基准测试中，QwenLong-L1-32B 超越了 OpenAI-o3-mini 和 Qwen3-235B-A22B 等旗舰模型，性能可媲美 Claude-3.7-Sonnet-Thinking。该模型特别擅长数学推理、逻辑推理和多跳推理等复杂任务。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-235B-A22B-Thinking-2507', 'Qwen3 235B A22B Thinking 2507', 'chat', 262144, NULL, 0.0025, 0.01, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-25", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "Qwen3-235B-A22B-Thinking-2507 是由阿里巴巴通义千问团队开发的 Qwen3 系列大型语言模型中的一员，专注于高难度的复杂推理任务。该模型基于混合专家（MoE）架构，总参数量达 2350 亿，而在处理每个 token 时仅激活约 220 亿参数，从而在保持强大性能的同时提高了计算效率。作为一个专门的“思考”模型，它在逻辑推理、数学、科学、编程和学术基准测试等需要人类专业知识的任务上表现显著提升，达到了开源思考模型中的顶尖水平。此外，模型还增强了通用能力，如指令遵循、工具使用和文本生成，并原生支持 256K 的长上下文理解能力，非常适合用于需要深度推理和处理长文档的场景。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-235B-A22B-Instruct-2507', 'Qwen3 235B A22B Instruct 2507', 'chat', 262144, NULL, 0.0025, 0.01, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-21", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "Qwen3-235B-A22B-Instruct-2507 是由阿里云通义千问团队开发的 Qwen3 系列中的一款旗舰级混合专家（MoE）大语言模型。该模型拥有 2350 亿总参数，每次推理激活 220 亿参数。它是作为 Qwen3-235B-A22B 非思考模式的更新版本发布的，专注于在指令遵循、逻辑推理、文本理解、数学、科学、编程及工具使用等通用能力上实现显著提升。此外，模型增强了对多语言长尾知识的覆盖，并能更好地对齐用户在主观和开放性任务上的偏好，以生成更有帮助和更高质量的文本。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-30B-A3B-Thinking-2507', 'Qwen3 30B A3B Thinking 2507', 'chat', 262144, NULL, 0.0007, 0.0028, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-30", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "Qwen3-30B-A3B-Thinking-2507 是由阿里巴巴通义千问团队发布的 Qwen3 系列的最新思考模型。作为一个拥有 305 亿总参数和 33 亿激活参数的混合专家（MoE）模型，它专注于提升复杂任务的处理能力。该模型在逻辑推理、数学、科学、编程和需要人类专业知识的学术基准测试上表现出显著的性能提升。同时，它在指令遵循、工具使用、文本生成和与人类偏好对齐等通用能力方面也得到了显著增强。模型原生支持 256K 的长上下文理解能力，并可扩展至 100 万 tokens。此版本专为“思考模式”设计，旨在通过详尽的逐步推理来解决高度复杂的任务，其 Agent 智能体能力也表现出色。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-30B-A3B-Instruct-2507', 'Qwen3 30B A3B Instruct 2507', 'chat', 262144, NULL, 0.0007, 0.0028, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-29", "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "Qwen3-30B-A3B-Instruct-2507 是 Qwen3-30B-A3B 非思考模式的更新版本。这是一个拥有 305 亿总参数和 33 亿激活参数的混合专家（MoE）模型。该模型在多个方面进行了关键增强，包括显著提升了指令遵循、逻辑推理、文本理解、数学、科学、编码和工具使用等通用能力。同时，它在多语言的长尾知识覆盖范围上取得了实质性进展，并能更好地与用户在主观和开放式任务中的偏好对齐，从而能够生成更有帮助的回复和更高质量的文本。此外，该模型的长文本理解能力也增强到了 256K。此模型仅支持非思考模式，其输出中不会生成 `<think></think>` 标签。", "organization": "Qwen", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-235B-A22B', 'Qwen3 235B A22B', 'chat', 131072, NULL, 0.0025, 0.01, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-28", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-32B', 'Qwen3 32B', 'chat', 131072, NULL, 0.001, 0.004, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-28", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-30B-A3B', 'Qwen3 30B A3B', 'chat', 131072, NULL, 0.0007, 0.0028, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-28", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-14B', 'Qwen3 14B', 'chat', 131072, NULL, 0.0005, 0.002, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-28", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen3-8B', 'Qwen3 8B (Free)', 'chat', 131072, NULL, 0, 0, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning", "reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-28", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Qwen3是一款能力大幅提升的新一代通义千问大模型，在推理、通用、Agent和多语言等多个核心能力上均达到业界领先水平，并支持思考模式切换。", "organization": "Qwen", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'THUDM/GLM-4.1V-9B-Thinking', 'GLM-4.1V 9B Thinking (Free)', 'chat', 65536, NULL, 0, 0, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-02", "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "GLM-4.1V-9B-Thinking 是由智谱 AI 和清华大学 KEG 实验室联合发布的一款开源视觉语言模型（VLM），专为处理复杂的多模态认知任务而设计。该模型基于 GLM-4-9B-0414 基础模型，通过引入“思维链”（Chain-of-Thought）推理机制和采用强化学习策略，显著提升了其跨模态的推理能力和稳定性。", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Pro/THUDM/GLM-4.1V-9B-Thinking', 'GLM-4.1V 9B Thinking (Pro)', 'chat', 65536, NULL, 0.00025, 0.001, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-02", "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "GLM-4.1V-9B-Thinking 是由智谱 AI 和清华大学 KEG 实验室联合发布的一款开源视觉语言模型（VLM），专为处理复杂的多模态认知任务而设计。该模型基于 GLM-4-9B-0414 基础模型，通过引入“思维链”（Chain-of-Thought）推理机制和采用强化学习策略，显著提升了其跨模态的推理能力和稳定性。", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'THUDM/GLM-Z1-Rumination-32B-0414', 'GLM-Z1-Rumination 32B 0414', 'chat', 131072, NULL, 0.001, 0.004, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "GLM-Z1-Rumination-32B-0414 是一个具有沉思能力的深度推理模型（与 OpenAI 的 Deep Research 对标）。与典型的深度思考模型不同，沉思模型采用更长时间的深度思考来解决更开放和复杂的问题。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'THUDM/GLM-Z1-32B-0414', 'GLM-Z1 32B 0414', 'chat', 131072, NULL, 0.001, 0.004, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "GLM-Z1-32B-0414 是一个具有深度思考能力的推理模型。该模型基于 GLM-4-32B-0414 通过冷启动和扩展强化学习开发，并在数学、代码和逻辑任务上进行了进一步训练。与基础模型相比，GLM-Z1-32B-0414 显著提升了数学能力和解决复杂任务的能力。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'THUDM/GLM-Z1-9B-0414', 'GLM-Z1 9B 0414 (Free)', 'chat', 131072, NULL, 0, 0, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "GLM-Z1-9B-0414 是 GLM 系列的小型模型，仅有 90 亿参数，但保持了开源传统的同时展现出惊人的能力。尽管规模较小，该模型在数学推理和通用任务上仍表现出色，其总体性能在同等规模的开源模型中已处于领先水平。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'THUDM/GLM-4-32B-0414', 'GLM-4 32B 0414', 'chat', 32768, NULL, 0.00189, 0.00189, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.89, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.89, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "GLM-4-32B-0414 是 GLM 系列的新一代开源模型，拥有 320 亿参数。该模型性能可与 OpenAI 的 GPT 系列和 DeepSeek 的 V3/R1 系列相媲美。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'THUDM/GLM-4-9B-0414', 'GLM-4 9B 0414 (Free)', 'chat', 32768, NULL, 0, 0, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-14", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "GLM-4-9B-0414 是 GLM 系列的小型模型，拥有 90 亿参数。该模型继承了 GLM-4-32B 系列的技术特点，但提供了更轻量级的部署选择。尽管规模较小，GLM-4-9B-0414 仍在代码生成、网页设计、SVG 图形生成和基于搜索的写作等任务上展现出色能力。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'THUDM/glm-4-9b-chat', 'GLM-4 9B Chat (Free)', 'chat', 131072, NULL, 0, 0, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-06-04", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "GLM-4-9B-Chat 是智谱 AI 推出的 GLM-4 系列预训练模型中的开源版本。该模型在语义、数学、推理、代码和知识等多个方面表现出色。除了支持多轮对话外，GLM-4-9B-Chat 还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理等高级功能。模型支持 26 种语言，包括中文、英文、日语、韩语和德语等。在多项基准测试中，GLM-4-9B-Chat 展现了优秀的性能，如 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等。该模型支持最大 128K 的上下文长度，适用于学术研究和商业应用", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Pro/THUDM/glm-4-9b-chat', 'GLM-4 9B Chat (Pro)', 'chat', 131072, NULL, 0.0006, 0.0006, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-06-04", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "GLM-4-9B-Chat 是智谱 AI 推出的 GLM-4 系列预训练模型中的开源版本。该模型在语义、数学、推理、代码和知识等多个方面表现出色。除了支持多轮对话外，GLM-4-9B-Chat 还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理等高级功能。模型支持 26 种语言，包括中文、英文、日语、韩语和德语等。在多项基准测试中，GLM-4-9B-Chat 展现了优秀的性能，如 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等。该模型支持最大 128K 的上下文长度，适用于学术研究和商业应用", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'deepseek-ai/DeepSeek-R1-0528-Qwen3-8B', 'DeepSeek R1 0528 Qwen3 8B (Free)', 'chat', 131072, NULL, 0, 0, '{"abilities": {"reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-R1-0528-Qwen3-8B 是通过从 DeepSeek-R1-0528 模型蒸馏思维链到 Qwen3 8B Base 获得的模型。该模型在开源模型中达到了最先进（SOTA）的性能，在 AIME 2024 测试中超越了 Qwen3 8B 10%，并达到了 Qwen3-235B-thinking 的性能水平。该模型在数学推理、编程和通用逻辑等多个基准测试中表现出色，其架构与 Qwen3-8B 相同，但共享 DeepSeek-R1-0528 的分词器配置。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'deepseek-ai/DeepSeek-R1', 'DeepSeek R1', 'chat', 98304, NULL, 0.004, 0.016, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 98304, "contextWindowTokens": 98304, "description": "DeepSeek-R1 是一款强化学习（RL）驱动的推理模型，解决了模型中的重复性和可读性问题。在 RL 之前，DeepSeek-R1 引入了冷启动数据，进一步优化了推理性能。它在数学、代码和推理任务中与 OpenAI-o1 表现相当，并且通过精心设计的训练方法，提升了整体效果。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'deepseek-ai/DeepSeek-V3', 'DeepSeek V3', 'chat', 65536, NULL, 0.002, 0.008, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "DeepSeek-V3 是一款拥有 6710 亿参数的混合专家（MoE）语言模型，采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，结合无辅助损失的负载平衡策略，优化推理和训练效率。通过在 14.8 万亿高质量tokens上预训练，并进行监督微调和强化学习，DeepSeek-V3 在性能上超越其他开源模型，接近领先闭源模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Pro/deepseek-ai/DeepSeek-R1', 'DeepSeek R1 (Pro)', 'chat', 98304, NULL, 0.004, 0.016, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 98304, "contextWindowTokens": 98304, "description": "DeepSeek-R1 是一款强化学习（RL）驱动的推理模型，解决了模型中的重复性和可读性问题。在 RL 之前，DeepSeek-R1 引入了冷启动数据，进一步优化了推理性能。它在数学、代码和推理任务中与 OpenAI-o1 表现相当，并且通过精心设计的训练方法，提升了整体效果。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Pro/deepseek-ai/DeepSeek-V3', 'DeepSeek V3 (Pro)', 'chat', 65536, NULL, 0.002, 0.008, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "DeepSeek-V3 是一款拥有 6710 亿参数的混合专家（MoE）语言模型，采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，结合无辅助损失的负载平衡策略，优化推理和训练效率。通过在 14.8 万亿高质量tokens上预训练，并进行监督微调和强化学习，DeepSeek-V3 在性能上超越其他开源模型，接近领先闭源模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B', 'DeepSeek R1 Distill Qwen 32B', 'chat', 131072, NULL, 0.00126, 0.00126, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.26, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.26, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-R1-Distill-Qwen-32B 是基于 Qwen2.5-32B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，在数学、编程和推理等多个领域展现出卓越的性能。在 AIME 2024、MATH-500、GPQA Diamond 等多个基准测试中都取得了优异成绩，其中在 MATH-500 上达到了 94.3% 的准确率，展现出强大的数学推理能力。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B', 'DeepSeek R1 Distill Qwen 14B', 'chat', 131072, NULL, 0.0007, 0.0007, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-R1-Distill-Qwen-14B 是基于 Qwen2.5-14B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，展现出优秀的推理能力。在多个基准测试中表现出色，其中在 MATH-500 上达到了 93.9% 的准确率，在 AIME 2024 上达到了 69.7% 的通过率，在 CodeForces 上获得了 1481 的评分，显示出在数学和编程领域的强大实力。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'DeepSeek R1 Distill Qwen 7B (Free)', 'chat', 131072, NULL, 0, 0, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-R1-Distill-Qwen-7B 是基于 Qwen2.5-Math-7B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，展现出优秀的推理能力。在多个基准测试中表现出色，其中在 MATH-500 上达到了 92.8% 的准确率，在 AIME 2024 上达到了 55.5% 的通过率，在 CodeForces 上获得了 1189 的评分，作为 7B 规模的模型展示了较强的数学和编程能力。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'DeepSeek R1 Distill Qwen 7B (Pro)', 'chat', 131072, NULL, 0.00035, 0.00035, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.35, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.35, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-R1-Distill-Qwen-7B 是基于 Qwen2.5-Math-7B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，展现出优秀的推理能力。在多个基准测试中表现出色，其中在 MATH-500 上达到了 92.8% 的准确率，在 AIME 2024 上达到了 55.5% 的通过率，在 CodeForces 上获得了 1189 的评分，作为 7B 规模的模型展示了较强的数学和编程能力。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'deepseek-ai/DeepSeek-V2.5', 'DeepSeek V2.5', 'chat', 32768, NULL, 0.00133, 0.00133, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.33, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.33, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "DeepSeek-V2.5 是 DeepSeek-V2-Chat 和 DeepSeek-Coder-V2-Instruct 的升级版本，集成了两个先前版本的通用和编码能力。该模型在多个方面进行了优化，包括写作和指令跟随能力，更好地与人类偏好保持一致。DeepSeek-V2.5 在各种评估基准上都取得了显著的提升，如 AlpacaEval 2.0、ArenaHard、AlignBench 和 MT-Bench 等。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'deepseek-ai/deepseek-vl2', 'DeepSeek VL2', 'chat', 4096, NULL, 0.00099, 0.00099, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.99, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.99, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "DeepSeek-VL2 是一个基于 DeepSeekMoE-27B 开发的混合专家（MoE）视觉语言模型，采用稀疏激活的 MoE 架构，在仅激活 4.5B 参数的情况下实现了卓越性能。该模型在视觉问答、光学字符识别、文档/表格/图表理解和视觉定位等多个任务中表现优异。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/QVQ-72B-Preview', 'QVQ 72B Preview', 'chat', 32768, NULL, 0.0099, 0.0099, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 9.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "QVQ-72B-Preview 是由 Qwen 团队开发的专注于视觉推理能力的研究型模型，其在复杂场景理解和解决视觉相关的数学问题方面具有独特优势。", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/QwQ-32B', 'QwQ 32B', 'chat', 131072, NULL, 0.001, 0.004, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["reasoningBudgetToken"]}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "QwQ 是 Qwen 系列的推理模型。与传统的指令调优模型相比，QwQ 具备思考和推理能力，能够在下游任务中实现显著增强的性能，尤其是在解决困难问题方面。QwQ-32B 是中型推理模型，能够在与最先进的推理模型（如 DeepSeek-R1、o1-mini）的对比中取得有竞争力的性能。该模型采用 RoPE、SwiGLU、RMSNorm 和 Attention QKV bias 等技术，具有 64 层网络结构和 40 个 Q 注意力头（GQA 架构中 KV 为 8 个）。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen2.5-7B-Instruct', 'Qwen2.5 7B Instruct (Free)', 'chat', 32768, NULL, 0, 0, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5-7B-Instruct 是阿里云发布的最新大语言模型系列之一。该 7B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Pro/Qwen/Qwen2.5-7B-Instruct', 'Qwen2.5 7B Instruct (Pro)', 'chat', 32768, NULL, 0.00035, 0.00035, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.35, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.35, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5-7B-Instruct 是阿里云发布的最新大语言模型系列之一。该 7B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen2.5-14B-Instruct', 'Qwen2.5 14B Instruct', 'chat', 32768, NULL, 0.0007, 0.0007, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.7, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5-14B-Instruct 是阿里云发布的最新大语言模型系列之一。该 14B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen2.5-32B-Instruct', 'Qwen2.5 32B Instruct', 'chat', 32768, NULL, 0.00126, 0.00126, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.26, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.26, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5-32B-Instruct 是阿里云发布的最新大语言模型系列之一。该 32B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen2.5-72B-Instruct', 'Qwen2.5 72B Instruct', 'chat', 32768, NULL, 0.00413, 0.00413, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4.13, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.13, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen2.5-72B-Instruct-128K', 'Qwen2.5 72B Instruct 128K', 'chat', 131072, NULL, 0.00413, 0.00413, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4.13, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.13, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。它支持长达 128K tokens 的输入，可以生成超过 8K tokens 的长文本。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen2.5-Coder-7B-Instruct', 'Qwen2.5 Coder 7B Instruct (Free)', 'chat', 32768, NULL, 0, 0, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5-Coder-7B-Instruct 是阿里云发布的代码特定大语言模型系列的最新版本。该模型在 Qwen2.5 的基础上，通过 5.5 万亿个 tokens 的训练，显著提升了代码生成、推理和修复能力。它不仅增强了编码能力，还保持了数学和通用能力的优势。模型为代码智能体等实际应用提供了更全面的基础"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Pro/Qwen/Qwen2.5-Coder-7B-Instruct', 'Qwen2.5 Coder 7B Instruct (Pro)', 'chat', 32768, NULL, 0.00035, 0.00035, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.35, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.35, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5-Coder-7B-Instruct 是阿里云发布的代码特定大语言模型系列的最新版本。该模型在 Qwen2.5 的基础上，通过 5.5 万亿个 tokens 的训练，显著提升了代码生成、推理和修复能力。它不仅增强了编码能力，还保持了数学和通用能力的优势。模型为代码智能体等实际应用提供了更全面的基础"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen2.5-Coder-32B-Instruct', 'Qwen2.5 Coder 32B Instruct', 'chat', 32768, NULL, 0.00126, 0.00126, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.26, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.26, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5-Coder-32B-Instruct 是基于 Qwen2.5 开发的代码特定大语言模型。该模型通过 5.5 万亿 tokens 的训练，在代码生成、代码推理和代码修复方面都取得了显著提升。它是当前最先进的开源代码语言模型，编码能力可与 GPT-4 相媲美。模型不仅增强了编码能力，还保持了在数学和通用能力方面的优势，并支持长文本处理"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen2-7B-Instruct', 'Qwen2 7B Instruct (Free)', 'chat', 32768, NULL, 0, 0, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2-7B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 7B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力。Qwen2-7B-Instruct 在多项评测中均优于 Qwen1.5-7B-Chat，显示出显著的性能提升"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Pro/Qwen/Qwen2-7B-Instruct', 'Qwen2 7B Instruct (Pro)', 'chat', 32768, NULL, 0.00035, 0.00035, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.35, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.35, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2-7B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 7B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力。Qwen2-7B-Instruct 在多项评测中均优于 Qwen1.5-7B-Chat，显示出显著的性能提升"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen2-VL-72B-Instruct', 'Qwen2 VL 72B Instruct', 'chat', 32768, NULL, 0.00413, 0.00413, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4.13, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.13, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2-VL 是 Qwen-VL 模型的最新迭代版本，在视觉理解基准测试中达到了最先进的性能，包括 MathVista、DocVQA、RealWorldQA 和 MTVQA 等。Qwen2-VL 能够理解超过 20 分钟的视频，用于高质量的基于视频的问答、对话和内容创作。它还具备复杂推理和决策能力，可以与移动设备、机器人等集成，基于视觉环境和文本指令进行自动操作。除了英语和中文，Qwen2-VL 现在还支持理解图像中不同语言的文本，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语等", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Pro/Qwen/Qwen2.5-VL-7B-Instruct', 'Qwen2.5 VL 7B Instruct (Pro)', 'chat', 32768, NULL, 0.00035, 0.00035, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.35, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.35, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5-VL 是 Qwen 系列的新成员，具备强大的视觉理解能力，能分析图像中的文本、图表和布局，并能理解长视频和捕捉事件，它可以进行推理、操作工具，支持多格式物体定位和生成结构化输出，优化了视频理解的动态分辨率与帧率训练，并提升了视觉编码器效率。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen2.5-VL-32B-Instruct', 'Qwen2.5 VL 32B Instruct', 'chat', 131072, NULL, 0.00189, 0.00189, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.89, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.89, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Qwen2.5-VL-32B-Instruct 是通义千问团队推出的多模态大模型，是 Qwen2.5-VL 系列的一部分。该模型不仅精通识别常见物体，还能分析图像中的文本、图表、图标、图形和布局。它可作为视觉智能体，能够推理并动态操控工具，具备使用电脑和手机的能力。此外，这个模型可以精确定位图像中的对象，并为发票、表格等生成结构化输出。相比前代模型 Qwen2-VL，该版本在数学和问题解决能力方面通过强化学习得到了进一步提升，响应风格也更符合人类偏好。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen2.5-VL-72B-Instruct', 'Qwen2.5 VL 72B Instruct', 'chat', 131072, NULL, 0.00413, 0.00413, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4.13, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.13, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Qwen2.5-VL 是 Qwen2.5 系列中的视觉语言模型。该模型在多方面有显著提升：具备更强的视觉理解能力，能够识别常见物体、分析文本、图表和布局；作为视觉代理能够推理并动态指导工具使用；支持理解超过 1 小时的长视频并捕捉关键事件；能够通过生成边界框或点准确定位图像中的物体；支持生成结构化输出，尤其适用于发票、表格等扫描数据。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'internlm/internlm2_5-7b-chat', 'InternLM2.5 7B Chat (Free)', 'chat', 32768, NULL, 0, 0, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "InternLM2.5-7B-Chat 是一个开源的对话模型，基于 InternLM2 架构开发。该 7B 参数规模的模型专注于对话生成任务，支持中英双语交互。模型采用了最新的训练技术，旨在提供流畅、智能的对话体验。InternLM2.5-7B-Chat 适用于各种对话应用场景，包括但不限于智能客服、个人助手等领域", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Kwai-Kolors/Kolors', 'Kolors', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"prompt": {"default": ""}, "seed": {"default": null}, "size": {"default": "1024x1024", "enum": ["1024x1024", "960x1280", "768x1024", "720x1440", "720x1280"]}}, "released_at": "2024-07-06", "source": "builtin", "description": "Kolors 是由快手 Kolors 团队开发的基于潜在扩散的大规模文本到图像生成模型。该模型通过数十亿文本-图像对的训练，在视觉质量、复杂语义准确性以及中英文字符渲染方面展现出显著优势。它不仅支持中英文输入，在理解和生成中文特定内容方面也表现出色"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen-Image', 'Qwen-Image', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0.04, "strategy": "fixed", "unit": "image"}]}, "parameters": {"prompt": {"default": ""}, "seed": {"default": null}, "size": {"default": "1328x1328", "enum": ["1328x1328", "1584x1056", "1140x1472", "1664x928", "928x1664"]}}, "released_at": "2025-08-04", "source": "builtin", "description": "Qwen-Image 是由阿里巴巴通义千问团队发布的图像生成基础模型，拥有 200 亿参数。该模型在复杂的文本渲染和精确的图像编辑方面取得了显著进展，尤其擅长生成包含高保真度中英文文字的图像。Qwen-Image 不仅能够处理多行布局和段落级文本，还能在生成图像时保持排版的连贯性和上下文的和谐。除了卓越的文本渲染能力，该模型还支持广泛的艺术风格，从写实照片到动漫美学，能够灵活适应各种创作需求。同时，它也具备强大的图像编辑和理解能力，支持风格迁移、物体增删、细节增强、文本编辑乃至人体姿态操控等高级操作，旨在成为一个集语言、布局和图像于一体的综合性智能视觉创作与处理基础模型"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'siliconcloud'), 'Qwen/Qwen-Image-Edit-2509', 'Qwen-Image-Edit (2509)', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0.04, "strategy": "fixed", "unit": "image"}]}, "parameters": {"imageUrls": {"default": [], "maxCount": 3}, "prompt": {"default": ""}, "seed": {"default": null}}, "released_at": "2025-09-22", "source": "builtin", "description": "Qwen-Image-Edit-2509 是由阿里巴巴通义千问团队发布的 Qwen-Image 的图像编辑最新版本。该模型基于 20B 参数的 Qwen-Image 模型进行深入训练，将其独特的文本渲染能力成功扩展至图像编辑领域，实现了对图片中文字的精准编辑。此外，Qwen-Image-Edit 采用了一种创新的架构，将输入图像同时送入 Qwen2.5-VL（用于视觉语义控制）和 VAE Encoder（用于视觉外观控制），从而兼具语义与外观的双重编辑能力。这意味着它不仅支持元素的添加、删除或修改等局部外观编辑，还支持如 IP 创作、风格迁移等需要保持语义一致性的高阶视觉语义编辑。模型在多个公开基准测试中展现了顶尖（SOTA）的性能，使其成为一个强大的图像编辑基础模型"}', TRUE),
    -- spark
    ((SELECT id FROM ai_providers WHERE code = 'spark'), 'x1', 'Spark X1', 'chat', 32768, 32768, NULL, NULL, '{"abilities": {"reasoning": true, "search": true}, "settings": {"searchImpl": "params"}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "Spark X1 模型将进一步升级，在原来数学任务国内领先基础上，推理、文本生成、语言理解等通用任务实现效果对标 OpenAI o1 和 DeepSeek R1。", "reasoning": true, "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'spark'), 'lite', 'Spark Lite', 'chat', 8192, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Spark Lite 是一款轻量级大语言模型，具备极低的延迟与高效的处理能力，完全免费开放，支持实时在线搜索功能。其快速响应的特性使其在低算力设备上的推理应用和模型微调中表现出色，为用户带来出色的成本效益和智能体验，尤其在知识问答、内容生成及搜索场景下表现不俗。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'spark'), 'generalv3', 'Spark Pro', 'chat', 8192, 8192, NULL, NULL, '{"abilities": {"search": true}, "settings": {"searchImpl": "params"}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Spark Pro 是一款为专业领域优化的高性能大语言模型，专注数学、编程、医疗、教育等多个领域，并支持联网搜索及内置天气、日期等插件。其优化后模型在复杂知识问答、语言理解及高层次文本创作中展现出色表现和高效性能，是适合专业应用场景的理想选择。", "web_search": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'spark'), 'pro-128k', 'Spark Pro 128K', 'chat', 131072, 4096, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Spark Pro 128K 配置了特大上下文处理能力，能够处理多达128K的上下文信息，特别适合需通篇分析和长期逻辑关联处理的长文内容，可在复杂文本沟通中提供流畅一致的逻辑与多样的引用支持。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'spark'), 'generalv3.5', 'Spark Max', 'chat', 8192, 8192, NULL, NULL, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Spark Max 为功能最为全面的版本，支持联网搜索及众多内置插件。其全面优化的核心能力以及系统角色设定和函数调用功能，使其在各种复杂应用场景中的表现极为优异和出色。", "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'spark'), 'max-32k', 'Spark Max 32K', 'chat', 32768, 8192, NULL, NULL, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "internal"}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Spark Max 32K 配置了大上下文处理能力，更强的上下文理解和逻辑推理能力，支持32K tokens的文本输入，适用于长文档阅读、私有知识问答等场景", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'spark'), '4.0Ultra', 'Spark 4.0 Ultra', 'chat', 8192, 8192, NULL, NULL, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Spark Ultra 是星火大模型系列中最为强大的版本，在升级联网搜索链路同时，提升对文本内容的理解和总结能力。它是用于提升办公生产力和准确响应需求的全方位解决方案，是引领行业的智能产品。", "web_search": true, "function_calling": true}', TRUE),
    -- stepfun
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-3', 'Step 3', 'chat', 64000, NULL, NULL, NULL, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "strategy": "tiered", "tiers": [{"rate": 1.5, "upTo": 0.004}, {"rate": 4, "upTo": "infinity"}], "unit": "millionTokens"}, {"name": "textOutput", "strategy": "tiered", "tiers": [{"rate": 4, "upTo": 0.004}, {"rate": 8, "upTo": "infinity"}], "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 64000, "contextWindowTokens": 64000, "description": "该模型拥有强大的视觉感知和复杂推理能力。可准确完成跨领域的复杂知识理解、数学与视觉信息的交叉分析，以及日常生活中的各类视觉分析问题。", "vision": true, "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-r1-v-mini', 'Step R1 V Mini', 'chat', 100000, NULL, 0.0025, 0.008, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 100000, "contextWindowTokens": 100000, "description": "该模型是拥有强大的图像理解能力的推理大模型，能够处理图像和文字信息，经过深度思考后输出文本生成文本内容。该模型在视觉推理领域表现突出，同时拥有第一梯队的数学、代码、文本推理能力。上下文长度为100k。", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-1-8k', 'Step 1 8K', 'chat', 8000, NULL, 0.005, 0.02, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "小型模型，适合轻量级任务。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-1-32k', 'Step 1 32K', 'chat', 32000, NULL, 0.015, 0.07, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 70, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "支持中等长度的对话，适用于多种应用场景。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-1-256k', 'Step 1 256K', 'chat', 256000, NULL, 0.095, 0.3, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 95, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 300, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "具备超长上下文处理能力，尤其适合长文档分析。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-2-mini', 'Step 2 Mini', 'chat', 8000, NULL, 0.001, 0.002, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-14", "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "基于新一代自研Attention架构MFA的极速大模型，用极低成本达到和step1类似的效果，同时保持了更高的吞吐和更快响应时延。能够处理通用任务，在代码能力上具备特长。", "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-2-16k', 'Step 2 16K', 'chat', 16000, NULL, 0.038, 0.12, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 38, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 120, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "description": "支持大规模上下文交互，适合复杂对话场景。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-2-16k-exp', 'Step 2 16K Exp', 'chat', 16000, NULL, 0.038, 0.12, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 38, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 120, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-15", "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "description": "step-2模型的实验版本，包含最新的特性，滚动更新中。不推荐在正式生产环境使用。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-1v-8k', 'Step 1V 8K', 'chat', 8000, NULL, 0.005, 0.02, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8000, "contextWindowTokens": 8000, "description": "小型视觉模型，适合基本的图文任务。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-1v-32k', 'Step 1V 32K', 'chat', 32000, NULL, 0.015, 0.07, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 70, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "支持视觉输入，增强多模态交互体验。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-1o-vision-32k', 'Step 1o Vision 32K', 'chat', 32000, NULL, 0.015, 0.07, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 70, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-22", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "该模型拥有强大的图像理解能力。相比于 step-1v 系列模型，拥有更强的视觉性能。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-1o-turbo-vision', 'Step 1o Turbo Vision', 'chat', 32000, NULL, 0.0025, 0.008, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-14", "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "该模型拥有强大的图像理解能力，在数理、代码领域强于1o。模型比1o更小，输出速度更快。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-2x-large', 'Step 2X Large', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"prompt": {"default": ""}, "seed": {"default": null}, "size": {"default": "1024x1024", "enum": ["256x256", "512x512", "768x768", "1024x1024", "1280x800", "800x1280"]}, "steps": {"default": 50, "max": 100, "min": 1}}, "released_at": "2024-08-07", "source": "builtin", "description": "阶跃星辰新一代生图模型,该模型专注于图像生成任务,能够根据用户提供的文本描述,生成高质量的图像。新模型生成图片质感更真实，中英文文字生成能力更强。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-1x-medium', 'Step 1X Medium', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"prompt": {"default": ""}, "seed": {"default": null}, "size": {"default": "1024x1024", "enum": ["256x256", "512x512", "768x768", "1024x1024", "1280x800", "800x1280"]}, "steps": {"default": 50, "max": 100, "min": 1}}, "released_at": "2025-07-15", "source": "builtin", "description": "该模型拥有强大的图像生成能力，支持文本描述作为输入方式。具备原生的中文支持，能够更好的理解和处理中文文本描述，并且能够更准确地捕捉文本描述中的语义信息，并将其转化为图像特征，从而实现更精准的图像生成。模型能够根据输入生成高分辨率、高质量的图像，并具备一定的风格迁移能力。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'stepfun'), 'step-1x-edit', 'Step 1X Edit', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "seed": {"default": null}, "size": {"default": "1024x1024", "enum": ["512x512", "768x768", "1024x1024"]}, "steps": {"default": 28, "max": 100, "min": 1}}, "released_at": "2025-03-04", "source": "builtin", "description": "该模型专注于图像编辑任务，能够根据用户提供的图片和文本描述，对图片进行修改和增强。支持多种输入格式，包括文本描述和示例图像。模型能够理解用户的意图，并生成符合要求的图像编辑结果。"}', TRUE),
    -- taichu
    ((SELECT id FROM ai_providers WHERE code = 'taichu'), 'taichu_o1', 'Taichu O1', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "taichu_o1是新一代推理大模型，通过多模态交互和强化学习实现类人思维链，支持复杂决策推演，在保持高精度输出的同时展现可模型推理的思维路径，适用于策略分析与深度思考等场景。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'taichu'), 'taichu_llm', 'Taichu 2.0', 'chat', 32768, NULL, 0.002, 0.002, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "基于海量高质数据训练，具有更强的文本理解、内容创作、对话问答等能力", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'taichu'), 'taichu_vl', 'Taichu 2.0 VL', 'chat', 4096, NULL, 0.005, 0.005, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "融合了图像理解、知识迁移、逻辑归因等能力，在图文问答领域表现突出", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'taichu'), 'deepseek_r1', 'DeepSeek R1', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-R1 是一款强化学习（RL）驱动的推理模型，解决了模型中的重复性和可读性问题。在 RL 之前，DeepSeek-R1 引入了冷启动数据，进一步优化了推理性能。它在数学、代码和推理任务中与 OpenAI-o1 表现相当，并且通过精心设计的训练方法，提升了整体效果。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'taichu'), 'deepseek_r1_distill_qwen_14b', 'DeepSeek R1 Distill Qwen 14B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-R1-Distill-Qwen-14B 是基于 Qwen2.5-14B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，展现出优秀的推理能力。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'taichu'), 'deepseek_r1_distill_qwen_32b', 'DeepSeek R1 Distill Qwen 32B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-R1-Distill-Qwen-32B 是基于 Qwen2.5-32B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，在数学、编程和推理等多个领域展现出卓越的性能。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'taichu'), 'deepseek_r1_distill_llama_70b', 'DeepSeek R1 Distill Llama 70B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-R1-Distill-Llama-70B 是基于 Llama-3.3-70B-Instruct 经过蒸馏训练得到的模型。该模型是 DeepSeek-R1 系列的一部分，通过使用 DeepSeek-R1 生成的样本进行微调，在数学、编程和推理等多个领域展现出优秀的性能。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'taichu'), 'qwq_32b', 'QwQ 32B', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen 系列中等规模的推理模型。与传统的指令调优模型相比，具备思考和推理能力的 QwQ 在下游任务中，尤其是在解决难题时，能够显著提升性能。", "reasoning": true}', FALSE),
    -- tencentcloud
    ((SELECT id FROM ai_providers WHERE code = 'tencentcloud'), 'deepseek-r1', 'DeepSeek R1', 'chat', 65536, 16000, 0.004, 0.016, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "maxOutputTokens": 16000, "maxOutput": 16000, "description": "DeepSeek-R1 为671B 模型，使用强化学习训练，推理过程包含大量反思和验证，思维链长度可达数万字。 该系列模型在数学、代码以及各种复杂逻辑推理任务上推理效果优异，并为用户展现了完整的思考过程。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'tencentcloud'), 'deepseek-v3-0324', 'DeepSeek V3 0324', 'chat', 65536, 16000, 0.002, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "maxOutputTokens": 16000, "maxOutput": 16000, "description": "DeepSeek-V3-0324 为671B 参数 MoE 模型，在编程与技术能力、上下文理解与长文本处理等方面优势突出。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'tencentcloud'), 'deepseek-v3', 'DeepSeek V3', 'chat', 65536, 16000, 0.002, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "maxOutputTokens": 16000, "maxOutput": 16000, "description": "DeepSeek-V3 为671B 参数 MoE 模型，在百科知识、数学推理等多项任务上优势突出。"}', FALSE),
    -- togetherai
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Llama-3.3-70B-Instruct-Turbo', 'Llama 3.3 70B Instruct Turbo', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Meta Llama 3.3 多语言大语言模型 ( LLM ) 是 70B（文本输入/文本输出）中的预训练和指令调整生成模型。 Llama 3.3 指令调整的纯文本模型针对多语言对话用例进行了优化，并且在常见行业基准上优于许多可用的开源和封闭式聊天模型。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Llama-3.2-3B-Instruct-Turbo', 'Llama 3.2 3B Instruct Turbo', 'chat', 131072, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "LLaMA 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Llama-Vision-Free', 'Llama 3.2 11B Vision Instruct Turbo (Free)', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "LLaMA 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo', 'Llama 3.2 11B Vision Instruct Turbo', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "LLaMA 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo', 'Llama 3.2 90B Vision Instruct Turbo', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "LLaMA 3.2 旨在处理结合视觉和文本数据的任务。它在图像描述和视觉问答等任务中表现出色，跨越了语言生成和视觉推理之间的鸿沟。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', 'Llama 3.1 8B Instruct Turbo', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Llama 3.1 8B 模型采用FP8量化，支持高达131,072个上下文标记，是开源模型中的佼佼者，适合复杂任务，表现优异于许多行业基准。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'Llama 3.1 70B Instruct Turbo', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Llama 3.1 70B 模型经过精细调整，适用于高负载应用，量化至FP8提供更高效的计算能力和准确性，确保在复杂场景中的卓越表现。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'Llama 3.1 405B Instruct Turbo', 'chat', 130815, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 130815, "contextWindowTokens": 130815, "description": "405B 的 Llama 3.1 Turbo 模型，为大数据处理提供超大容量的上下文支持，在超大规模的人工智能应用中表现突出。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'nvidia/Llama-3.1-Nemotron-70B-Instruct-HF', 'Llama 3.1 Nemotron 70B', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Llama 3.1 Nemotron 70B 是由 NVIDIA 定制的大型语言模型，旨在提高 LLM 生成的响应对用户查询的帮助程度。该模型在 Arena Hard、AlpacaEval 2 LC 和 GPT-4-Turbo MT-Bench 等基准测试中表现出色，截至 2024 年 10 月 1 日，在所有三个自动对齐基准测试中排名第一。该模型使用 RLHF（特别是 REINFORCE）、Llama-3.1-Nemotron-70B-Reward 和 HelpSteer2-Preference 提示在 Llama-3.1-70B-Instruct 模型基础上进行训练"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Meta-Llama-3-8B-Instruct-Turbo', 'Llama 3 8B Instruct Turbo', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Llama 3 8B Instruct Turbo 是一款高效能的大语言模型，支持广泛的应用场景。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Meta-Llama-3-70B-Instruct-Turbo', 'Llama 3 70B Instruct Turbo', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Llama 3 70B Instruct Turbo 提供卓越的语言理解和生成能力，适合最苛刻的计算任务。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Meta-Llama-3-8B-Instruct-Lite', 'Llama 3 8B Instruct Lite', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Llama 3 8B Instruct Lite 适合资源受限的环境，提供出色的平衡性能。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Meta-Llama-3-70B-Instruct-Lite', 'Llama 3 70B Instruct Lite', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Llama 3 70B Instruct Lite 适合需要高效能和低延迟的环境。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Llama-3-8b-chat-hf', 'Llama 3 8B Instruct Reference', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Llama 3 8B Instruct Reference 提供多语言支持，涵盖丰富的领域知识。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Llama-3-70b-chat-hf', 'Llama 3 70B Instruct Reference', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Llama 3 70B Instruct Reference 是功能强大的聊天模型，支持复杂的对话需求。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Llama-2-13b-chat-hf', 'LLaMA-2 Chat (13B)', 'chat', 4096, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "LLaMA-2 Chat (13B) 提供优秀的语言处理能力和出色的交互体验。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'meta-llama/Llama-2-70b-hf', 'LLaMA-2 (70B)', 'chat', 4096, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "LLaMA-2 提供优秀的语言处理能力和出色的交互体验。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'codellama/CodeLlama-34b-Instruct-hf', 'CodeLlama 34B Instruct', 'chat', 16384, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "Code Llama 是一款专注于代码生成和讨论的 LLM，结合广泛的编程语言支持，适用于开发者环境。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'google/gemma-2-9b-it', 'Gemma 2 9B', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Gemma 2 9B 由Google开发，提供高效的指令响应和综合能力。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'google/gemma-2-27b-it', 'Gemma 2 27B', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Gemma 2 27B 是一款通用大语言模型，具有优异的性能和广泛的应用场景。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'google/gemma-2b-it', 'Gemma Instruct (2B)', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Gemma Instruct (2B) 提供基本的指令处理能力，适合轻量级应用。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'mistralai/Mistral-7B-Instruct-v0.3', 'Mistral (7B) Instruct v0.3', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Mistral (7B) Instruct v0.3 提供高效的计算能力和自然语言理解，适合广泛的应用。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'mistralai/Mistral-7B-Instruct-v0.2', 'Mistral (7B) Instruct v0.2', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Mistral (7B) Instruct v0.2 提供改进的指令处理能力和更精确的结果。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'mistralai/Mistral-7B-Instruct-v0.1', 'Mistral (7B) Instruct', 'chat', 8192, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Mistral (7B) Instruct 以高性能著称，适用于多种语言任务。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'mistralai/Mistral-7B-v0.1', 'Mistral (7B)', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Mistral 7B是一款紧凑但高性能的模型，擅长批量处理和简单任务，如分类和文本生成，具有良好的推理能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'Mixtral-8x7B Instruct (46.7B)', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Mixtral-8x7B Instruct (46.7B) 提供高容量的计算框架，适合大规模数据处理。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'mistralai/Mixtral-8x7B-v0.1', 'Mixtral-8x7B (46.7B)', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Mixtral 8x7B是一个稀疏专家模型，利用多个参数提高推理速度，适合处理多语言和代码生成任务。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'mistralai/Mixtral-8x22B-Instruct-v0.1', 'Mixtral-8x22B Instruct (141B)', 'chat', 65536, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "Mixtral-8x22B Instruct (141B) 是一款超级大语言模型，支持极高的处理需求。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'microsoft/WizardLM-2-8x22B', 'WizardLM-2 8x22B', 'chat', 65536, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "WizardLM 2 是微软AI提供的语言模型，在复杂对话、多语言、推理和智能助手领域表现尤为出色。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'deepseek-ai/DeepSeek-R1', 'DeepSeek-R1', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "DeepSeek-R1 系列通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆，超越 OpenAI-o1-mini 水平。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', 'DeepSeek R1 Distill Qwen 1.5B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B', 'DeepSeek R1 Distill Qwen 14B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'deepseek-ai/DeepSeek-R1-Distill-Llama-70B', 'DeepSeek R1 Distill Llama 70B', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-R1 蒸馏模型，通过强化学习与冷启动数据优化推理性能，开源模型刷新多任务标杆。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'deepseek-ai/DeepSeek-V3', 'DeepSeek-V3', 'chat', 16384, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "最新模型 DeepSeek-V3 多项评测成绩超越 Qwen2.5-72B 和 Llama-3.1-405B 等开源模型，性能对齐领军闭源模型 GPT-4o 与 Claude-3.5-Sonnet。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'deepseek-ai/deepseek-llm-67b-chat', 'DeepSeek LLM Chat (67B)', 'chat', 4096, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "DeepSeek LLM Chat (67B) 是创新的 AI 模型 提供深度语言理解和互动能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'Qwen/QwQ-32B-Preview', 'QwQ 32B Preview', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "QwQ模型是由 Qwen 团队开发的实验性研究模型，专注于增强 AI 推理能力。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'Qwen/Qwen2.5-7B-Instruct-Turbo', 'Qwen 2.5 7B Instruct Turbo', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5 是全新的大型语言模型系列，旨在优化指令式任务的处理。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'Qwen/Qwen2.5-72B-Instruct-Turbo', 'Qwen 2.5 72B Instruct Turbo', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5 是全新的大型语言模型系列，旨在优化指令式任务的处理。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'Qwen/Qwen2.5-Coder-32B-Instruct', 'Qwen 2.5 Coder 32B Instruct', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5 Coder 32B Instruct 是阿里云发布的代码特定大语言模型系列的最新版本。该模型在 Qwen2.5 的基础上，通过 5.5 万亿个 tokens 的训练，显著提升了代码生成、推理和修复能力。它不仅增强了编码能力，还保持了数学和通用能力的优势。模型为代码智能体等实际应用提供了更全面的基础"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'Qwen/Qwen2-72B-Instruct', 'Qwen 2 Instruct (72B)', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen 2 Instruct (72B) 为企业级应用提供精准的指令理解和响应。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'databricks/dbrx-instruct', 'DBRX Instruct', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "DBRX Instruct 提供高可靠性的指令处理能力，支持多行业应用。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'upstage/SOLAR-10.7B-Instruct-v1.0', 'Upstage SOLAR Instruct v1 (11B)', 'chat', 4096, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "Upstage SOLAR Instruct v1 (11B) 适用于精细化指令任务，提供出色的语言处理能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO', 'Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B)', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) 是高精度的指令模型，适用于复杂计算。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'Gryphe/MythoMax-L2-13b', 'MythoMax-L2 (13B)', 'chat', 4096, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "description": "MythoMax-L2 (13B) 是一种创新模型，适合多领域应用和复杂任务。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'togetherai'), 'togethercomputer/StripedHyena-Nous-7B', 'StripedHyena Nous (7B)', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "StripedHyena Nous (7B) 通过高效的策略和模型架构，提供增强的计算能力。"}', FALSE),
    -- upstage
    ((SELECT id FROM ai_providers WHERE code = 'upstage'), 'solar-pro', 'Solar Pro', 'chat', 32768, NULL, 0.00025, 0.00025, '{"pricing": {"units": [{"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-11-26", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Solar Pro 是 Upstage 推出的一款高智能LLM，专注于单GPU的指令跟随能力，IFEval得分80以上。目前支持英语，正式版本计划于2024年11月推出，将扩展语言支持和上下文长度。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'upstage'), 'solar-mini', 'Solar Mini', 'chat', 32768, NULL, 0.00015, 0.00015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-23", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Solar Mini 是一种紧凑型 LLM，性能优于 GPT-3.5，具备强大的多语言能力，支持英语和韩语，提供高效小巧的解决方案。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'upstage'), 'solar-mini-ja', 'Solar Mini (Ja)', 'chat', 32768, NULL, NULL, NULL, '{"released_at": "2025-01-23", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Solar Mini (Ja) 扩展了 Solar Mini 的能力，专注于日语，同时在英语和韩语的使用中保持高效和卓越性能。"}', FALSE),
    -- v0
    ((SELECT id FROM ai_providers WHERE code = 'v0'), 'v0-1.5-lg', 'v0-1.5-lg', 'chat', 512000, 32000, 0.015, 0.075, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 75, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 512000, "contextWindowTokens": 512000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "v0-1.5-lg 模型适用于高级思考或推理任务", "vision": true, "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'v0'), 'v0-1.5-md', 'v0-1.5-md', 'chat', 128000, 32000, 0.003, 0.015, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "v0-1.5-md 模型适用于日常任务和用户界面（UI）生成", "vision": true, "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'v0'), 'v0-1.0-md', 'v0-1.0-md', 'chat', 128000, 32000, 0.003, 0.015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "v0-1.0-md 模型是通过 v0 API 提供服务的旧版模型", "vision": true, "function_calling": true}', FALSE),
    -- vercelaigateway
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'google/gemini-2.5-pro', 'Gemini 2.5 Pro', 'chat', 1048576, NULL, 0.0025, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1048576, "contextWindowTokens": 1048576, "description": "Gemini 2.5 Pro 是我们最先进的推理 Gemini 模型，能够解决复杂问题。它具有 200 万 token 的上下文窗口，支持包括文本、图像、音频、视频和 PDF 文档在内的多模态输入。", "vision": true, "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'anthropic/claude-opus-4.1', 'Claude Opus 4.1', 'chat', 200000, NULL, 0.015, 0.075, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheWrite", "rate": 18.75, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "Claude Opus 4.1 是 Opus 4 的即插即用替代品，为实际编码和代理任务提供卓越的性能和精度。Opus 4.1 将最先进的编码性能提升到 SWE-bench Verified 的 74.5%，并以更高的严谨性和对细节的关注处理复杂的多步问题。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'anthropic/claude-opus-4', 'Claude Opus 4', 'chat', 200000, NULL, 0.015, 0.075, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheWrite", "rate": 18.75, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "Claude Opus 4 是 Anthropic 迄今为止最强大的模型，也是世界上最好的编码模型，在 SWE-bench (72.5%) 和 Terminal-bench (43.2%) 上领先。它为需要专注努力和数千个步骤的长期任务提供持续性能，能够连续工作数小时——显著扩展了 AI 代理的能力。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'anthropic/claude-sonnet-4', 'Claude Sonnet 4', 'chat', 200000, NULL, 0.003, 0.015, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheWrite", "rate": 3.75, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "Claude Sonnet 4 在 Sonnet 3.7 的行业领先能力基础上进行了显著改进，在编码方面表现出色，在 SWE-bench 上达到了最先进的 72.7%。该模型在性能和效率之间取得了平衡，适用于内部和外部用例，并通过增强的可控性实现对实现的更大控制。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/gpt-5', 'GPT-5', 'chat', 400000, NULL, 0.00125, 0.01, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["gpt5ReasoningEffort", "textVerbosity"]}, "pricing": {"units": [{"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.125, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "description": "GPT-5 是 OpenAI 的旗舰语言模型，在复杂推理、广泛的现实世界知识、代码密集型和多步代理任务方面表现出色。", "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/o3', 'o3', 'chat', 200000, NULL, 0.002, 0.008, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"]}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "OpenAI 的 o3 是最强大的推理模型，在编码、数学、科学和视觉感知方面设立了新的最先进水平。它擅长需要多方面分析的复杂查询，在分析图像、图表和图形方面具有特殊优势。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/o1', 'o1', 'chat', 200000, NULL, 0.015, 0.06, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"]}, "pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 7.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "OpenAI 的 o1 是旗舰推理模型，专为需要深度思考的复杂问题而设计。它为复杂多步任务提供了强大的推理能力和更高的准确性。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'anthropic/claude-3.7-sonnet', 'Claude 3.7 Sonnet', 'chat', 200000, NULL, 0.003, 0.015, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheWrite", "rate": 3.75, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "Claude 3.7 Sonnet 是第一个混合推理模型，也是 Anthropic 迄今为止最智能的模型。它在编码、内容生成、数据分析和规划任务方面提供了最先进的性能，在其前身 Claude 3.5 Sonnet 的软件工程和计算机使用能力基础上进行了构建。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'anthropic/claude-3.5-sonnet', 'Claude 3.5 Sonnet', 'chat', 200000, NULL, 0.003, 0.015, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheWrite", "rate": 3.75, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "Claude 3.5 Sonnet 在智能和速度之间达到了理想的平衡——特别是对于企业工作负载。与同类产品相比，它以更低的成本提供了强大的性能，并专为大规模 AI 部署中的高耐久性而设计。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'anthropic/claude-3-opus', 'Claude 3 Opus', 'chat', 200000, NULL, 0.015, 0.075, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheWrite", "rate": 18.75, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "Claude 3 Opus 是 Anthropic 最智能的模型，在高度复杂的任务上具有市场领先的性能。它能够以卓越的流畅度和类人理解力驾驭开放式提示和前所未见的场景。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/gpt-4o', 'GPT-4o', 'chat', 128000, NULL, 0.0025, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GPT-4o 来自 OpenAI，具有广泛的通用知识和领域专长，能够遵循自然语言的复杂指令并准确解决难题。它以更快、更便宜的 API 匹配 GPT-4 Turbo 的性能。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/gpt-5-mini', 'GPT-5 mini', 'chat', 400000, NULL, 0.00025, 0.002, '{"abilities": {"functionCall": true, "vision": true}, "settings": {"extendParams": ["gpt5ReasoningEffort", "textVerbosity"]}, "pricing": {"units": [{"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "description": "GPT-5 mini 是一个成本优化的模型，在推理/聊天任务方面表现出色。它在速度、成本和能力之间提供了最佳平衡。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/gpt-5-nano', 'GPT-5 nano', 'chat', 400000, NULL, 0.00005, 0.0004, '{"abilities": {"functionCall": true, "vision": true}, "settings": {"extendParams": ["gpt5ReasoningEffort", "textVerbosity"]}, "pricing": {"units": [{"name": "textInput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.005, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 400000, "contextWindowTokens": 400000, "description": "GPT-5 nano 是一个高吞吐量模型，在简单指令或分类任务方面表现出色。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/gpt-oss-120b', 'gpt-oss-120b', 'chat', 131072, NULL, 0.0001, 0.0005, '{"abilities": {"functionCall": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"]}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "极其能干的通用大型语言模型，具有强大、可控的推理能力", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/gpt-oss-20b', 'gpt-oss-20b', 'chat', 128000, NULL, 0.00007, 0.0003, '{"abilities": {"functionCall": true}, "settings": {"extendParams": ["reasoningEffort"]}, "pricing": {"units": [{"name": "textInput", "rate": 0.07, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "一个紧凑、开源权重的语言模型，针对低延迟和资源受限环境进行了优化，包括本地和边缘部署", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/o3-mini', 'o3-mini', 'chat', 200000, NULL, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"]}, "pricing": {"units": [{"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "o3-mini 是 OpenAI 最新的小型推理模型，在 o1-mini 的相同成本和延迟目标下提供高智能。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/o4-mini', 'o4-mini', 'chat', 200000, NULL, 0.0011, 0.0044, '{"abilities": {"functionCall": true, "vision": true}, "settings": {"extendParams": ["reasoningEffort"]}, "pricing": {"units": [{"name": "textInput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.275, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "OpenAI 的 o4-mini 提供快速、成本效益高的推理，在其尺寸上具有卓越性能，特别是在数学（AIME 基准测试中表现最佳）、编码和视觉任务方面。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/gpt-4.1', 'GPT-4.1', 'chat', 1047576, NULL, 0.002, 0.008, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "description": "GPT 4.1 是 OpenAI 的旗舰模型，适用于复杂任务。它非常适合跨领域解决问题。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'moonshotai/kimi-k2', 'Kimi K2', 'chat', 131072, NULL, 0.00055, 0.0022, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Kimi K2 是由月之暗面 AI 开发的大规模混合专家 (MoE) 语言模型，具有 1 万亿总参数和每次前向传递 320 亿激活参数。它针对代理能力进行了优化，包括高级工具使用、推理和代码合成。", "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'alibaba/qwen3-coder', 'Qwen3 Coder 480B A35B Instruct', 'chat', 262144, NULL, 0.0004, 0.0016, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 262144, "contextWindowTokens": 262144, "description": "Qwen3-Coder-480B-A35B-Instruct 是 Qwen 最具代理性的代码模型，在代理编码、代理浏览器使用和其他基础编码任务方面具有显著性能，达到了与 Claude Sonnet 相当的结果。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'alibaba/qwen-3-235b', 'Qwen3 235B A22B Instruct 2507', 'chat', 40960, NULL, 0.0002, 0.0006, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "description": "Qwen3 是 Qwen 系列中最新一代的大型语言模型，提供了一套全面的密集和混合专家 (MoE) 模型。基于广泛的训练构建，Qwen3 在推理、指令遵循、代理能力和多语言支持方面提供了突破性的进展。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'zai/glm-4.5', 'GLM-4.5', 'chat', 131072, NULL, 0.0006, 0.0022, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "GLM-4.5 系列模型是专门为智能体设计的基础模型。旗舰 GLM-4.5 集成了 3550 亿总参数（320 亿活跃），统一了推理、编码和代理能力以解决复杂的应用需求。作为混合推理系统，它提供双重操作模式。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'zai/glm-4.5-air', 'GLM 4.5 Air', 'chat', 128000, NULL, 0.0002, 0.0011, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GLM-4.5 和 GLM-4.5-Air 是我们最新的旗舰模型，专门设计为面向代理应用的基础模型。两者都利用混合专家 (MoE) 架构。GLM-4.5 的总参数数为 3550 亿，每次前向传递有 320 亿活跃参数，而 GLM-4.5-Air 采用更简化的设计，总参数数为 1060 亿，活跃参数为 120 亿。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'zai/glm-4.5v', 'GLM 4.5V', 'chat', 65536, NULL, 0.0006, 0.0018, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "GLM-4.5V 基于 GLM-4.5-Air 基础模型构建，继承了 GLM-4.1V-Thinking 的经过验证的技术，同时通过强大的 1060 亿参数 MoE 架构实现了有效的扩展。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'alibaba/qwen-3-32b', 'Qwen3 32B', 'chat', 40960, NULL, 0.0001, 0.0003, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "description": "Qwen3 是 Qwen 系列中最新一代的大型语言模型，提供了一套全面的密集和混合专家 (MoE) 模型。基于广泛的训练构建，Qwen3 在推理、指令遵循、代理能力和多语言支持方面提供了突破性的进展。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'alibaba/qwen-3-30b', 'Qwen3 30B A3B', 'chat', 40960, NULL, 0.00008, 0.0003, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.08, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "description": "Qwen3 是 Qwen 系列中最新一代的大型语言模型，提供了一套全面的密集和混合专家 (MoE) 模型。基于广泛的训练构建，Qwen3 在推理、指令遵循、代理能力和多语言支持方面提供了突破性的进展。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'alibaba/qwen-3-14b', 'Qwen3 14B', 'chat', 40960, NULL, 0.00006, 0.00024, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.06, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.24, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "description": "Qwen3 是 Qwen 系列中最新一代的大型语言模型，提供了一套全面的密集和混合专家 (MoE) 模型。基于广泛的训练构建，Qwen3 在推理、指令遵循、代理能力和多语言支持方面提供了突破性的进展。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'cohere/command-a', 'Command A', 'chat', 256000, NULL, 0.00025, 0.01, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "Command A 是 Cohere 迄今为止性能最强的模型，在工具使用、代理、检索增强生成 (RAG) 和多语言用例方面表现出色。Command A 的上下文长度为 256K，仅需两个 GPU 即可运行，与 Command R+ 08-2024 相比吞吐量提高了 150%。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'cohere/command-r', 'Command R', 'chat', 128000, NULL, 0.00015, 0.0006, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Command R 是一个针对对话交互和长上下文任务优化的大型语言模型。它定位于\"可扩展\"类别的模型，在高性能和强准确性之间取得平衡，使公司能够超越概念验证并进入生产。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'cohere/command-r-plus', 'Command R+', 'chat', 128000, NULL, 0.0025, 0.01, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Command R+ 是 Cohere 最新的大型语言模型，针对对话交互和长上下文任务进行了优化。它的目标是在性能上极其出色，使公司能够超越概念验证并进入生产。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'deepseek/deepseek-r1', 'DeepSeek R1 0528', 'chat', 128000, NULL, 0.00055, 0.00219, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.55, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.19, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "DeepSeek R1 模型已经进行了小版本升级，当前版本为 DeepSeek-R1-0528。在最新更新中，DeepSeek R1 通过利用增加的计算资源和在训练后引入算法优化机制，显著提高了推理深度和推理能力。该模型在数学、编程和一般逻辑等多个基准评估中表现出色，其整体性能现在正接近领先模型，如 O3 和 Gemini 2.5 Pro。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'deepseek/deepseek-v3', 'DeepSeek V3 0324', 'chat', 163840, NULL, 0.00077, 0.00077, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.77, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.77, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "具有增强推理能力的快速通用大型语言模型", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'deepseek/deepseek-v3.1-base', 'DeepSeek V3.1 Base', 'chat', 128000, NULL, 0.0001999, 0.0008001, '{"pricing": {"units": [{"name": "textInput", "rate": 0.1999, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.8001, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "DeepSeek V3.1 Base 是 DeepSeek V3 模型的改进版本。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'google/gemini-2.0-flash', 'Gemini 2.0 Flash', 'chat', 1048576, NULL, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1048576, "contextWindowTokens": 1048576, "description": "Gemini 2.0 Flash 提供下一代功能和改进的功能，包括卓越的速度、内置工具使用、多模态生成和 100 万 token 的上下文窗口。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'google/gemini-2.0-flash-lite', 'Gemini 2.0 Flash Lite', 'chat', 1048576, NULL, 0.000075, 0.0003, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1048576, "contextWindowTokens": 1048576, "description": "Gemini 2.0 Flash Lite 提供下一代功能和改进的功能，包括卓越的速度、内置工具使用、多模态生成和 100 万 token 的上下文窗口。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'google/gemini-2.5-flash', 'Gemini 2.5 Flash', 'chat', 1000000, NULL, 0.0003, 0.0025, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1000000, "contextWindowTokens": 1000000, "description": "Gemini 2.5 Flash 是一个思考模型，提供出色的全面能力。它旨在价格和性能之间取得平衡，支持多模态和 100 万 token 的上下文窗口。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'google/gemini-2.5-flash-lite', 'Gemini 2.5 Flash Lite', 'chat', 1048576, NULL, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1048576, "contextWindowTokens": 1048576, "description": "Gemini 2.5 Flash-Lite 是一个平衡、低延迟的模型，具有可配置的思考预算和工具连接性（例如，Google Search 接地和代码执行）。它支持多模态输入，并提供 100 万 token 的上下文窗口。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'google/gemma-2-9b', 'Gemma 2 9B IT', 'chat', 8192, NULL, 0.0002, 0.0002, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "由 Google 精心调整用于聊天目的的 90 亿参数开源模型。由 Groq 使用其自定义语言处理单元 (LPU) 硬件提供服务，以提供快速高效的推理。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'xai/grok-4', 'Grok 4', 'chat', 256000, NULL, 0.003, 0.015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "xAI 最新和最伟大的旗舰模型，在自然语言、数学和推理方面提供无与伦比的性能——完美的全能选手。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'xai/grok-3-mini-fast', 'Grok 3 Mini Fast Beta', 'chat', 131072, NULL, 0.0006, 0.004, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "xAI 的轻量级模型，在响应之前进行思考。非常适合不需要深厚领域知识的简单或基于逻辑的任务。原始思维轨迹可访问。快速模型变体在更快的基础设施上提供服务，提供比标准快得多的响应时间。增加的速度以每个输出 token 更高的成本为代价。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'xai/grok-3-mini', 'Grok 3 Mini Beta', 'chat', 131072, NULL, 0.0003, 0.0005, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "xAI 的轻量级模型，在响应之前进行思考。非常适合不需要深厚领域知识的简单或基于逻辑的任务。原始思维轨迹可访问。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'xai/grok-3-fast', 'Grok 3 Fast Beta', 'chat', 131072, NULL, 0.005, 0.025, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 25, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "xAI 的旗舰模型，在企业用例方面表现出色，如数据提取、编码和文本摘要。在金融、医疗保健、法律和科学领域拥有深厚的领域知识。快速模型变体在更快的基础设施上提供服务，提供比标准快得多的响应时间。增加的速度以每个输出 token 更高的成本为代价。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'xai/grok-3', 'Grok 3 Beta', 'chat', 131072, NULL, 0.003, 0.015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "xAI 的旗舰模型，在企业用例方面表现出色，如数据提取、编码和文本摘要。在金融、医疗保健、法律和科学领域拥有深厚的领域知识。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'xai/grok-2-vision', 'Grok 2 Vision', 'chat', 32768, NULL, 0.002, 0.01, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Grok 2 视觉模型在基于视觉的任务方面表现出色，在视觉数学推理 (MathVista) 和基于文档的问答 (DocVQA) 方面提供最先进的性能。它能够处理各种视觉信息，包括文档、图表、图表、屏幕截图和照片。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'xai/grok-2', 'Grok 2', 'chat', 131072, NULL, 0.002, 0.01, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Grok 2 是一个具有最先进推理能力的前沿语言模型。它在聊天、编码和推理方面具有先进能力，在 LMSYS 排行榜上优于 Claude 3.5 Sonnet 和 GPT-4-Turbo。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'meta/llama-3-70b', 'Llama 3 70B Instruct', 'chat', 8192, NULL, 0.00059, 0.00079, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.59, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.79, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "由 Meta 精心调整用于指令遵循目的的 700 亿参数开源模型。由 Groq 使用其自定义语言处理单元 (LPU) 硬件提供服务，以提供快速高效的推理。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'meta/llama-3-8b', 'Llama 3 8B Instruct', 'chat', 8192, NULL, 0.00005, 0.00008, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.08, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "由 Meta 精心调整用于指令遵循目的的 80 亿参数开源模型。由 Groq 使用其自定义语言处理单元 (LPU) 硬件提供服务，以提供快速高效的推理。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'meta/llama-3.1-70b', 'Llama 3.1 70B Instruct', 'chat', 128000, NULL, 0.00072, 0.00072, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.72, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.72, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Meta Llama 3 70B Instruct 的更新版本，包括扩展的 128K 上下文长度、多语言和改进的推理能力。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'meta/llama-3.1-8b', 'Llama 3.1 8B Instruct', 'chat', 131000, NULL, 0.00005, 0.00008, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.08, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131000, "contextWindowTokens": 131000, "description": "Llama 3.1 8B 支持 128K 上下文窗口，使其成为实时对话界面和数据分析的理想选择，同时与更大的模型相比提供显著的成本节约。由 Groq 使用其自定义语言处理单元 (LPU) 硬件提供服务，以提供快速高效的推理。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'meta/llama-3.2-11b', 'Llama 3.2 11B Vision Instruct', 'chat', 128000, NULL, 0.00016, 0.00016, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.16, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "指令调整的图像推理生成模型（文本 + 图像输入 / 文本输出），针对视觉识别、图像推理、标题生成和回答关于图像的一般问题进行了优化。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'meta/llama-3.2-1b', 'Llama 3.2 1B Instruct', 'chat', 128000, NULL, 0.0001, 0.0001, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "仅文本模型，支持设备上用例，如多语言本地知识检索、摘要和重写。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'meta/llama-3.2-3b', 'Llama 3.2 3B Instruct', 'chat', 128000, NULL, 0.00015, 0.00015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "仅文本模型，精心调整用于支持设备上用例，如多语言本地知识检索、摘要和重写。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'meta/llama-3.2-90b', 'Llama 3.2 90B Vision Instruct', 'chat', 128000, NULL, 0.00072, 0.00072, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.72, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.72, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "指令调整的图像推理生成模型（文本 + 图像输入 / 文本输出），针对视觉识别、图像推理、标题生成和回答关于图像的一般问题进行了优化。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'meta/llama-3.3-70b', 'Llama 3.3 70B Instruct', 'chat', 128000, NULL, 0.00072, 0.00072, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.72, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.72, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "性能与效率的完美结合。该模型支持高性能对话 AI，专为内容创建、企业应用和研究而设计，提供先进的语言理解能力，包括文本摘要、分类、情感分析和代码生成。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'meta/llama-4-maverick', 'Llama 4 Maverick 17B 128E Instruct', 'chat', 131072, NULL, 0.0002, 0.0006, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Llama 4 模型集合是原生多模态 AI 模型，支持文本和多模态体验。这些模型利用混合专家架构在文本和图像理解方面提供行业领先的性能。Llama 4 Maverick，一个 170 亿参数模型，具有 128 个专家。由 DeepInfra 提供服务。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'meta/llama-4-scout', 'Llama 4 Scout 17B 16E Instruct', 'chat', 131072, NULL, 0.0001, 0.0003, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Llama 4 模型集合是原生多模态 AI 模型，支持文本和多模态体验。这些模型利用混合专家架构在文本和图像理解方面提供行业领先的性能。Llama 4 Scout，一个 170 亿参数模型，具有 16 个专家。由 DeepInfra 提供服务。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'mistral/codestral', 'Mistral Codestral 25.01', 'chat', 256000, NULL, 0.0003, 0.0009, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "Mistral Codestral 25.01 是最先进的编码模型，针对低延迟、高频率用例进行了优化。精通 80 多种编程语言，它在中间填充 (FIM)、代码纠正和测试生成等任务上表现出色。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'mistral/devstral-small', 'Devstral Small', 'chat', 128000, NULL, 0.00007, 0.00028, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.07, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.28, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Devstral 是一个用于软件工程任务的代理大型语言模型，使其成为软件工程代理的绝佳选择。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'mistral/magistral-medium', 'Magistral Medium 2509', 'chat', 128000, NULL, 0.002, 0.005, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "复杂思维，由深刻理解支持，具有您可以遵循和验证的透明推理。该模型即使在任务中途切换语言时，也能在众多语言中保持高保真推理。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'mistral/magistral-small', 'Magistral Small 2506', 'chat', 128000, NULL, 0.0005, 0.0015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "复杂思维，由深刻理解支持，具有您可以遵循和验证的透明推理。该模型即使在任务中途切换语言时，也能在众多语言中保持高保真推理。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'mistral/ministral-3b', 'Ministral 3B', 'chat', 128000, NULL, 0.00004, 0.00004, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.04, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.04, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "一个紧凑、高效的模型，用于智能助手和本地分析等设备上任务，提供低延迟性能。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'mistral/ministral-8b', 'Ministral 8B', 'chat', 128000, NULL, 0.0001, 0.0001, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "一个更强大的模型，具有更快、内存高效的推理，是复杂工作流程和要求苛刻的边缘应用的理想选择。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'mistral/mistral-large', 'Mistral Large', 'chat', 32000, NULL, 0.002, 0.006, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "Mistral Large 是复杂任务的理想选择，这些任务需要大型推理能力或高度专业化——如合成文本生成、代码生成、RAG 或代理。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'mistral/mistral-small', 'Mistral Small', 'chat', 32000, NULL, 0.0001, 0.0003, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32000, "contextWindowTokens": 32000, "description": "Mistral Small 是简单任务的理想选择，这些任务可以批量完成——如分类、客户支持或文本生成。它以可承受的价格点提供出色的性能。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'mistral/mixtral-8x22b-instruct', 'Mixtral MoE 8x22B Instruct', 'chat', 65536, NULL, 0.0012, 0.0012, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "8x22b Instruct 模型。8x22b 是由 Mistral 提供服务的混合专家开源模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'mistral/pixtral-12b', 'Pixtral 12B 2409', 'chat', 128000, NULL, 0.00015, 0.00015, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "一个具有图像理解能力的 12B 模型，以及文本。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'mistral/pixtral-large', 'Pixtral Large', 'chat', 128000, NULL, 0.002, 0.006, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Pixtral Large 是我们多模态家族中的第二个模型，展示了前沿水平的图像理解。特别是，该模型能够理解文档、图表和自然图像，同时保持了 Mistral Large 2 的领先文本理解能力。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'inception/mercury-coder-small', 'Mercury Coder Small Beta', 'chat', 32768, NULL, 0.00025, 0.001, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Mercury Coder Small 是代码生成、调试和重构任务的理想选择，具有最小延迟。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'morph/morph-v3-fast', 'Morph V3 Fast', 'chat', 32768, NULL, 0.0008, 0.0012, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Morph 提供了一个专门的 AI 模型，将前沿模型（如 Claude 或 GPT-4o）建议的代码更改应用到您的现有代码文件中 FAST - 4500+ tokens/秒。它充当 AI 编码工作流程中的最后一步。支持 16k 输入 tokens 和 16k 输出 tokens。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'morph/morph-v3-large', 'Morph V3 Large', 'chat', 32768, NULL, 0.0009, 0.0019, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.9, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Morph 提供了一个专门的 AI 模型，将前沿模型（如 Claude 或 GPT-4o）建议的代码更改应用到您的现有代码文件中 FAST - 2500+ tokens/秒。它充当 AI 编码工作流程中的最后一步。支持 16k 输入 tokens 和 16k 输出 tokens。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/gpt-3.5-turbo', 'GPT-3.5 Turbo', 'chat', 16385, NULL, 0.0005, 0.0015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16385, "contextWindowTokens": 16385, "description": "OpenAI 在 GPT-3.5 系列中最能干且最具成本效益的模型，针对聊天目的进行了优化，但在传统完成任务中也表现良好。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/gpt-3.5-turbo-instruct', 'GPT-3.5 Turbo Instruct', 'chat', 8192, NULL, 0.0015, 0.002, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "与 GPT-3 时代模型类似的能力。与传统的完成端点兼容，而不是聊天完成端点。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/gpt-4-turbo', 'GPT-4 Turbo', 'chat', 128000, NULL, 0.01, 0.03, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "来自 OpenAI 的 gpt-4-turbo 具有广泛的通用知识和领域专长，使其能够遵循自然语言的复杂指令并准确解决困难问题。它的知识截止日期为 2023 年 4 月，上下文窗口为 128,000 个 token。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/gpt-4.1-mini', 'GPT-4.1 mini', 'chat', 1047576, NULL, 0.0004, 0.0016, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "description": "GPT 4.1 mini 在智能、速度和成本之间取得了平衡，使其成为许多用例的有吸引力的模型。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/gpt-4.1-nano', 'GPT-4.1 nano', 'chat', 1047576, NULL, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1047576, "contextWindowTokens": 1047576, "description": "GPT-4.1 nano 是最快、最具成本效益的 GPT 4.1 模型。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/gpt-4o-mini', 'GPT-4o mini', 'chat', 128000, NULL, 0.00015, 0.0006, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "GPT-4o mini 来自 OpenAI 是他们最先进且最具成本效益的小模型。它是多模态的（接受文本或图像输入并输出文本），并且比 gpt-3.5-turbo 具有更高的智能性，但速度同样快。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'perplexity/sonar', 'Sonar', 'chat', 127000, NULL, 0.001, 0.001, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 127000, "contextWindowTokens": 127000, "description": "Perplexity 的轻量级产品，具有搜索接地能力，比 Sonar Pro 更快、更便宜。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'perplexity/sonar-pro', 'Sonar Pro', 'chat', 200000, NULL, 0.003, 0.015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "Perplexity 的旗舰产品，具有搜索接地能力，支持高级查询和后续操作。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'perplexity/sonar-reasoning', 'Sonar Reasoning', 'chat', 127000, NULL, 0.001, 0.005, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 127000, "contextWindowTokens": 127000, "description": "一个专注于推理的模型，在响应中输出思维链 (CoT)，提供具有搜索接地的详细解释。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'perplexity/sonar-reasoning-pro', 'Sonar Reasoning Pro', 'chat', 127000, NULL, 0.002, 0.008, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 127000, "contextWindowTokens": 127000, "description": "一个高级推理聚焦模型，在响应中输出思维链 (CoT)，提供具有增强搜索能力和每个请求多个搜索查询的综合解释。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'vercel/v0-1.0-md', 'v0-1.0-md', 'chat', 128000, NULL, 0.003, 0.015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "访问 v0 背后的模型以生成、修复和优化现代 Web 应用，具有特定框架的推理和最新知识。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'vercel/v0-1.5-md', 'v0-1.5-md', 'chat', 128000, NULL, 0.003, 0.015, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "访问 v0 背后的模型以生成、修复和优化现代 Web 应用，具有特定框架的推理和最新知识。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'amazon/nova-lite', 'Nova Lite', 'chat', 300000, NULL, 0.00006, 0.00024, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.06, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.24, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 300000, "contextWindowTokens": 300000, "description": "一个非常低成本的多模态模型，处理图像、视频和文本输入的速度极快。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'amazon/nova-micro', 'Nova Micro', 'chat', 128000, NULL, 0.000035, 0.00014, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.035, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.14, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "一个仅文本模型，以非常低的成本提供最低延迟的响应。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'anthropic/claude-3.5-haiku', 'Claude 3.5 Haiku', 'chat', 200000, NULL, 0.0008, 0.004, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.08, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheWrite", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "Claude 3.5 Haiku 是我们最快模型的下一代。与 Claude 3 Haiku 的速度相似，Claude 3.5 Haiku 在每个技能集上都得到了改进，并在许多智能基准测试中超越了我们上一代最大的模型 Claude 3 Opus。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'anthropic/claude-3-haiku', 'Claude 3 Haiku', 'chat', 200000, NULL, 0.00025, 0.00125, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.03, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput_cacheWrite", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "Claude 3 Haiku 是 Anthropic 迄今为止最快的模型，专为通常涉及较长提示的企业工作负载而设计。Haiku 可以快速分析大量文档，如季度文件、合同或法律案件，成本是其性能等级中其他模型的一半。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'deepseek/deepseek-r1-distill-llama-70b', 'DeepSeek R1 Distill Llama 70B', 'chat', 131072, NULL, 0.00075, 0.00099, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.99, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "DeepSeek-R1-Distill-Llama-70B 是 70B Llama 模型的蒸馏、更高效变体。它在文本生成任务中保持强大性能，减少计算开销以便于部署和研究。由 Groq 使用其自定义语言处理单元 (LPU) 硬件提供服务，以提供快速高效的推理。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'amazon/nova-pro', 'Nova Pro', 'chat', 300000, NULL, 0.0008, 0.0032, '{"abilities": {"functionCall": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3.2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 300000, "contextWindowTokens": 300000, "description": "一个高度能干的多模态模型，具有准确性、速度和成本的最佳组合，适用于广泛的任务。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'amazon/titan-embed-text-v2', 'Titan Text Embeddings V2', 'embedding', NULL, NULL, 0.00002, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 0.02, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "description": "Amazon Titan Text Embeddings V2 是一个轻量级、高效的多语言嵌入模型，支持 1024、512 和 256 维度。", "maxDimension": 1024}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'google/gemini-embedding-001', 'Gemini Embedding 001', 'embedding', NULL, NULL, 0.00015, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "description": "最先进的嵌入模型，在英语、多语言和代码任务中具有出色的性能。", "maxDimension": 768}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'google/text-embedding-005', 'Text Embedding 005', 'embedding', NULL, NULL, 0.000025, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "description": "针对代码和英语语言任务优化的英语聚焦文本嵌入模型。", "maxDimension": 768}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'google/text-multilingual-embedding-002', 'Text Multilingual Embedding 002', 'embedding', NULL, NULL, 0.000025, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "description": "针对跨语言任务优化的多语言文本嵌入模型，支持多种语言。", "maxDimension": 768}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'cohere/embed-v4.0', 'Embed v4.0', 'embedding', NULL, NULL, 0.00012, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 0.12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "description": "一个允许对文本、图像或混合内容进行分类或转换为嵌入的模型。", "maxDimension": 1024}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'mistral/codestral-embed', 'Codestral Embed', 'embedding', NULL, NULL, 0.00015, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "description": "可以嵌入代码数据库和存储库以支持编码助手的代码嵌入模型。", "maxDimension": 1024}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'mistral/mistral-embed', 'Mistral Embed', 'embedding', NULL, NULL, 0.0001, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "description": "用于语义搜索、相似性、聚类和 RAG 工作流的通用文本嵌入模型。", "maxDimension": 1024}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/text-embedding-3-large', 'text-embedding-3-large', 'embedding', NULL, NULL, 0.00013, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 0.13, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "description": "OpenAI 最能干的嵌入模型，适用于英语和非英语任务。", "maxDimension": 3072}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/text-embedding-3-small', 'text-embedding-3-small', 'embedding', NULL, NULL, 0.00002, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 0.02, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "description": "OpenAI 改进的、性能更高的 ada 嵌入模型版本。", "maxDimension": 1536}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vercelaigateway'), 'openai/text-embedding-ada-002', 'text-embedding-ada-002', 'embedding', NULL, NULL, 0.0001, NULL, '{"pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "description": "OpenAI 的传统文本嵌入模型。", "maxDimension": 1536}', FALSE),
    -- vertexai
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'gemini-2.5-pro', 'Gemini 2.5 Pro', 'chat', 1114112, 65536, 0.00125, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.31, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-17", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Pro 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'gemini-2.5-pro-preview-05-06', 'Gemini 2.5 Pro Preview 05-06', 'chat', 1114112, 65536, 0.00125, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-05-06", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Pro Preview 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'gemini-2.5-pro-preview-03-25', 'Gemini 2.5 Pro Preview 03-25', 'chat', 1114112, 65536, 0.00125, 0.01, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-09", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Pro Preview 是 Google 最先进的思维模型，能够对代码、数学和STEM领域的复杂问题进行推理，以及使用长上下文分析大型数据集、代码库和文档。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'gemini-2.5-flash', 'Gemini 2.5 Flash', 'chat', 1114112, 65536, 0.0003, 0.0025, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-17", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Flash 是 Google 性价比最高的模型，提供全面的功能。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'gemini-2.5-flash-preview-04-17', 'Gemini 2.5 Flash Preview 04-17', 'chat', 1114112, 65536, 0.00015, 0.0035, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-17", "source": "builtin", "maxToken": 1114112, "contextWindowTokens": 1114112, "maxOutputTokens": 65536, "maxOutput": 65536, "description": "Gemini 2.5 Flash Preview 是 Google 性价比最高的模型，提供全面的功能。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'gemini-2.5-flash-image-preview', 'Nano Banana', 'chat', 40960, 8192, 0.0003, 0.0025, '{"abilities": {"imageOutput": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-26", "source": "builtin", "maxToken": 40960, "contextWindowTokens": 40960, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Nano Banana 是 Google 最新、最快、最高效的原生多模态模型，它允许您通过对话生成和编辑图像。", "vision": true, "image_generation": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'gemini-2.5-flash-lite', 'Gemini 2.5 Flash-Lite', 'chat', 1064000, 64000, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.025, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-22", "source": "builtin", "maxToken": 1064000, "contextWindowTokens": 1064000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Gemini 2.5 Flash-Lite 是 Google 最小、性价比最高的模型，专为大规模使用而设计。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'gemini-2.5-flash-lite-preview-06-17', 'Gemini 2.5 Flash-Lite Preview 06-17', 'chat', 1064000, 64000, 0.0001, 0.0004, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["thinkingBudget"], "searchImpl": "params", "searchProvider": "google"}, "pricing": {"units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-06-17", "source": "builtin", "maxToken": 1064000, "contextWindowTokens": 1064000, "maxOutputTokens": 64000, "maxOutput": 64000, "description": "Gemini 2.5 Flash-Lite Preview 是 Google 最小、性价比最高的模型，专为大规模使用而设计。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'gemini-2.0-flash', 'Gemini 2.0 Flash', 'chat', 1056768, 8192, 0.00015, 0.0006, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.0375, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-05", "source": "builtin", "maxToken": 1056768, "contextWindowTokens": 1056768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 2.0 Flash 提供下一代功能和改进，包括卓越的速度、原生工具使用、多模态生成和1M令牌上下文窗口。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'gemini-2.0-flash-lite', 'Gemini 2.0 Flash-Lite', 'chat', 1056768, 8192, 0.000075, 0.0003, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.018, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-02-05", "source": "builtin", "maxToken": 1056768, "contextWindowTokens": 1056768, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 2.0 Flash 模型变体，针对成本效益和低延迟等目标进行了优化。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'gemini-1.5-flash-002', 'Gemini 1.5 Flash 002', 'chat', 1008192, 8192, 0.000075, 0.0003, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-25", "source": "builtin", "maxToken": 1008192, "contextWindowTokens": 1008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Flash 002 是一款高效的多模态模型，支持广泛应用的扩展。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'gemini-1.5-pro-002', 'Gemini 1.5 Pro 002', 'chat', 2008192, 8192, 0.00125, 0.0025, '{"abilities": {"functionCall": true, "vision": true}, "pricing": {"units": [{"name": "textInput", "rate": 1.25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-09-24", "source": "builtin", "maxToken": 2008192, "contextWindowTokens": 2008192, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "Gemini 1.5 Pro 002 是最新的生产就绪模型，提供更高质量的输出，特别在数学、长上下文和视觉任务方面有显著提升。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'gemini-2.5-flash-image:image', 'Nano Banana', 'image', NULL, NULL, 0.0003, 0.0025, '{"pricing": {"units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "imageOutput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-26", "source": "builtin", "description": "Nano Banana 是 Google 最新、最快、最高效的原生多模态模型，它允许您通过对话生成和编辑图像。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'imagen-4.0-generate-001', 'Imagen 4', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.04, "strategy": "fixed", "unit": "image"}]}, "released_at": "2025-08-15", "source": "builtin", "description": "Imagen 4th generation text-to-image model series", "organization": "Deepmind"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'imagen-4.0-ultra-generate-001', 'Imagen 4 Ultra', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.06, "strategy": "fixed", "unit": "image"}]}, "released_at": "2025-08-15", "source": "builtin", "description": "Imagen 4th generation text-to-image model series Ultra version", "organization": "Deepmind"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'vertexai'), 'imagen-4.0-fast-generate-001', 'Imagen 4 Fast', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"units": [{"name": "imageGeneration", "rate": 0.02, "strategy": "fixed", "unit": "image"}]}, "released_at": "2025-08-15", "source": "builtin", "description": "Imagen 4th generation text-to-image model series Fast version", "organization": "Deepmind"}', TRUE),
    -- vllm
    ((SELECT id FROM ai_providers WHERE code = 'vllm'), 'meta-llama/Meta-Llama-3.1-70B', 'Llama 3.1 70B', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Llama 3.1 是 Meta 推出的领先模型，支持高达 405B 参数，可应用于复杂对话、多语言翻译和数据分析领域。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'vllm'), 'meta-llama/Meta-Llama-3.1-405B-Instruct', 'Llama 3.1 405B Instruct', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Llama 3.1 是 Meta 推出的领先模型，支持高达 405B 参数，可应用于复杂对话、多语言翻译和数据分析领域。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vllm'), 'google/gemma-2-9b', 'Gemma 2 9B', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Gemma 2 是 Google 推出的高效模型，涵盖从小型应用到复杂数据处理的多种应用场景。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vllm'), 'google/gemma-2-27b', 'Gemma 2 27B', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Gemma 2 是 Google 推出的高效模型，涵盖从小型应用到复杂数据处理的多种应用场景。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vllm'), 'mistralai/Mistral-7B-Instruct-v0.1', 'Mistral 7B Instruct v0.1', 'chat', 8192, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "Mistral (7B) Instruct 以高性能著称，适用于多种语言任务。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vllm'), 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'Mistral 8x7B Instruct v0.1', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Mixtral-8x7B Instruct (46.7B) 提供高容量的计算框架，适合大规模数据处理。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'vllm'), 'deepseek-ai/DeepSeek-V3', 'DeepSeek V3', 'chat', 65536, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "DeepSeek-V3 是一款拥有 6710 亿参数的混合专家（MoE）语言模型，采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，结合无辅助损失的负载平衡策略，优化推理和训练效率。通过在 14.8 万亿高质量tokens上预训练，并进行监督微调和强化学习，DeepSeek-V3 在性能上超越其他开源模型，接近领先闭源模型。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'vllm'), 'Qwen/QwQ-32B-Preview', 'QwQ 32B Preview', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen QwQ 是由 Qwen 团队开发的实验研究模型，专注于提升AI推理能力。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'vllm'), 'Qwen/Qwen2-7B-Instruct', 'Qwen2 7B Instruct', 'chat', 32768, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2-7B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 7B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力。Qwen2-7B-Instruct 在多项评测中均优于 Qwen1.5-7B-Chat，显示出显著的性能提升"}', TRUE),
    -- volcengine
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'deepseek-v3.1', 'DeepSeek V3.1', 'chat', 131072, 32768, 0.004, 0.012, '{"abilities": {"functionCall": true, "reasoning": true}, "settings": {"extendParams": ["enableReasoning"]}, "config": {"deploymentName": "deepseek-v3-1-terminus"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput_cacheRead", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "DeepSeek-V3.1 是深度求索全新推出的混合推理模型，支持思考与非思考2种推理模式，较 DeepSeek-R1-0528 思考效率更高。经 Post-Training 优化，Agent 工具使用与智能体任务表现大幅提升。支持 128k 上下文窗口，输出长度支持最大 64k tokens。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'kimi-k2', 'Kimi K2', 'chat', 131072, 32768, 0.004, 0.016, '{"abilities": {"functionCall": true}, "config": {"deploymentName": "kimi-k2-250905"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput_cacheRead", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "Kimi-K2 是一款Moonshot AI推出的具备超强代码和 Agent 能力的 MoE 架构基础模型，总参数 1T，激活参数 32B。在通用知识推理、编程、数学、Agent 等主要类别的基准性能测试中，K2 模型的性能超过其他主流开源模型。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-seed-1.6-vision', 'Doubao Seed 1.6 Vision', 'chat', 256000, 32000, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["enableReasoning"]}, "config": {"deploymentName": "doubao-seed-1-6-vision-250815"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 0.8, "[0.032, 0.128]": 2.4, "[0.128, infinity]": 4.8}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 8, "[0.032, 0.128]": 16, "[0.128, infinity]": 24}, "pricingParams": ["textInputRange"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "Doubao-Seed-1.6-vision 视觉深度思考模型，在教育、图像审核、巡检与安防和AI 搜索问答等场景下展现出更强的通用多模态理解和推理能力。支持 256k 上下文窗口，输出长度支持最大 64k tokens。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-seed-1.6-thinking', 'Doubao Seed 1.6 Thinking', 'chat', 256000, 32000, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "config": {"deploymentName": "doubao-seed-1-6-thinking-250715"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 0.8, "[0.032, 0.128]": 1.2, "[0.128, infinity]": 2.4}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 8, "[0.032, 0.128]": 16, "[0.128, infinity]": 24}, "pricingParams": ["textInputRange"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "Doubao-Seed-1.6-thinking模型思考能力大幅强化， 对比Doubao-1.5-thinking-pro，在Coding、Math、 逻辑推理等基础能力上进一步提升， 支持视觉理解。 支持 256k 上下文窗口，输出长度支持最大 16k tokens。", "vision": true, "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-seed-1.6', 'Doubao Seed 1.6', 'chat', 256000, 32000, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["gpt5ReasoningEffort"]}, "config": {"deploymentName": "doubao-seed-1-6-251015"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 0.8, "[0.032, 0.128]": 1.2, "[0.128, infinity]": 2.4}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]_[0, 0.0002]": 2, "[0, 0.032]_[0.0002, infinity]": 8, "[0.032, 0.128]_[0, infinity]": 16, "[0.128, infinity]_[0, infinity]": 24}, "pricingParams": ["textInputRange", "textOutputRange"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "Doubao-Seed-1.6全新多模态深度思考模型，同时支持auto/thinking/non-thinking三种思考模式。 non-thinking模式下，模型效果对比Doubao-1.5-pro/250115大幅提升。支持 256k 上下文窗口，输出长度支持最大 16k tokens。", "vision": true, "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-seed-1.6-lite', 'Doubao Seed 1.6 Lite', 'chat', 256000, 32000, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["gpt5ReasoningEffort"]}, "config": {"deploymentName": "doubao-seed-1-6-lite-251015"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 0.3, "[0.032, 0.128]": 0.6, "[0.128, 0.256]": 1.2}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]_[0, 0.0002]": 0.6, "[0, 0.032]_[0.0002, infinity]": 2.4, "[0.032, 0.128]_[0, infinity]": 4, "[0.128, 0.256]_[0, infinity]": 12}, "pricingParams": ["textInputRange", "textOutputRange"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.06, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "Doubao-Seed-1.6-lite 全新多模态深度思考模型，支持思考程度可调节（reasoning effort），即 Minimal、Low、Medium、High 四种模式，更强性价比，常见任务的最佳选择，上下文窗口至256k。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-seed-1.6-flash', 'Doubao Seed 1.6 Flash', 'chat', 256000, 32000, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["enableReasoning"]}, "config": {"deploymentName": "doubao-seed-1-6-flash-250828"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 0.15, "[0.032, 0.128]": 0.3, "[0.128, infinity]": 0.6}, "pricingParams": ["textInputRange"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 1.5, "[0.032, 0.128]": 3, "[0.128, infinity]": 6}, "pricingParams": ["textInputRange"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}, {"name": "textInput_cacheRead", "rate": 0.03, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "maxOutputTokens": 32000, "maxOutput": 32000, "description": "Doubao-Seed-1.6-flash推理速度极致的多模态深度思考模型，TPOT仅需10ms； 同时支持文本和视觉理解，文本理解能力超过上一代lite，视觉理解比肩友商pro系列模型。支持 256k 上下文窗口，输出长度支持最大 16k tokens。", "vision": true, "reasoning": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-1.5-ui-tars', 'Doubao 1.5 UI TARS', 'chat', 131072, 16000, 0.0035, 0.012, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["thinking"]}, "config": {"deploymentName": "doubao-1-5-ui-tars-250428"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16000, "maxOutput": 16000, "description": "Doubao-1.5-UI-TARS 是一款原生面向图形界面交互（GUI）的Agent模型。通过感知、推理和行动等类人的能力，与 GUI 进行无缝交互。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-1.5-thinking-vision-pro', 'Doubao 1.5 Thinking Vision Pro', 'chat', 131072, 16000, 0.003, 0.009, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["thinking"]}, "config": {"deploymentName": "doubao-1-5-thinking-vision-pro-250428"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16000, "maxOutput": 16000, "description": "全新视觉深度思考模型，具备更强的通用多模态理解和推理能力，在 59 个公开评测基准中的 37 个上取得 SOTA 表现。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-1.5-thinking-pro', 'Doubao 1.5 Thinking Pro', 'chat', 131072, 16000, 0.004, 0.016, '{"abilities": {"functionCall": true, "reasoning": true}, "config": {"deploymentName": "doubao-1-5-thinking-pro-250415"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16000, "maxOutput": 16000, "description": "Doubao-1.5全新深度思考模型，在数学、编程、科学推理等专业领域及创意写作等通用任务中表现突出，在AIME 2024、Codeforces、GPQA等多项权威基准上达到或接近业界第一梯队水平。支持128k上下文窗口，16k输出。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-1.5-thinking-pro-m', 'Doubao 1.5 Thinking Pro M', 'chat', 131072, 16000, 0.004, 0.016, '{"abilities": {"functionCall": true, "reasoning": true, "vision": true}, "settings": {"extendParams": ["thinking"]}, "config": {"deploymentName": "doubao-1-5-thinking-pro-m-250428"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16000, "maxOutput": 16000, "description": "Doubao-1.5全新深度思考模型 (m 版本自带原生多模态深度推理能力)，在数学、编程、科学推理等专业领域及创意写作等通用任务中表现突出，在AIME 2024、Codeforces、GPQA等多项权威基准上达到或接近业界第一梯队水平。支持128k上下文窗口，16k输出。", "vision": true, "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'deepseek-r1', 'DeepSeek R1', 'chat', 131072, 16384, 0.004, 0.016, '{"abilities": {"functionCall": true, "reasoning": true}, "config": {"deploymentName": "deepseek-r1-250528"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "0528最新版本上线，DeepSeek-R1 在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能比肩 OpenAI o1 正式版。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'deepseek-r1-distill-qwen-32b', 'DeepSeek R1 Distill Qwen 32B', 'chat', 65536, 8192, 0.0015, 0.006, '{"abilities": {"functionCall": true, "reasoning": true}, "config": {"deploymentName": "deepseek-r1-distill-qwen-32b-250120"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "DeepSeek-R1-Distill 模型是在开源模型的基础上通过微调训练得到的，训练过程中使用了由 DeepSeek-R1 生成的样本数据。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'deepseek-r1-distill-qwen-7b', 'DeepSeek R1 Distill Qwen 7B', 'chat', 65536, 8192, 0.0006, 0.0024, '{"abilities": {"functionCall": true, "reasoning": true}, "config": {"deploymentName": "deepseek-r1-distill-qwen-7b-250120"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "DeepSeek-R1-Distill 模型是在开源模型的基础上通过微调训练得到的，训练过程中使用了由 DeepSeek-R1 生成的样本数据。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'deepseek-v3', 'DeepSeek V3', 'chat', 128000, 16384, 0.002, 0.008, '{"abilities": {"functionCall": true}, "config": {"deploymentName": "deepseek-v3-250324"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "DeepSeek-V3 是一款由深度求索公司自研的MoE模型。DeepSeek-V3 多项评测成绩超越了 Qwen2.5-72B 和 Llama-3.1-405B 等其他开源模型，并在性能上和世界顶尖的闭源模型 GPT-4o 以及 Claude-3.5-Sonnet 不分伯仲。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-1.5-pro-32k', 'Doubao 1.5 Pro 32k', 'chat', 128000, 16384, 0.0008, 0.002, '{"abilities": {"functionCall": true}, "config": {"deploymentName": "doubao-1-5-pro-32k-250115"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "Doubao-1.5-pro 全新一代主力模型，性能全面升级，在知识、代码、推理、等方面表现卓越。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-1.5-pro-256k', 'Doubao 1.5 Pro 256k', 'chat', 256000, 12288, 0.005, 0.009, '{"config": {"deploymentName": "doubao-1-5-pro-256k-250115"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "maxOutputTokens": 12288, "maxOutput": 12288, "description": "Doubao-1.5-pro-256k 基于 Doubao-1.5-Pro 全面升级版，整体效果大幅提升 10%。支持 256k 上下文窗口的推理，输出长度支持最大 12k tokens。更高性能、更大窗口、超高性价比，适用于更广泛的应用场景。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-1.5-lite-32k', 'Doubao 1.5 Lite 32k', 'chat', 32768, 12288, 0.0003, 0.0006, '{"abilities": {"functionCall": true}, "config": {"deploymentName": "doubao-1-5-lite-32k-250115"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 12288, "maxOutput": 12288, "description": "Doubao-1.5-lite 全新一代轻量版模型，极致响应速度，效果与时延均达到全球一流水平。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-1.5-vision-pro-32k', 'Doubao 1.5 Vision Pro 32k', 'chat', 32768, 12288, 0.003, 0.009, '{"abilities": {"functionCall": true, "vision": true}, "config": {"deploymentName": "doubao-1-5-vision-pro-32k-250115"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-01-15", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 12288, "maxOutput": 12288, "description": "Doubao-1.5-vision-pro 全新升级的多模态大模型，支持任意分辨率和极端长宽比图像识别，增强视觉推理、文档识别、细节信息理解和指令遵循能力。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-1.5-vision-pro', 'Doubao 1.5 Vision Pro', 'chat', 128000, 16384, 0.003, 0.009, '{"abilities": {"functionCall": true, "vision": true}, "config": {"deploymentName": "doubao-1-5-vision-pro-250328"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-28", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "Doubao-1.5-vision-pro 全新升级的多模态大模型，支持任意分辨率和极端长宽比图像识别，增强视觉推理、文档识别、细节信息理解和指令遵循能力。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-1.5-vision-lite', 'Doubao 1.5 Vision Lite', 'chat', 128000, 16384, 0.0015, 0.0045, '{"abilities": {"functionCall": true, "vision": true}, "config": {"deploymentName": "doubao-1-5-vision-lite-250315"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-15", "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "Doubao-1.5-vision-lite 全新升级的多模态大模型，支持任意分辨率和极端长宽比图像识别，增强视觉推理、文档识别、细节信息理解和指令遵循能力。支持 128k 上下文窗口，输出长度支持最大 16k tokens。", "vision": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-vision-pro-32k', 'Doubao Vision Pro 32k', 'chat', 32768, 4096, 0.003, 0.009, '{"abilities": {"vision": true}, "config": {"deploymentName": "doubao-vision-pro-32k-241028"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-10-28", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Doubao-vision 模型是豆包推出的多模态大模型，具备强大的图片理解与推理能力，以及精准的指令理解能力。模型在图像文本信息抽取、基于图像的推理任务上有展现出了强大的性能，能够应用于更复杂、更广泛的视觉问答任务。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-vision-lite-32k', 'Doubao Vision Lite 32k', 'chat', 32768, 4096, 0.0015, 0.0045, '{"abilities": {"vision": true}, "config": {"deploymentName": "doubao-vision-lite-32k-241015"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-10-15", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "Doubao-vision 模型是豆包推出的多模态大模型，具备强大的图片理解与推理能力，以及精准的指令理解能力。模型在图像文本信息抽取、基于图像的推理任务上有展现出了强大的性能，能够应用于更复杂、更广泛的视觉问答任务。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-lite-4k', 'Doubao Lite 4k', 'chat', 4096, 4096, 0.0003, 0.0006, '{"config": {"deploymentName": "doubao-lite-4k-character-240828"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持 4k 上下文窗口的推理和精调。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-lite-32k', 'Doubao Lite 32k', 'chat', 32768, 4096, 0.0003, 0.0006, '{"config": {"deploymentName": "doubao-lite-32k-240828"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持 32k 上下文窗口的推理和精调。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-lite-128k', 'Doubao Lite 128k', 'chat', 128000, 4096, 0.0008, 0.001, '{"config": {"deploymentName": "doubao-lite-128k-240828"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持 128k 上下文窗口的推理和精调。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-pro-32k', 'Doubao Pro 32k', 'chat', 32768, 4096, 0.0008, 0.002, '{"config": {"deploymentName": "doubao-pro-32k-241215"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持 32k 上下文窗口的推理和精调。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-pro-256k', 'Doubao Pro 256k', 'chat', 256000, 4096, 0.005, 0.009, '{"config": {"deploymentName": "doubao-pro-256k-241115"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "maxOutputTokens": 4096, "maxOutput": 4096, "description": "效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持 256k 上下文窗口的推理和精调。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-seedream-4-0-250828', 'Seedream 4.0', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrls": {"default": [], "maxCount": 10, "maxFileSize": 10485760}, "prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["2048x2048", "2304x1728", "1728x2304", "2560x1440", "1440x2560", "2496x1664", "1664x2496", "3024x1296"]}}, "released_at": "2025-09-09", "source": "builtin", "description": "Seedream 4.0 图片生成模型由字节跳动 Seed 团队研发，支持文字与图片输入，提供高可控、高质量的图片生成体验。基于文本提示词生成图片。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-seedream-3-0-t2i-250415', 'Seedream 3.0 文生图', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"cfg": {"default": 2.5, "max": 10, "min": 1, "step": 0.1}, "prompt": {"default": ""}, "seed": {"default": null}, "size": {"default": "1024x1024", "enum": ["1024x1024", "864x1152", "1152x864", "1280x720", "720x1280", "832x1248", "1248x832", "1512x648"]}}, "released_at": "2025-04-15", "source": "builtin", "description": "Seedream 3.0 图片生成模型由字节跳动 Seed 团队研发，支持文字与图片输入，提供高可控、高质量的图片生成体验。基于文本提示词生成图片。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'volcengine'), 'doubao-seededit-3-0-i2i-250628', 'SeedEdit 3.0 图生图', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"cfg": {"default": 5.5, "max": 10, "min": 1, "step": 0.1}, "imageUrl": {"default": null, "maxFileSize": 10485760}, "prompt": {"default": ""}, "seed": {"default": null}}, "released_at": "2025-06-28", "source": "builtin", "description": "Doubao图片生成模型由字节跳动 Seed 团队研发，支持文字与图片输入，提供高可控、高质量的图片生成体验。支持通过文本指令编辑图像，生成图像的边长在512～1536之间。"}', TRUE),
    -- wenxin
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-x1-turbo-32k', 'ERNIE X1 Turbo 32K', 'chat', 32768, NULL, 0.001, 0.004, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-24", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "与ERNIE-X1-32K相比，模型效果和性能更好。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-x1-32k', 'ERNIE X1 32K', 'chat', 32768, NULL, 0.002, 0.008, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-15", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "具备更强的理解、规划、反思、进化能力。作为能力更全面的深度思考模型，文心X1兼备准确、创意和文采，在中文知识问答、文学创作、文稿写作、日常对话、逻辑推理、复杂计算及工具调用等方面表现尤为出色。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-x1-32k-preview', 'ERNIE X1 32K Preview', 'chat', 32768, NULL, 0.002, 0.008, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-16", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "文心大模型X1具备更强的理解、规划、反思、进化能力。作为能力更全面的深度思考模型，文心X1兼备准确、创意和文采，在中文知识问答、文学创作、文稿写作、日常对话、逻辑推理、复杂计算及工具调用等方面表现尤为出色。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-4.5-turbo-128k', 'ERNIE 4.5 Turbo 128K', 'chat', 131072, NULL, 0.0008, 0.0032, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3.2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-24", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "文心4.5 Turbo在去幻觉、逻辑推理和代码能力等方面也有着明显增强。对比文心4.5，速度更快、价格更低。模型能力全面提升，更好满足多轮长历史对话处理、长文档理解问答任务。", "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-4.5-turbo-32k', 'ERNIE 4.5 Turbo 32K', 'chat', 32768, NULL, 0.0008, 0.0032, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 3.2, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-24", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "文心4.5 Turbo在去幻觉、逻辑推理和代码能力等方面也有着明显增强。对比文心4.5，速度更快、价格更低。文本创作、知识问答等能力提升显著。输出长度及整句时延相较ERNIE 4.5有所增加。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-4.5-turbo-vl-32k', 'ERNIE 4.5 Turbo VL 32K', 'chat', 32768, NULL, 0.003, 0.009, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 9, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-24", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "文心一言大模型全新版本，图片理解、创作、翻译、代码等能力显著提升，首次支持32K上下文长度，首Token时延显著降低。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-4.5-8k-preview', 'ERNIE 4.5 8K Preview', 'chat', 8192, NULL, 0.004, 0.016, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 16, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-03-16", "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "文心大模型4.5是百度自主研发的新一代原生多模态基础大模型，通过多个模态联合建模实现协同优化，多模态理解能力优秀；具备更精进的语言能力，理解、生成、逻辑、记忆能力全面提升，去幻觉、逻辑推理、代码能力显著提升。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-4.0-8k-latest', 'ERNIE 4.0 8K', 'chat', 8192, NULL, 0.03, 0.09, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 90, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的旗舰级超大规模⼤语⾔模型，相较ERNIE 3.5实现了模型能力全面升级，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-4.0-8k-preview', 'ERNIE 4.0 8K Preview', 'chat', 8192, NULL, 0.03, 0.09, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 30, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 90, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的旗舰级超大规模⼤语⾔模型，相较ERNIE 3.5实现了模型能力全面升级，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-4.0-turbo-8k-latest', 'ERNIE 4.0 Turbo 8K', 'chat', 8192, NULL, 0.02, 0.06, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的旗舰级超大规模⼤语⾔模型，综合效果表现出色，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。相较于ERNIE 4.0在性能表现上更优秀", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-4.0-turbo-128k', 'ERNIE 4.0 Turbo 128K', 'chat', 128000, NULL, 0.02, 0.06, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "百度自研的旗舰级超大规模⼤语⾔模型，综合效果表现出色，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。相较于ERNIE 4.0在性能表现上更优秀", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-4.0-turbo-8k-preview', 'ERNIE 4.0 Turbo 8K Preview', 'chat', 8192, NULL, 0.02, 0.06, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 60, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的旗舰级超大规模⼤语⾔模型，综合效果表现出色，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。相较于ERNIE 4.0在性能表现上更优秀", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-3.5-8k', 'ERNIE 3.5 8K', 'chat', 8192, NULL, 0.0008, 0.002, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的旗舰级大规模⼤语⾔模型，覆盖海量中英文语料，具有强大的通用能力，可满足绝大部分对话问答、创作生成、插件应用场景要求；支持自动对接百度搜索插件，保障问答信息时效。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-3.5-8k-preview', 'ERNIE 3.5 8K Preview', 'chat', 8192, NULL, 0.0008, 0.002, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的旗舰级大规模⼤语⾔模型，覆盖海量中英文语料，具有强大的通用能力，可满足绝大部分对话问答、创作生成、插件应用场景要求；支持自动对接百度搜索插件，保障问答信息时效。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-3.5-128k', 'ERNIE 3.5 128K', 'chat', 128000, NULL, 0.0008, 0.002, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "百度自研的旗舰级大规模⼤语⾔模型，覆盖海量中英文语料，具有强大的通用能力，可满足绝大部分对话问答、创作生成、插件应用场景要求；支持自动对接百度搜索插件，保障问答信息时效。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-lite-8k', 'ERNIE Lite 8K', 'chat', 8192, NULL, 0, 0, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "ERNIE Lite是百度自研的轻量级大语言模型，兼顾优异的模型效果与推理性能，适合低算力AI加速卡推理使用。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-lite-pro-128k', 'ERNIE Lite Pro 128K', 'chat', 128000, NULL, 0.0002, 0.0004, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "百度自研的轻量级大语言模型，兼顾优异的模型效果与推理性能，效果比ERNIE Lite更优，适合低算力AI加速卡推理使用。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-tiny-8k', 'ERNIE Tiny 8K', 'chat', 8192, NULL, 0, 0, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "ERNIE Tiny是百度自研的超高性能大语言模型，部署与精调成本在文心系列模型中最低。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-speed-128k', 'ERNIE Speed 128K', 'chat', 128000, NULL, 0, 0, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "百度2024年最新发布的自研高性能大语言模型，通用能力优异，适合作为基座模型进行精调，更好地处理特定场景问题，同时具备极佳的推理性能。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-speed-pro-128k', 'ERNIE Speed Pro 128K', 'chat', 128000, NULL, 0.0003, 0.0006, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "百度2024年最新发布的自研高性能大语言模型，通用能力优异，效果比ERNIE Speed更优，适合作为基座模型进行精调，更好地处理特定场景问题，同时具备极佳的推理性能。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-char-8k', 'ERNIE Character 8K', 'chat', 8192, NULL, 0.004, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的垂直场景大语言模型，适合游戏NPC、客服对话、对话角色扮演等应用场景，人设风格更为鲜明、一致，指令遵循能力更强，推理性能更优。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-char-fiction-8k', 'ERNIE Character Fiction 8K', 'chat', 8192, NULL, 0.004, 0.008, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研的垂直场景大语言模型，适合游戏NPC、客服对话、对话角色扮演等应用场景，人设风格更为鲜明、一致，指令遵循能力更强，推理性能更优。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-novel-8k', 'ERNIE Novel 8K', 'chat', 8192, NULL, 0.04, 0.12, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 40, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 120, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "description": "百度自研通用大语言模型，在小说续写能力上有明显优势，也可用在短剧、电影等场景。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'deepseek-v3', 'DeepSeek V3', 'chat', 65536, NULL, 0.0008, 0.0016, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.8, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "DeepSeek-V3 为杭州深度求索人工智能基础技术研究有限公司自研的 MoE 模型，其多项评测成绩突出，在主流榜单中位列开源模型榜首。V3 相比 V2.5 模型生成速度实现 3 倍提升，为用户带来更加迅速流畅的使用体验。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'deepseek-r1', 'DeepSeek R1', 'chat', 65536, NULL, 0.002, 0.008, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "description": "DeepSeek-R1 在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能比肩 OpenAI o1 正式版。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'deepseek-r1-distill-qwen-1.5b', 'DeepSeek R1 Distill Qwen 1.5B', 'chat', 32768, NULL, 0.002, 0.008, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "DeepSeek-R1-Distill-Qwen-1.5B是DeepSeek-R1基于Qwen-2.5系列的蒸馏模型。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'deepseek-r1-distill-qwen-7b', 'DeepSeek R1 Distill Qwen 7B', 'chat', 32768, NULL, 0.0006, 0.0024, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "DeepSeek-R1-Distill-Qwen-7B是DeepSeek-R1基于Qwen-2.5系列的蒸馏模型。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'deepseek-r1-distill-qwen-14b', 'DeepSeek R1 Distill Qwen 14B', 'chat', 32768, NULL, 0.0006, 0.0024, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "DeepSeek-R1-Distill-Qwen-14B是DeepSeek-R1基于Qwen-2.5系列的蒸馏模型。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'deepseek-r1-distill-qwen-32b', 'DeepSeek R1 Distill Qwen 32B', 'chat', 32768, NULL, 0.0015, 0.006, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "DeepSeek-R1-Distill-Qwen-32B是DeepSeek-R1基于Qwen-2.5系列的蒸馏模型。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'deepseek-r1-distill-llama-8b', 'DeepSeek R1 Distill Llama 8B', 'chat', 32768, NULL, 0.0015, 0.006, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "DeepSeek-R1-Distill-Llama-8B是DeepSeek-R1基于Llama3.1-8B-Base的蒸馏模型。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'deepseek-r1-distill-llama-70b', 'DeepSeek R1 Distill Llama 70B', 'chat', 32768, NULL, 0.002, 0.008, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "DeepSeek-R1-Distill-Llama-70B是DeepSeek-R1基于Llama3.3-70B-Instruct的蒸馏模型。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'deepseek-r1-distill-qianfan-llama-8b', 'DeepSeek R1 Distill Qianfan Llama 8B', 'chat', 32768, NULL, 0.001, 0.004, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "2025年2月14日首次发布，由千帆大模型研发团队以 Llama3_8B为base模型（Built with Meta Llama）蒸馏所得，蒸馏数据中也同步添加了千帆的语料。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'deepseek-r1-distill-qianfan-llama-70b', 'DeepSeek R1 Distill Qianfan Llama 70B', 'chat', 32768, NULL, 0.002, 0.008, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "2025年2月14日首次发布，由千帆大模型研发团队以 Llama3_70B为base模型（Built with Meta Llama）蒸馏所得，蒸馏数据中也同步添加了千帆的语料。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'qwq-32b', 'QwQ 32B', 'chat', 32768, NULL, 0.002, 0.008, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 8, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "通义千问团队推出的高效推理模型，支持消费级硬件部署，具备强大的实时推理能力和与智能体Agent集成的潜力。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'irag-1.0', 'ERNIE iRAG', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["768x768", "1024x1024", "1536x1536", "2048x2048", "1024x768", "2048x1536", "768x1024", "1536x2048", "1024x576", "2048x1152", "576x1024", "1152x2048"]}}, "released_at": "2025-02-05", "source": "builtin", "description": "百度自研的iRAG（image based RAG），检索增强的文生图技术，将百度搜索的亿级图片资源跟强大的基础模型能力相结合，就可以生成各种超真实的图片，整体效果远远超过文生图原生系统，去掉了AI味儿，而且成本很低。iRAG具备无幻觉、超真实、立等可取等特点。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'ernie-irag-edit', 'ERNIE iRAG Edit', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"imageUrl": {"default": null}, "prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["768x768", "1024x1024", "1536x1536", "2048x2048", "1024x768", "2048x1536", "768x1024", "1536x2048", "1024x576", "2048x1152", "576x1024", "1152x2048"]}}, "released_at": "2025-04-17", "source": "builtin", "description": "百度自研的ERNIE iRAG Edit图像编辑模型支持基于图片进行erase（消除对象）、repaint（重绘对象）、variation（生成变体）等操作。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'wenxin'), 'flux.1-schnell', 'FLUX.1-schnell', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"prompt": {"default": ""}, "seed": {"default": null}, "size": {"default": "1024x1024", "enum": ["768x768", "1024x1024", "1536x1536", "2048x2048", "1024x768", "2048x1536", "768x1024", "1536x2048", "1024x576", "2048x1152", "576x1024", "1152x2048"]}, "steps": {"default": 25, "max": 50, "min": 1}}, "released_at": "2025-03-27", "source": "builtin", "description": "具有120亿参数的修正流变换器，能够根据文本描述生成图像。"}', TRUE),
    -- xai
    ((SELECT id FROM ai_providers WHERE code = 'xai'), 'grok-4-fast-non-reasoning', 'Grok 4 Fast (Non-Reasoning)', 'chat', 2000000, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "strategy": "tiered", "tiers": [{"rate": 0.2, "upTo": 0.128}, {"rate": 0.4, "upTo": "infinity"}], "unit": "millionTokens"}, {"name": "textOutput", "strategy": "tiered", "tiers": [{"rate": 0.5, "upTo": 0.128}, {"rate": 1, "upTo": "infinity"}], "unit": "millionTokens"}]}, "released_at": "2025-09-09", "source": "builtin", "maxToken": 2000000, "contextWindowTokens": 2000000, "description": "我们很高兴发布 Grok 4 Fast，这是我们在成本效益推理模型方面的最新进展。", "vision": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xai'), 'grok-4-fast-reasoning', 'Grok 4 Fast', 'chat', 2000000, NULL, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.05, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "strategy": "tiered", "tiers": [{"rate": 0.2, "upTo": 0.128}, {"rate": 0.4, "upTo": "infinity"}], "unit": "millionTokens"}, {"name": "textOutput", "strategy": "tiered", "tiers": [{"rate": 0.5, "upTo": 0.128}, {"rate": 1, "upTo": "infinity"}], "unit": "millionTokens"}]}, "released_at": "2025-09-09", "source": "builtin", "maxToken": 2000000, "contextWindowTokens": 2000000, "description": "我们很高兴发布 Grok 4 Fast，这是我们在成本效益推理模型方面的最新进展。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xai'), 'grok-code-fast-1', 'Grok Code Fast 1', 'chat', 256000, NULL, 0.0002, 0.0015, '{"abilities": {"functionCall": true, "reasoning": true}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.02, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-08-27", "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "我们很高兴推出 grok-code-fast-1，这是一款快速且经济高效的推理模型，在代理编码方面表现出色。", "reasoning": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'xai'), 'grok-4', 'Grok 4 0709', 'chat', 256000, NULL, 0.003, 0.015, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-07-09", "source": "builtin", "maxToken": 256000, "contextWindowTokens": 256000, "description": "我们最新最强大的旗舰模型，在自然语言处理、数学计算和推理方面表现卓越 —— 是一款完美的全能型选手。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xai'), 'grok-3', 'Grok 3', 'chat', 131072, NULL, 0.003, 0.015, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.75, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-03", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "旗舰级模型，擅长数据提取、编程和文本摘要等企业级应用，拥有金融、医疗、法律和科学等领域的深厚知识。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'xai'), 'grok-3-mini', 'Grok 3 Mini', 'chat', 131072, NULL, 0.0003, 0.0005, '{"abilities": {"functionCall": true, "reasoning": true, "search": true}, "settings": {"extendParams": ["reasoningEffort"], "searchImpl": "params"}, "pricing": {"units": [{"name": "textInput_cacheRead", "rate": 0.075, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0.3, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2025-04-03", "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "轻量级模型，回话前会先思考。运行快速、智能，适用于不需要深层领域知识的逻辑任务，并能获取原始的思维轨迹。", "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'xai'), 'grok-2-vision-1212', 'Grok 2 Vision 1212', 'chat', 32768, NULL, 0.002, 0.01, '{"abilities": {"functionCall": true, "search": true, "vision": true}, "settings": {"searchImpl": "params"}, "pricing": {"units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-12-12", "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "该模型在准确性、指令遵循和多语言能力方面有所改进。", "vision": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'xai'), 'grok-2-image-1212', 'Grok 2 Image 1212', 'image', NULL, NULL, NULL, NULL, '{"parameters": {"prompt": {"default": ""}}, "released_at": "2024-12-12", "source": "builtin", "description": "我们最新的图像生成模型可以根据文本提示生成生动逼真的图像。它在营销、社交媒体和娱乐等领域的图像生成方面表现出色。"}', TRUE),
    -- xinference
    ((SELECT id FROM ai_providers WHERE code = 'xinference'), 'deepseek-v3', 'DeepSeek V3', 'chat', 163840, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek-V3 是一个强大的专家混合（MoE）语言模型，拥有总计 6710 亿参数，每个 token 激活 370 亿参数。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xinference'), 'deepseek-r1', 'DeepSeek R1', 'chat', 163840, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "DeepSeek-R1 在强化学习（RL）之前引入了冷启动数据，在数学、代码和推理任务上表现可与 OpenAI-o1 相媲美。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xinference'), 'deepseek-r1-distill-llama', 'DeepSeek R1 Distill Llama', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "deepseek-r1-distill-llama 是基于 Llama 从 DeepSeek-R1 蒸馏而来的模型。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xinference'), 'deepseek-r1-distill-qwen', 'DeepSeek R1 Distill Qwen', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "deepseek-r1-distill-qwen 是基于 Qwen 从 DeepSeek-R1 蒸馏而来的模型。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xinference'), 'qwq-32b', 'QwQ 32B', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"reasoning": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "QwQ 是 Qwen 系列的推理模型。与传统的指令微调模型相比，QwQ 具备思考和推理能力，在下游任务中，尤其是复杂问题上，能够实现显著增强的性能。QwQ-32B 是一款中型推理模型，其性能可与最先进的推理模型（如 DeepSeek-R1、o1-mini）相媲美。", "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xinference'), 'qvq-72b-preview', 'QVQ 72B Preview', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"reasoning": true, "vision": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "QVQ-72B-Preview 是由 Qwen 团队开发的实验性研究模型，专注于提升视觉推理能力。", "vision": true, "reasoning": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xinference'), 'qwen2.5-instruct', 'Qwen2.5 Instruct', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5 是 Qwen 大型语言模型的最新系列。对于 Qwen2.5，我们发布了多个基础语言模型和指令微调语言模型，参数范围从 5 亿到 72 亿不等。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xinference'), 'qwen2.5-coder-instruct', 'Qwen2.5 Coder Instruct', 'chat', 32768, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "Qwen2.5-Coder 是 Qwen 系列中最新的代码专用大型语言模型（前身为 CodeQwen）。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xinference'), 'qwen2.5-vl-instruct', 'Qwen2.5 VL Instruct', 'chat', 128000, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 128000, "contextWindowTokens": 128000, "description": "Qwen2.5-VL 是 Qwen 模型家族中视觉语言模型的最新版本。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xinference'), 'mistral-nemo-instruct', 'Mistral Nemo Instruct', 'chat', 1024000, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 1024000, "contextWindowTokens": 1024000, "description": "Mistral-Nemo-Instruct-2407 大型语言模型（LLM）是 Mistral-Nemo-Base-2407 的指令微调版本。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xinference'), 'mistral-large-instruct', 'Mistral Large Instruct', 'chat', 131072, NULL, NULL, NULL, '{"source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Mistral-Large-Instruct-2407 是一款先进的稠密大型语言模型（LLM），拥有 1230 亿参数，具备最先进的推理、知识和编码能力。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xinference'), 'llama-3.3-instruct', 'Llama 3.3 Instruct', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Llama 3.3 指令微调模型针对对话场景进行了优化，在常见的行业基准测试中，超越了许多现有的开源聊天模型。", "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xinference'), 'llama-3.2-vision-instruct', 'Llama 3.2 Vision Instruct', 'chat', 163840, NULL, NULL, NULL, '{"abilities": {"vision": true}, "source": "builtin", "maxToken": 163840, "contextWindowTokens": 163840, "description": "Llama 3.2-Vision 指令微调模型针对视觉识别、图像推理、图像描述和回答与图像相关的常规问题进行了优化。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'xinference'), 'llama-3.1-instruct', 'Llama 3.1 Instruct', 'chat', 131072, NULL, NULL, NULL, '{"abilities": {"functionCall": true}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "Llama 3.1 指令微调模型针对对话场景进行了优化，在常见的行业基准测试中，超越了许多现有的开源聊天模型。", "function_calling": true}', TRUE),
    -- zeroone
    ((SELECT id FROM ai_providers WHERE code = 'zeroone'), 'yi-lightning', 'Yi Lightning', 'chat', 16384, NULL, 0.00099, 0.00099, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.99, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.99, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "最新高性能模型，保证高质量输出同时，推理速度大幅提升。"}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'zeroone'), 'yi-vision-v2', 'Yi Vision V2', 'chat', 16384, NULL, 0.006, 0.006, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "复杂视觉任务模型，提供基于多张图片的高性能理解、分析能力。", "vision": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'zeroone'), 'yi-spark', 'Yi Spark', 'chat', 16384, NULL, 0.001, 0.001, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "小而精悍，轻量极速模型。提供强化数学运算和代码编写能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zeroone'), 'yi-medium', 'Yi Medium', 'chat', 16384, NULL, 0.0025, 0.0025, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "中型尺寸模型升级微调，能力均衡，性价比高。深度优化指令遵循能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zeroone'), 'yi-medium-200k', 'Yi Medium 200K', 'chat', 200000, NULL, 0.012, 0.012, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "description": "200K 超长上下文窗口，提供长文本深度理解和生成能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zeroone'), 'yi-large-turbo', 'Yi Large Turbo', 'chat', 16384, NULL, 0.012, 0.012, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 12, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "超高性价比、卓越性能。根据性能和推理速度、成本，进行平衡性高精度调优。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zeroone'), 'yi-large-rag', 'Yi Large RAG', 'chat', 16384, NULL, 0.025, 0.025, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 25, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 25, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "基于 yi-large 超强模型的高阶服务，结合检索与生成技术提供精准答案，实时全网检索信息服务。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zeroone'), 'yi-large-fc', 'Yi Large FC', 'chat', 32768, NULL, 0.02, 0.02, '{"abilities": {"functionCall": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "在 yi-large 模型的基础上支持并强化了工具调用的能力，适用于各种需要搭建 agent 或 workflow 的业务场景。", "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zeroone'), 'yi-large', 'Yi Large', 'chat', 32768, NULL, 0.02, 0.02, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "description": "全新千亿参数模型，提供超强问答及文本生成能力。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zeroone'), 'yi-vision', 'Yi Vision', 'chat', 16384, NULL, 0.006, 0.006, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 6, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "复杂视觉任务模型，提供高性能图片理解、分析能力。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zeroone'), 'yi-large-preview', 'Yi Large Preview', 'chat', 16384, NULL, 0.02, 0.02, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 20, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "初期版本，推荐使用 yi-large（新版本）。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zeroone'), 'yi-lightning-lite', 'Yi Lightning Lite', 'chat', 16384, NULL, 0.00099, 0.00099, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.99, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.99, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "轻量化版本，推荐使用 yi-lightning。"}', FALSE),
    -- zhipu
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4.6', 'GLM-4.6', 'chat', 200000, 131072, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "search": true}, "settings": {"extendParams": ["enableReasoning"], "searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]_[0, 0.0002]": 0.4, "[0, 0.032]_[0.0002, infinity]": 0.6, "[0.032, 0.2]": 0.8}, "pricingParams": ["textInput", "textOutput"]}, "name": "textInput_cacheRead", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]_[0, 0.0002]": 2, "[0, 0.032]_[0.0002, infinity]": 3, "[0.032, 0.2]": 4}, "pricingParams": ["textInput", "textOutput"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]_[0, 0.0002]": 8, "[0, 0.032]_[0.0002, infinity]": 14, "[0.032, 0.2]": 16}, "pricingParams": ["textInput", "textOutput"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 200000, "contextWindowTokens": 200000, "maxOutputTokens": 131072, "maxOutput": 131072, "description": "智谱最新旗舰模型 GLM-4.6 (355B) 在高级编码、长文本处理、推理与智能体能力上全面超越前代，尤其在编程能力上对齐 Claude Sonnet 4，成为国内顶尖的 Coding 模型。", "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4.5v', 'GLM-4.5V', 'chat', 65536, 16384, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "search": true, "vision": true}, "settings": {"extendParams": ["enableReasoning"], "searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 0.4, "[0.032, infinity]": 0.8}, "pricingParams": ["textInput"]}, "name": "textInput_cacheRead", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 2, "[0.032, infinity]": 4}, "pricingParams": ["textInput"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 6, "[0.032, infinity]": 12}, "pricingParams": ["textInput"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "智谱新一代基于 MOE 架构的视觉推理模型，以106B的总参数量和12B激活参数量，在各类基准测试中达到全球同级别开源多模态模型 SOTA，涵盖图像、视频、文档理解及 GUI 任务等常见任务。", "vision": true, "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4.5', 'GLM-4.5', 'chat', 131072, 98304, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "search": true}, "settings": {"extendParams": ["enableReasoning"], "searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]_[0, 0.0002]": 0.4, "[0, 0.032]_[0.0002, infinity]": 0.6, "[0.032, 0.128]": 0.8}, "pricingParams": ["textInput", "textOutput"]}, "name": "textInput_cacheRead", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]_[0, 0.0002]": 2, "[0, 0.032]_[0.0002, infinity]": 3, "[0.032, 0.128]": 4}, "pricingParams": ["textInput", "textOutput"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]_[0, 0.0002]": 8, "[0, 0.032]_[0.0002, infinity]": 14, "[0.032, 0.128]": 16}, "pricingParams": ["textInput", "textOutput"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 98304, "maxOutput": 98304, "description": "智谱旗舰模型，支持思考模式切换，综合能力达到开源模型的 SOTA 水平，上下文长度可达128K。", "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4.5-x', 'GLM-4.5-X', 'chat', 131072, 98304, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "search": true}, "settings": {"extendParams": ["enableReasoning"], "searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 1.6, "[0, 0.032]_[0.0002, infinity]": 2.4, "[0.032, 0.128]": 3.2}, "pricingParams": ["textInput", "textOutput"]}, "name": "textInput_cacheRead", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]_[0, 0.0002]": 8, "[0, 0.032]_[0.0002, infinity]": 12, "[0.032, 0.128]": 16}, "pricingParams": ["textInput", "textOutput"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]_[0, 0.0002]": 16, "[0, 0.032]_[0.0002, infinity]": 32, "[0.032, 0.128]": 64}, "pricingParams": ["textInput", "textOutput"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 98304, "maxOutput": 98304, "description": "GLM-4.5 的极速版，在性能强劲的同时，生成速度可达 100 tokens/秒。", "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4.5-air', 'GLM-4.5-Air', 'chat', 131072, 98304, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "search": true}, "settings": {"extendParams": ["enableReasoning"], "searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 0.16, "[0.032, 0.128]": 0.24}, "pricingParams": ["textInput"]}, "name": "textInput_cacheRead", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 0.8, "[0.032, 0.128]": 1.2}, "pricingParams": ["textInput"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]_[0, 0.0002]": 2, "[0, 0.032]_[0.0002, infinity]": 6, "[0.032, 0.128]": 8}, "pricingParams": ["textInput", "textOutput"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 98304, "maxOutput": 98304, "description": "GLM-4.5 的轻量版，兼顾性能与性价比，可灵活切换混合思考模型。", "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4.5-airx', 'GLM-4.5-AirX', 'chat', 131072, 98304, NULL, NULL, '{"abilities": {"functionCall": true, "reasoning": true, "search": true}, "settings": {"extendParams": ["enableReasoning"], "searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"lookup": {"prices": {"[0, 0.032]": 0.8, "[0.032, 0.128]": 1.6}, "pricingParams": ["textInput"]}, "name": "textInput_cacheRead", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]": 4, "[0.032, 0.128]": 8}, "pricingParams": ["textInput"]}, "name": "textInput", "strategy": "lookup", "unit": "millionTokens"}, {"lookup": {"prices": {"[0, 0.032]_[0, 0.0002]": 12, "[0, 0.032]_[0.0002, infinity]": 16, "[0.032, 0.128]": 32}, "pricingParams": ["textInput", "textOutput"]}, "name": "textOutput", "strategy": "lookup", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 98304, "maxOutput": 98304, "description": "GLM-4.5-Air 的极速版，响应速度更快，专为大规模高速度需求打造。", "reasoning": true, "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4.5-flash', 'GLM-4.5-Flash', 'chat', 131072, 98304, 0, 0, '{"abilities": {"functionCall": true, "reasoning": true, "search": true}, "settings": {"extendParams": ["enableReasoning"], "searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput_cacheRead", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 98304, "maxOutput": 98304, "description": "GLM-4.5 的免费版，推理、代码、智能体等任务表现出色。", "reasoning": true, "web_search": true, "function_calling": true}', TRUE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4.1v-thinking-flashx', 'GLM-4.1V-Thinking-FlashX', 'chat', 65536, 32768, 0.002, 0.002, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 2, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GLM-4.1V-Thinking 系列模型是目前已知10B级别的VLM模型中性能最强的视觉模型，融合了同级别SOTA的各项视觉语言任务，包括视频理解、图片问答、学科解题、OCR文字识别、文档和图表解读、GUI Agent、前端网页Coding、Grounding等，多项任务能力甚至超过8倍参数量的Qwen2.5-VL-72B。通过领先的强化学习技术，模型掌握了通过思维链推理的方式提升回答的准确性和丰富度，从最终效果和可解释性等维度都显著超过传统的非thinking模型。", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4.1v-thinking-flash', 'GLM-4.1V-Thinking-Flash', 'chat', 65536, 32768, 0, 0, '{"abilities": {"reasoning": true, "vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 65536, "contextWindowTokens": 65536, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GLM-4.1V-Thinking 系列模型是目前已知10B级别的VLM模型中性能最强的视觉模型，融合了同级别SOTA的各项视觉语言任务，包括视频理解、图片问答、学科解题、OCR文字识别、文档和图表解读、GUI Agent、前端网页Coding、Grounding等，多项任务能力甚至超过8倍参数量的Qwen2.5-VL-72B。通过领先的强化学习技术，模型掌握了通过思维链推理的方式提升回答的准确性和丰富度，从最终效果和可解释性等维度都显著超过传统的非thinking模型。", "vision": true, "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-zero-preview', 'GLM-Zero-Preview', 'chat', 16384, NULL, 0.01, 0.01, '{"abilities": {"reasoning": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16384, "contextWindowTokens": 16384, "description": "GLM-Zero-Preview具备强大的复杂推理能力，在逻辑推理、数学、编程等领域表现优异。", "reasoning": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-z1-air', 'GLM-Z1-Air', 'chat', 131072, 32768, 0.0005, 0.0005, '{"abilities": {"reasoning": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "推理模型: 具备强大推理能力，适用于需要深度推理的任务。", "reasoning": true, "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-z1-airx', 'GLM-Z1-AirX', 'chat', 32768, 32768, 0.005, 0.005, '{"abilities": {"reasoning": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 32768, "contextWindowTokens": 32768, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "极速推理：具有超快的推理速度和强大的推理效果。", "reasoning": true, "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-z1-flashx', 'GLM-Z1-FlashX', 'chat', 131072, 32768, 0.0001, 0.0001, '{"abilities": {"reasoning": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "高速低价：Flash增强版本，超快推理速度，更快并发保障。", "reasoning": true, "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-z1-flash', 'GLM-Z1-Flash', 'chat', 131072, 32768, 0, 0, '{"abilities": {"reasoning": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GLM-Z1 系列具备强大的复杂推理能力，在逻辑推理、数学、编程等领域表现优异。", "reasoning": true, "web_search": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4-flash-250414', 'GLM-4-Flash-250414', 'chat', 131072, 32768, 0, 0, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "GLM-4-Flash 是处理简单任务的理想选择，速度最快且免费。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4-flashx', 'GLM-4-FlashX-250414', 'chat', 131072, 4095, 0.0001, 0.0001, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4095, "maxOutput": 4095, "description": "GLM-4-FlashX 是Flash的增强版本，超快推理速度。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4-long', 'GLM-4-Long', 'chat', 1024000, 4095, 0.001, 0.001, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 1024000, "contextWindowTokens": 1024000, "maxOutputTokens": 4095, "maxOutput": 4095, "description": "GLM-4-Long 支持超长文本输入，适合记忆型任务与大规模文档处理。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4-air-250414', 'GLM-4-Air-250414', 'chat', 131072, 16384, 0.0005, 0.0005, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 16384, "maxOutput": 16384, "description": "GLM-4-Air 是性价比高的版本，性能接近GLM-4，提供快速度和实惠的价格。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4-airx', 'GLM-4-AirX', 'chat', 8192, 4095, 0.01, 0.01, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 10, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 4095, "maxOutput": 4095, "description": "GLM-4-AirX 提供 GLM-4-Air 的高效版本，推理速度可达其2.6倍。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4-plus', 'GLM-4-Plus', 'chat', 131072, 4095, 0.005, 0.005, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 5, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 4095, "maxOutput": 4095, "description": "GLM-4-Plus 作为高智能旗舰，具备强大的处理长文本和复杂任务的能力，性能全面提升。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4-0520', 'GLM-4-0520', 'chat', 131072, NULL, 0.1, 0.1, '{"abilities": {"functionCall": true, "search": true}, "settings": {"searchImpl": "params"}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 100, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 100, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "description": "GLM-4-0520 是最新模型版本，专为高度复杂和多样化任务设计，表现卓越。", "web_search": true, "function_calling": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4v-flash', 'GLM-4V-Flash', 'chat', 4096, 8192, 0, 0, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0, "strategy": "fixed", "unit": "millionTokens"}]}, "released_at": "2024-12-09", "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "maxOutputTokens": 8192, "maxOutput": 8192, "description": "GLM-4V-Flash 专注于高效的单一图像理解，适用于快速图像解析的场景，例如实时图像分析或批量图像处理。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4v-plus-0111', 'GLM-4V-Plus-0111', 'chat', 16000, NULL, 0.004, 0.004, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 4, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 16000, "contextWindowTokens": 16000, "description": "GLM-4V-Plus 具备对视频内容及多图片的理解能力，适合多模态任务。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'glm-4v', 'GLM-4V', 'chat', 4096, 1024, 0.05, 0.05, '{"abilities": {"vision": true}, "pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 50, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 50, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 4096, "contextWindowTokens": 4096, "maxOutputTokens": 1024, "maxOutput": 1024, "description": "GLM-4V 提供强大的图像理解与推理能力，支持多种视觉任务。", "vision": true}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'codegeex-4', 'CodeGeeX-4', 'chat', 131072, 32768, 0.0001, 0.0001, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 0.1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 131072, "contextWindowTokens": 131072, "maxOutputTokens": 32768, "maxOutput": 32768, "description": "CodeGeeX-4 是强大的AI编程助手，支持多种编程语言的智能问答与代码补全，提升开发效率。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'charglm-4', 'CharGLM-4', 'chat', 8192, 4000, 0.001, 0.001, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 1, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "CharGLM-4 专为角色扮演与情感陪伴设计，支持超长多轮记忆与个性化对话，应用广泛。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'emohaa', 'Emohaa', 'chat', 8192, 4000, 0.015, 0.015, '{"pricing": {"currency": "CNY", "units": [{"name": "textInput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}, {"name": "textOutput", "rate": 15, "strategy": "fixed", "unit": "millionTokens"}]}, "source": "builtin", "maxToken": 8192, "contextWindowTokens": 8192, "maxOutputTokens": 4000, "maxOutput": 4000, "description": "Emohaa 是心理模型，具备专业咨询能力，帮助用户理解情感问题。"}', FALSE),
    ((SELECT id FROM ai_providers WHERE code = 'zhipu'), 'cogview-4', 'CogView-4', 'image', NULL, NULL, NULL, NULL, '{"pricing": {"currency": "CNY", "units": [{"name": "imageGeneration", "rate": 0.06, "strategy": "fixed", "unit": "image"}]}, "parameters": {"prompt": {"default": ""}, "size": {"default": "1024x1024", "enum": ["1024x1024", "768x1344", "864x1152", "1344x768", "1152x864", "1440x720", "720x1440"]}}, "released_at": "2025-03-04", "source": "builtin", "description": "CogView-4 是智谱首个支持生成汉字的开源文生图模型，在语义理解、图像生成质量、中英文字生成能力等方面全面提升，支持任意长度的中英双语输入，能够生成在给定范围内的任意分辨率图像。"}', TRUE)
ON CONFLICT (provider_id, model_id) DO NOTHING;

-- ============================================================
-- End of Migration
-- ============================================================
